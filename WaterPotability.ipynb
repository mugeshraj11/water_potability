{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZIqzvSE1NfV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLpTBvKH1yuj"
      },
      "outputs": [],
      "source": [
        "zip_ref=zipfile.ZipFile(\"archive.zip\",\"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "1MyWrTHo1eUM",
        "outputId": "0e1d648b-857d-488f-86ba-9b8959694a0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "0          NaN  204.890455  20791.318981     7.300212  368.516441   \n",
              "1     3.716080  129.422921  18630.057858     6.635246         NaN   \n",
              "2     8.099124  224.236259  19909.541732     9.275884         NaN   \n",
              "3     8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
              "4     9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
              "...        ...         ...           ...          ...         ...   \n",
              "3271  4.668102  193.681735  47580.991603     7.166639  359.948574   \n",
              "3272  7.808856  193.553212  17329.802160     8.061362         NaN   \n",
              "3273  9.419510  175.762646  33155.578218     7.350233         NaN   \n",
              "3274  5.126763  230.603758  11983.869376     6.303357         NaN   \n",
              "3275  7.874671  195.102299  17404.177061     7.509306         NaN   \n",
              "\n",
              "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       564.308654       10.379783        86.990970   2.963135           0  \n",
              "1       592.885359       15.180013        56.329076   4.500656           0  \n",
              "2       418.606213       16.868637        66.420093   3.055934           0  \n",
              "3       363.266516       18.436524       100.341674   4.628771           0  \n",
              "4       398.410813       11.558279        31.997993   4.075075           0  \n",
              "...            ...             ...              ...        ...         ...  \n",
              "3271    526.424171       13.894419        66.687695   4.435821           1  \n",
              "3272    392.449580       19.903225              NaN   2.798243           1  \n",
              "3273    432.044783       11.039070        69.845400   3.298875           1  \n",
              "3274    402.883113       11.168946        77.488213   4.708658           1  \n",
              "3275    327.459760       16.140368        78.698446   2.309149           1  \n",
              "\n",
              "[3276 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf0b1b7b-0764-4212-a2fc-a1ccbc85a9e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3271</th>\n",
              "      <td>4.668102</td>\n",
              "      <td>193.681735</td>\n",
              "      <td>47580.991603</td>\n",
              "      <td>7.166639</td>\n",
              "      <td>359.948574</td>\n",
              "      <td>526.424171</td>\n",
              "      <td>13.894419</td>\n",
              "      <td>66.687695</td>\n",
              "      <td>4.435821</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3272</th>\n",
              "      <td>7.808856</td>\n",
              "      <td>193.553212</td>\n",
              "      <td>17329.802160</td>\n",
              "      <td>8.061362</td>\n",
              "      <td>NaN</td>\n",
              "      <td>392.449580</td>\n",
              "      <td>19.903225</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.798243</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3273</th>\n",
              "      <td>9.419510</td>\n",
              "      <td>175.762646</td>\n",
              "      <td>33155.578218</td>\n",
              "      <td>7.350233</td>\n",
              "      <td>NaN</td>\n",
              "      <td>432.044783</td>\n",
              "      <td>11.039070</td>\n",
              "      <td>69.845400</td>\n",
              "      <td>3.298875</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3274</th>\n",
              "      <td>5.126763</td>\n",
              "      <td>230.603758</td>\n",
              "      <td>11983.869376</td>\n",
              "      <td>6.303357</td>\n",
              "      <td>NaN</td>\n",
              "      <td>402.883113</td>\n",
              "      <td>11.168946</td>\n",
              "      <td>77.488213</td>\n",
              "      <td>4.708658</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3275</th>\n",
              "      <td>7.874671</td>\n",
              "      <td>195.102299</td>\n",
              "      <td>17404.177061</td>\n",
              "      <td>7.509306</td>\n",
              "      <td>NaN</td>\n",
              "      <td>327.459760</td>\n",
              "      <td>16.140368</td>\n",
              "      <td>78.698446</td>\n",
              "      <td>2.309149</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3276 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf0b1b7b-0764-4212-a2fc-a1ccbc85a9e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf0b1b7b-0764-4212-a2fc-a1ccbc85a9e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf0b1b7b-0764-4212-a2fc-a1ccbc85a9e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df=pd.read_csv(\"water_potability.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qm-zfGSOLij",
        "outputId": "a9c60e0a-c850-4127-d76f-7876dd2f6741"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1998\n",
              "1    1278\n",
              "Name: Potability, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df[\"Potability\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kAqmtG-t2ebe",
        "outputId": "3f652b2f-f0d7-4ce2-8616-55076da41526"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "3      8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
              "4      9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
              "5      5.584087  188.313324  28748.687739     7.544869  326.678363   \n",
              "6     10.223862  248.071735  28749.716544     7.513408  393.663396   \n",
              "7      8.635849  203.361523  13672.091764     4.563009  303.309771   \n",
              "...         ...         ...           ...          ...         ...   \n",
              "3267   8.989900  215.047358  15921.412018     6.297312  312.931022   \n",
              "3268   6.702547  207.321086  17246.920347     7.708117  304.510230   \n",
              "3269  11.491011   94.812545  37188.826022     9.263166  258.930600   \n",
              "3270   6.069616  186.659040  26138.780191     7.747547  345.700257   \n",
              "3271   4.668102  193.681735  47580.991603     7.166639  359.948574   \n",
              "\n",
              "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "3       363.266516       18.436524       100.341674   4.628771           0  \n",
              "4       398.410813       11.558279        31.997993   4.075075           0  \n",
              "5       280.467916        8.399735        54.917862   2.559708           0  \n",
              "6       283.651634       13.789695        84.603556   2.672989           0  \n",
              "7       474.607645       12.363817        62.798309   4.401425           0  \n",
              "...            ...             ...              ...        ...         ...  \n",
              "3267    390.410231        9.899115        55.069304   4.613843           1  \n",
              "3268    329.266002       16.217303        28.878601   3.442983           1  \n",
              "3269    439.893618       16.172755        41.558501   4.369264           1  \n",
              "3270    415.886955       12.067620        60.419921   3.669712           1  \n",
              "3271    526.424171       13.894419        66.687695   4.435821           1  \n",
              "\n",
              "[2011 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1800837a-c3af-4744-9430-df03e0075e0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3267</th>\n",
              "      <td>8.989900</td>\n",
              "      <td>215.047358</td>\n",
              "      <td>15921.412018</td>\n",
              "      <td>6.297312</td>\n",
              "      <td>312.931022</td>\n",
              "      <td>390.410231</td>\n",
              "      <td>9.899115</td>\n",
              "      <td>55.069304</td>\n",
              "      <td>4.613843</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3268</th>\n",
              "      <td>6.702547</td>\n",
              "      <td>207.321086</td>\n",
              "      <td>17246.920347</td>\n",
              "      <td>7.708117</td>\n",
              "      <td>304.510230</td>\n",
              "      <td>329.266002</td>\n",
              "      <td>16.217303</td>\n",
              "      <td>28.878601</td>\n",
              "      <td>3.442983</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3269</th>\n",
              "      <td>11.491011</td>\n",
              "      <td>94.812545</td>\n",
              "      <td>37188.826022</td>\n",
              "      <td>9.263166</td>\n",
              "      <td>258.930600</td>\n",
              "      <td>439.893618</td>\n",
              "      <td>16.172755</td>\n",
              "      <td>41.558501</td>\n",
              "      <td>4.369264</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3270</th>\n",
              "      <td>6.069616</td>\n",
              "      <td>186.659040</td>\n",
              "      <td>26138.780191</td>\n",
              "      <td>7.747547</td>\n",
              "      <td>345.700257</td>\n",
              "      <td>415.886955</td>\n",
              "      <td>12.067620</td>\n",
              "      <td>60.419921</td>\n",
              "      <td>3.669712</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3271</th>\n",
              "      <td>4.668102</td>\n",
              "      <td>193.681735</td>\n",
              "      <td>47580.991603</td>\n",
              "      <td>7.166639</td>\n",
              "      <td>359.948574</td>\n",
              "      <td>526.424171</td>\n",
              "      <td>13.894419</td>\n",
              "      <td>66.687695</td>\n",
              "      <td>4.435821</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2011 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1800837a-c3af-4744-9430-df03e0075e0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1800837a-c3af-4744-9430-df03e0075e0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1800837a-c3af-4744-9430-df03e0075e0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df=df.dropna(axis=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxSSqlhYOVW6",
        "outputId": "a8b497dd-8212-4565-b314-7a79199a525f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1200\n",
              "1     811\n",
              "Name: Potability, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df[\"Potability\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "E_AkakYOHFSX",
        "outputId": "a2f998b8-b126-4cf4-c69b-fa37a594cb4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "3      8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
              "4      9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
              "5      5.584087  188.313324  28748.687739     7.544869  326.678363   \n",
              "6     10.223862  248.071735  28749.716544     7.513408  393.663396   \n",
              "7      8.635849  203.361523  13672.091764     4.563009  303.309771   \n",
              "...         ...         ...           ...          ...         ...   \n",
              "3267   8.989900  215.047358  15921.412018     6.297312  312.931022   \n",
              "3268   6.702547  207.321086  17246.920347     7.708117  304.510230   \n",
              "3269  11.491011   94.812545  37188.826022     9.263166  258.930600   \n",
              "3270   6.069616  186.659040  26138.780191     7.747547  345.700257   \n",
              "3271   4.668102  193.681735  47580.991603     7.166639  359.948574   \n",
              "\n",
              "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "3       363.266516       18.436524       100.341674   4.628771           0  \n",
              "4       398.410813       11.558279        31.997993   4.075075           0  \n",
              "5       280.467916        8.399735        54.917862   2.559708           0  \n",
              "6       283.651634       13.789695        84.603556   2.672989           0  \n",
              "7       474.607645       12.363817        62.798309   4.401425           0  \n",
              "...            ...             ...              ...        ...         ...  \n",
              "3267    390.410231        9.899115        55.069304   4.613843           1  \n",
              "3268    329.266002       16.217303        28.878601   3.442983           1  \n",
              "3269    439.893618       16.172755        41.558501   4.369264           1  \n",
              "3270    415.886955       12.067620        60.419921   3.669712           1  \n",
              "3271    526.424171       13.894419        66.687695   4.435821           1  \n",
              "\n",
              "[2011 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5add5f20-d7fb-4e45-9545-9680e01153b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3267</th>\n",
              "      <td>8.989900</td>\n",
              "      <td>215.047358</td>\n",
              "      <td>15921.412018</td>\n",
              "      <td>6.297312</td>\n",
              "      <td>312.931022</td>\n",
              "      <td>390.410231</td>\n",
              "      <td>9.899115</td>\n",
              "      <td>55.069304</td>\n",
              "      <td>4.613843</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3268</th>\n",
              "      <td>6.702547</td>\n",
              "      <td>207.321086</td>\n",
              "      <td>17246.920347</td>\n",
              "      <td>7.708117</td>\n",
              "      <td>304.510230</td>\n",
              "      <td>329.266002</td>\n",
              "      <td>16.217303</td>\n",
              "      <td>28.878601</td>\n",
              "      <td>3.442983</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3269</th>\n",
              "      <td>11.491011</td>\n",
              "      <td>94.812545</td>\n",
              "      <td>37188.826022</td>\n",
              "      <td>9.263166</td>\n",
              "      <td>258.930600</td>\n",
              "      <td>439.893618</td>\n",
              "      <td>16.172755</td>\n",
              "      <td>41.558501</td>\n",
              "      <td>4.369264</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3270</th>\n",
              "      <td>6.069616</td>\n",
              "      <td>186.659040</td>\n",
              "      <td>26138.780191</td>\n",
              "      <td>7.747547</td>\n",
              "      <td>345.700257</td>\n",
              "      <td>415.886955</td>\n",
              "      <td>12.067620</td>\n",
              "      <td>60.419921</td>\n",
              "      <td>3.669712</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3271</th>\n",
              "      <td>4.668102</td>\n",
              "      <td>193.681735</td>\n",
              "      <td>47580.991603</td>\n",
              "      <td>7.166639</td>\n",
              "      <td>359.948574</td>\n",
              "      <td>526.424171</td>\n",
              "      <td>13.894419</td>\n",
              "      <td>66.687695</td>\n",
              "      <td>4.435821</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2011 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5add5f20-d7fb-4e45-9545-9680e01153b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5add5f20-d7fb-4e45-9545-9680e01153b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5add5f20-d7fb-4e45-9545-9680e01153b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "pd.get_dummies(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sFxarBa3GNy"
      },
      "outputs": [],
      "source": [
        "y=df[\"Potability\"]\n",
        "y=y.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehGL1ROWHqzs"
      },
      "outputs": [],
      "source": [
        "y=y.drop(\"index\",axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rt08x4ow3WbJ"
      },
      "outputs": [],
      "source": [
        "x=df.loc[:,:\"Turbidity\"]\n",
        "x=x.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Yzqh2CgGuvr"
      },
      "outputs": [],
      "source": [
        "x=x.drop(\"index\",axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7irHpxAcH5Eo",
        "outputId": "632f6742-dc7a-4df8-d2a5-4146d2eaac12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "0      8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
              "1      9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
              "2      5.584087  188.313324  28748.687739     7.544869  326.678363   \n",
              "3     10.223862  248.071735  28749.716544     7.513408  393.663396   \n",
              "4      8.635849  203.361523  13672.091764     4.563009  303.309771   \n",
              "...         ...         ...           ...          ...         ...   \n",
              "2006   8.989900  215.047358  15921.412018     6.297312  312.931022   \n",
              "2007   6.702547  207.321086  17246.920347     7.708117  304.510230   \n",
              "2008  11.491011   94.812545  37188.826022     9.263166  258.930600   \n",
              "2009   6.069616  186.659040  26138.780191     7.747547  345.700257   \n",
              "2010   4.668102  193.681735  47580.991603     7.166639  359.948574   \n",
              "\n",
              "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  \n",
              "0       363.266516       18.436524       100.341674   4.628771  \n",
              "1       398.410813       11.558279        31.997993   4.075075  \n",
              "2       280.467916        8.399735        54.917862   2.559708  \n",
              "3       283.651634       13.789695        84.603556   2.672989  \n",
              "4       474.607645       12.363817        62.798309   4.401425  \n",
              "...            ...             ...              ...        ...  \n",
              "2006    390.410231        9.899115        55.069304   4.613843  \n",
              "2007    329.266002       16.217303        28.878601   3.442983  \n",
              "2008    439.893618       16.172755        41.558501   4.369264  \n",
              "2009    415.886955       12.067620        60.419921   3.669712  \n",
              "2010    526.424171       13.894419        66.687695   4.435821  \n",
              "\n",
              "[2011 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9496dd5e-b7c3-4d7b-aab1-320011f036a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006</th>\n",
              "      <td>8.989900</td>\n",
              "      <td>215.047358</td>\n",
              "      <td>15921.412018</td>\n",
              "      <td>6.297312</td>\n",
              "      <td>312.931022</td>\n",
              "      <td>390.410231</td>\n",
              "      <td>9.899115</td>\n",
              "      <td>55.069304</td>\n",
              "      <td>4.613843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007</th>\n",
              "      <td>6.702547</td>\n",
              "      <td>207.321086</td>\n",
              "      <td>17246.920347</td>\n",
              "      <td>7.708117</td>\n",
              "      <td>304.510230</td>\n",
              "      <td>329.266002</td>\n",
              "      <td>16.217303</td>\n",
              "      <td>28.878601</td>\n",
              "      <td>3.442983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008</th>\n",
              "      <td>11.491011</td>\n",
              "      <td>94.812545</td>\n",
              "      <td>37188.826022</td>\n",
              "      <td>9.263166</td>\n",
              "      <td>258.930600</td>\n",
              "      <td>439.893618</td>\n",
              "      <td>16.172755</td>\n",
              "      <td>41.558501</td>\n",
              "      <td>4.369264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009</th>\n",
              "      <td>6.069616</td>\n",
              "      <td>186.659040</td>\n",
              "      <td>26138.780191</td>\n",
              "      <td>7.747547</td>\n",
              "      <td>345.700257</td>\n",
              "      <td>415.886955</td>\n",
              "      <td>12.067620</td>\n",
              "      <td>60.419921</td>\n",
              "      <td>3.669712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010</th>\n",
              "      <td>4.668102</td>\n",
              "      <td>193.681735</td>\n",
              "      <td>47580.991603</td>\n",
              "      <td>7.166639</td>\n",
              "      <td>359.948574</td>\n",
              "      <td>526.424171</td>\n",
              "      <td>13.894419</td>\n",
              "      <td>66.687695</td>\n",
              "      <td>4.435821</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2011 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9496dd5e-b7c3-4d7b-aab1-320011f036a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9496dd5e-b7c3-4d7b-aab1-320011f036a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9496dd5e-b7c3-4d7b-aab1-320011f036a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wWzQRqC2lrY"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKYH8PJO3C_8"
      },
      "outputs": [],
      "source": [
        "x_train=x_train.to_numpy()\n",
        "y_train=y_train.to_numpy()\n",
        "x_test=x_test.to_numpy()\n",
        "y_test=y_test.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01gf9gXq4a5N",
        "outputId": "12c8ec65-2401-4bda-9663-8374a21bb38a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(403, 403)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(x_test),len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOU462Cb5eyT",
        "outputId": "387d63a8-0ca5-4c05-9d1a-e02eb478efec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1608, 1608)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(x_train),len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edyNR4Ed6sTU",
        "outputId": "4898d628-e99b-4a3c-dee9-55206860c635"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1608, 9), (1608, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "x_train.shape,y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvtGjNZbISqC",
        "outputId": "43c8d97b-6cb2-4f9a-8a12-24c14b410b04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "y_train[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "604jR6PKJTDm",
        "outputId": "dd838150-5771-4a3e-860c-cd72b7576044"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZKAvecn7Px9",
        "outputId": "2761c7d2-b083-418b-e5df-2dc7f4779ef3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "y_train.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mShPBix7gut",
        "outputId": "4af111ad-758b-41b7-8a26-67a84e3640fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "x_train.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amN9S4_S7i93",
        "outputId": "9189ad5c-6d6d-4f0b-d623-10921cf8dc0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1608, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nFKK9BlAhJs",
        "outputId": "b1f60893-09e1-4827-99fb-63fa37c53d09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "y_train[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "9hVm0BBo5hpy",
        "outputId": "8cb45ca2-9bda-44af-b248-b0d6f5bb2821"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0d2d06a9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df.plot(figsize=(10,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5SaAzgK5nAW"
      },
      "source": [
        "#Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBvqHn_P54_p"
      },
      "source": [
        "Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SPsjU_h59iq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential,layers\n",
        "from tensorflow.keras.layers import Dense,Conv1D,LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqQR6sf_57z6",
        "outputId": "f2ccd5f7-31ac-43d0-e9db-db8ea30c0b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5050 - val_loss: 0.6929 - val_accuracy: 0.4837\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5141 - val_loss: 0.6922 - val_accuracy: 0.5200\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.5357 - val_loss: 0.6913 - val_accuracy: 0.5088\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5426 - val_loss: 0.6896 - val_accuracy: 0.5100\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5704 - val_loss: 0.6868 - val_accuracy: 0.5425\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.5854 - val_loss: 0.6829 - val_accuracy: 0.5700\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.5939 - val_loss: 0.6780 - val_accuracy: 0.5875\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6111 - val_loss: 0.6726 - val_accuracy: 0.6050\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.6176 - val_loss: 0.6672 - val_accuracy: 0.6175\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.6233 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6352 - val_loss: 0.6568 - val_accuracy: 0.6212\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6345 - val_loss: 0.6525 - val_accuracy: 0.6187\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6345 - val_loss: 0.6486 - val_accuracy: 0.6187\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.6374 - val_loss: 0.6451 - val_accuracy: 0.6250\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.6380 - val_loss: 0.6420 - val_accuracy: 0.6250\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.6471 - val_loss: 0.6396 - val_accuracy: 0.6325\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6518 - val_loss: 0.6377 - val_accuracy: 0.6275\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6608 - val_loss: 0.6362 - val_accuracy: 0.6212\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.6599 - val_loss: 0.6352 - val_accuracy: 0.6250\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.6646 - val_loss: 0.6337 - val_accuracy: 0.6325\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6674 - val_loss: 0.6331 - val_accuracy: 0.6325\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6743 - val_loss: 0.6327 - val_accuracy: 0.6350\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6740 - val_loss: 0.6321 - val_accuracy: 0.6313\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.6724 - val_loss: 0.6321 - val_accuracy: 0.6288\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6777 - val_loss: 0.6323 - val_accuracy: 0.6325\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6012 - accuracy: 0.6746 - val_loss: 0.6320 - val_accuracy: 0.6300\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.6780 - val_loss: 0.6322 - val_accuracy: 0.6263\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.6783 - val_loss: 0.6317 - val_accuracy: 0.6288\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.5970 - accuracy: 0.6793 - val_loss: 0.6316 - val_accuracy: 0.6288\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.6783 - val_loss: 0.6324 - val_accuracy: 0.6275\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.6809 - val_loss: 0.6322 - val_accuracy: 0.6288\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.6799 - val_loss: 0.6322 - val_accuracy: 0.6225\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.6799 - val_loss: 0.6322 - val_accuracy: 0.6263\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.6815 - val_loss: 0.6326 - val_accuracy: 0.6187\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6824 - val_loss: 0.6323 - val_accuracy: 0.6225\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.6840 - val_loss: 0.6326 - val_accuracy: 0.6225\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.6840 - val_loss: 0.6330 - val_accuracy: 0.6187\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.6834 - val_loss: 0.6332 - val_accuracy: 0.6162\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6837 - val_loss: 0.6335 - val_accuracy: 0.6150\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.6840 - val_loss: 0.6333 - val_accuracy: 0.6187\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.6859 - val_loss: 0.6339 - val_accuracy: 0.6150\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.6859 - val_loss: 0.6340 - val_accuracy: 0.6162\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.6862 - val_loss: 0.6346 - val_accuracy: 0.6175\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.6865 - val_loss: 0.6343 - val_accuracy: 0.6175\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.6880 - val_loss: 0.6342 - val_accuracy: 0.6237\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.6896 - val_loss: 0.6343 - val_accuracy: 0.6250\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.6912 - val_loss: 0.6348 - val_accuracy: 0.6250\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.6915 - val_loss: 0.6350 - val_accuracy: 0.6263\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.6921 - val_loss: 0.6348 - val_accuracy: 0.6237\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.6937 - val_loss: 0.6347 - val_accuracy: 0.6225\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.6968 - val_loss: 0.6351 - val_accuracy: 0.6237\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.6962 - val_loss: 0.6350 - val_accuracy: 0.6225\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.6946 - val_loss: 0.6352 - val_accuracy: 0.6237\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6993 - val_loss: 0.6353 - val_accuracy: 0.6200\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.6990 - val_loss: 0.6355 - val_accuracy: 0.6212\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.6974 - val_loss: 0.6356 - val_accuracy: 0.6225\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5789 - accuracy: 0.6962 - val_loss: 0.6355 - val_accuracy: 0.6225\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.6987 - val_loss: 0.6358 - val_accuracy: 0.6225\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.6977 - val_loss: 0.6356 - val_accuracy: 0.6212\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7009 - val_loss: 0.6360 - val_accuracy: 0.6212\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7021 - val_loss: 0.6365 - val_accuracy: 0.6200\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7024 - val_loss: 0.6365 - val_accuracy: 0.6225\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7037 - val_loss: 0.6366 - val_accuracy: 0.6237\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.7049 - val_loss: 0.6364 - val_accuracy: 0.6263\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7031 - val_loss: 0.6370 - val_accuracy: 0.6212\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7043 - val_loss: 0.6369 - val_accuracy: 0.6237\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7078 - val_loss: 0.6371 - val_accuracy: 0.6237\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7081 - val_loss: 0.6371 - val_accuracy: 0.6263\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.7074 - val_loss: 0.6375 - val_accuracy: 0.6225\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7081 - val_loss: 0.6378 - val_accuracy: 0.6250\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7078 - val_loss: 0.6381 - val_accuracy: 0.6237\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7084 - val_loss: 0.6379 - val_accuracy: 0.6263\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7099 - val_loss: 0.6376 - val_accuracy: 0.6275\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.7093 - val_loss: 0.6381 - val_accuracy: 0.6275\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7093 - val_loss: 0.6378 - val_accuracy: 0.6263\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7078 - val_loss: 0.6378 - val_accuracy: 0.6288\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7078 - val_loss: 0.6381 - val_accuracy: 0.6288\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7087 - val_loss: 0.6386 - val_accuracy: 0.6250\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7099 - val_loss: 0.6385 - val_accuracy: 0.6263\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7106 - val_loss: 0.6386 - val_accuracy: 0.6263\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.7112 - val_loss: 0.6387 - val_accuracy: 0.6263\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.7103 - val_loss: 0.6390 - val_accuracy: 0.6263\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7084 - val_loss: 0.6396 - val_accuracy: 0.6237\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7084 - val_loss: 0.6389 - val_accuracy: 0.6250\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7096 - val_loss: 0.6390 - val_accuracy: 0.6237\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7071 - val_loss: 0.6389 - val_accuracy: 0.6250\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7084 - val_loss: 0.6390 - val_accuracy: 0.6263\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7084 - val_loss: 0.6392 - val_accuracy: 0.6225\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7084 - val_loss: 0.6396 - val_accuracy: 0.6237\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7103 - val_loss: 0.6398 - val_accuracy: 0.6237\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7090 - val_loss: 0.6401 - val_accuracy: 0.6237\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7112 - val_loss: 0.6400 - val_accuracy: 0.6212\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.7109 - val_loss: 0.6394 - val_accuracy: 0.6288\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7121 - val_loss: 0.6396 - val_accuracy: 0.6250\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7096 - val_loss: 0.6405 - val_accuracy: 0.6250\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7106 - val_loss: 0.6406 - val_accuracy: 0.6275\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.7134 - val_loss: 0.6409 - val_accuracy: 0.6275\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7140 - val_loss: 0.6407 - val_accuracy: 0.6263\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.7143 - val_loss: 0.6408 - val_accuracy: 0.6263\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c1f7ef760>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "model_1=Sequential([\n",
        "    Dense(100,activation=\"softmax\"),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "],name=\"Model_1\")\n",
        "\n",
        "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_1.fit(x_train,y_train,\n",
        "            epochs=100,\n",
        "            validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4fN7NXx6m2o",
        "outputId": "969d32d8-4ab6-468c-da84-ee103c276c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.5732\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6842136383056641, 0.5732010006904602]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model_1.evaluate(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61plJ_0A9nUb",
        "outputId": "fb20a1e5-f08d-465e-8ba4-8c162073f6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(403, 1), dtype=float32, numpy=\n",
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "tf.round(model_1.predict(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTaT6q_29rRh",
        "outputId": "21617980-3bea-4972-b53a-503601b65625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "51/51 [==============================] - 1s 4ms/step - loss: 0.7376 - accuracy: 0.3974\n",
            "Epoch 2/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6999 - accuracy: 0.4459\n",
            "Epoch 3/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6827 - accuracy: 0.6026\n",
            "Epoch 4/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6759 - accuracy: 0.6039\n",
            "Epoch 5/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6730 - accuracy: 0.6039\n",
            "Epoch 6/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6718 - accuracy: 0.6039\n",
            "Epoch 7/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 8/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6716 - accuracy: 0.6039\n",
            "Epoch 9/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 10/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6716 - accuracy: 0.6039\n",
            "Epoch 11/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 12/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 13/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6717 - accuracy: 0.6039\n",
            "Epoch 14/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 15/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 16/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6716 - accuracy: 0.6039\n",
            "Epoch 17/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 18/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 19/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 20/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 21/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6718 - accuracy: 0.6039\n",
            "Epoch 22/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 23/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 24/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 25/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 26/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 27/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.6039\n",
            "Epoch 28/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 29/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 30/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 31/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 32/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 33/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.6039\n",
            "Epoch 34/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.6039\n",
            "Epoch 35/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.6039\n",
            "Epoch 36/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 37/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 38/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 39/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 40/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 41/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 42/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 43/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 44/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 45/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 46/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 47/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 48/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 49/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 50/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 51/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 52/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 53/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 54/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 55/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 56/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 57/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 58/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 59/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 60/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 61/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 62/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 63/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 64/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 65/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 66/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 67/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 68/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 69/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 70/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 71/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 72/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 73/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 74/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 75/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 76/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 77/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 78/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 79/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 80/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 81/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 82/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.6039\n",
            "Epoch 83/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 84/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 85/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 86/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6039\n",
            "Epoch 87/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 88/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 89/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 90/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 91/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6039\n",
            "Epoch 92/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 93/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 94/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 95/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 96/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 97/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6039\n",
            "Epoch 98/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6039\n",
            "Epoch 99/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6039\n",
            "Epoch 100/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6039\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd0fdac400>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model_2=Sequential([\n",
        "    Dense(9,activation=\"relu\"),\n",
        "    Dense(8,activation=\"sigmoid\"),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_2.fit(x_train,y_train,\n",
        "            epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcua15VY_TaF",
        "outputId": "9dcf5be4-4a82-42c2-c2ad-cb23ed15bd34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.79111385],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.38378447],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.84335536],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562],\n",
              "       [0.39518562]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model_2.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xe0sv-1_Z_J",
        "outputId": "8889b7cd-dfa7-41be-b7ab-507161b13767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "51/51 [==============================] - 2s 11ms/step - loss: 0.7153 - accuracy: 0.4546 - val_loss: 0.6905 - val_accuracy: 0.5484\n",
            "Epoch 2/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6887 - accuracy: 0.5379 - val_loss: 0.6792 - val_accuracy: 0.5931\n",
            "Epoch 3/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6741 - accuracy: 0.6057 - val_loss: 0.6824 - val_accuracy: 0.5732\n",
            "Epoch 4/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6740 - accuracy: 0.5964 - val_loss: 0.6829 - val_accuracy: 0.5732\n",
            "Epoch 5/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6727 - accuracy: 0.6026 - val_loss: 0.6831 - val_accuracy: 0.5732\n",
            "Epoch 6/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6723 - accuracy: 0.6026 - val_loss: 0.6835 - val_accuracy: 0.5732\n",
            "Epoch 7/50\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6839 - val_accuracy: 0.5732\n",
            "Epoch 8/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6841 - val_accuracy: 0.5732\n",
            "Epoch 9/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6844 - val_accuracy: 0.5732\n",
            "Epoch 10/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6843 - val_accuracy: 0.5732\n",
            "Epoch 11/50\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6845 - val_accuracy: 0.5732\n",
            "Epoch 12/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6720 - accuracy: 0.6026 - val_loss: 0.6843 - val_accuracy: 0.5732\n",
            "Epoch 13/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6722 - accuracy: 0.6026 - val_loss: 0.6841 - val_accuracy: 0.5732\n",
            "Epoch 14/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6720 - accuracy: 0.6026 - val_loss: 0.6844 - val_accuracy: 0.5732\n",
            "Epoch 15/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6843 - val_accuracy: 0.5732\n",
            "Epoch 16/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 17/50\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6843 - val_accuracy: 0.5732\n",
            "Epoch 18/50\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6847 - val_accuracy: 0.5732\n",
            "Epoch 19/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6846 - val_accuracy: 0.5732\n",
            "Epoch 20/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6846 - val_accuracy: 0.5732\n",
            "Epoch 21/50\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6723 - accuracy: 0.6026 - val_loss: 0.6843 - val_accuracy: 0.5732\n",
            "Epoch 22/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6845 - val_accuracy: 0.5732\n",
            "Epoch 23/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6843 - val_accuracy: 0.5732\n",
            "Epoch 24/50\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6844 - val_accuracy: 0.5732\n",
            "Epoch 25/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6720 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 26/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 27/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6841 - val_accuracy: 0.5732\n",
            "Epoch 28/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6839 - val_accuracy: 0.5732\n",
            "Epoch 29/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6841 - val_accuracy: 0.5732\n",
            "Epoch 30/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6843 - val_accuracy: 0.5732\n",
            "Epoch 31/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 32/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 33/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6722 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 34/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6722 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 35/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6722 - accuracy: 0.6026 - val_loss: 0.6847 - val_accuracy: 0.5732\n",
            "Epoch 36/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6720 - accuracy: 0.6026 - val_loss: 0.6846 - val_accuracy: 0.5732\n",
            "Epoch 37/50\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6720 - accuracy: 0.6026 - val_loss: 0.6845 - val_accuracy: 0.5732\n",
            "Epoch 38/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6846 - val_accuracy: 0.5732\n",
            "Epoch 39/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6720 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 40/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6843 - val_accuracy: 0.5732\n",
            "Epoch 41/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6843 - val_accuracy: 0.5732\n",
            "Epoch 42/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6845 - val_accuracy: 0.5732\n",
            "Epoch 43/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6841 - val_accuracy: 0.5732\n",
            "Epoch 44/50\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6843 - val_accuracy: 0.5732\n",
            "Epoch 45/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6844 - val_accuracy: 0.5732\n",
            "Epoch 46/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 47/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6720 - accuracy: 0.6026 - val_loss: 0.6845 - val_accuracy: 0.5732\n",
            "Epoch 48/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6720 - accuracy: 0.6026 - val_loss: 0.6847 - val_accuracy: 0.5732\n",
            "Epoch 49/50\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6844 - val_accuracy: 0.5732\n",
            "Epoch 50/50\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6848 - val_accuracy: 0.5732\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbc936d8e80>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model_3=Sequential([\n",
        "    layers.Lambda(lambda x:tf.expand_dims(x,axis=1)),\n",
        "    LSTM(8,activation=\"sigmoid\"),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_3.fit(x_train,y_train,\n",
        "            epochs=50,\n",
        "            validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGCP5AiwBCgv",
        "outputId": "5693722b-f0fc-4af7-94a4-12b84c1e80dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               1000      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,101\n",
            "Trainable params: 1,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfcNUqkXDY4S",
        "outputId": "09930d64-ad60-4182-95b9-3254c0eea6e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lambda (Lambda)             (None, 1, 9)              0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 8)                 576       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 585\n",
            "Trainable params: 585\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMJ1w1D2DcE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1d95a9a-0a54-4e95-e47a-f6bc818120dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "51/51 [==============================] - 6s 8ms/step - loss: 0.6991 - accuracy: 0.6026 - val_loss: 0.6950 - val_accuracy: 0.5732\n",
            "Epoch 2/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.6026 - val_loss: 0.6912 - val_accuracy: 0.5732\n",
            "Epoch 3/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.5976 - val_loss: 0.6958 - val_accuracy: 0.5732\n",
            "Epoch 4/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6751 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 5/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.5951 - val_loss: 0.6888 - val_accuracy: 0.5732\n",
            "Epoch 6/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.5989 - val_loss: 0.6846 - val_accuracy: 0.5732\n",
            "Epoch 7/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6760 - accuracy: 0.6026 - val_loss: 0.6855 - val_accuracy: 0.5732\n",
            "Epoch 8/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.6026 - val_loss: 0.6847 - val_accuracy: 0.5732\n",
            "Epoch 9/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.6026 - val_loss: 0.6828 - val_accuracy: 0.5732\n",
            "Epoch 10/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.6026 - val_loss: 0.6851 - val_accuracy: 0.5732\n",
            "Epoch 11/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6026 - val_loss: 0.6839 - val_accuracy: 0.5732\n",
            "Epoch 12/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6026 - val_loss: 0.6831 - val_accuracy: 0.5732\n",
            "Epoch 13/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.5964 - val_loss: 0.6859 - val_accuracy: 0.5732\n",
            "Epoch 14/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.6026 - val_loss: 0.6847 - val_accuracy: 0.5732\n",
            "Epoch 15/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6728 - accuracy: 0.6026 - val_loss: 0.6833 - val_accuracy: 0.5732\n",
            "Epoch 16/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.6026 - val_loss: 0.6828 - val_accuracy: 0.5732\n",
            "Epoch 17/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6739 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 18/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.6026 - val_loss: 0.6837 - val_accuracy: 0.5732\n",
            "Epoch 19/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.6026 - val_loss: 0.6851 - val_accuracy: 0.5732\n",
            "Epoch 20/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6026 - val_loss: 0.6836 - val_accuracy: 0.5732\n",
            "Epoch 21/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.6026 - val_loss: 0.6866 - val_accuracy: 0.5732\n",
            "Epoch 22/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6729 - accuracy: 0.6026 - val_loss: 0.6857 - val_accuracy: 0.5732\n",
            "Epoch 23/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.6026 - val_loss: 0.6846 - val_accuracy: 0.5732\n",
            "Epoch 24/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6026 - val_loss: 0.6837 - val_accuracy: 0.5732\n",
            "Epoch 25/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.6026 - val_loss: 0.6828 - val_accuracy: 0.5732\n",
            "Epoch 26/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.6026 - val_loss: 0.6835 - val_accuracy: 0.5732\n",
            "Epoch 27/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.6026 - val_loss: 0.6826 - val_accuracy: 0.5732\n",
            "Epoch 28/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6730 - accuracy: 0.5964 - val_loss: 0.6836 - val_accuracy: 0.5732\n",
            "Epoch 29/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6026 - val_loss: 0.6829 - val_accuracy: 0.5732\n",
            "Epoch 30/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6026 - val_loss: 0.6833 - val_accuracy: 0.5732\n",
            "Epoch 31/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.6026 - val_loss: 0.6831 - val_accuracy: 0.5732\n",
            "Epoch 32/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.6026 - val_loss: 0.6833 - val_accuracy: 0.5732\n",
            "Epoch 33/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.6026 - val_loss: 0.6824 - val_accuracy: 0.5732\n",
            "Epoch 34/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.6026 - val_loss: 0.6854 - val_accuracy: 0.5732\n",
            "Epoch 35/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.6014 - val_loss: 0.6826 - val_accuracy: 0.5732\n",
            "Epoch 36/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.6026 - val_loss: 0.6836 - val_accuracy: 0.5732\n",
            "Epoch 37/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6026 - val_loss: 0.6833 - val_accuracy: 0.5732\n",
            "Epoch 38/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6727 - accuracy: 0.6026 - val_loss: 0.6832 - val_accuracy: 0.5732\n",
            "Epoch 39/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.6026 - val_loss: 0.6841 - val_accuracy: 0.5732\n",
            "Epoch 40/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.6026 - val_loss: 0.6839 - val_accuracy: 0.5732\n",
            "Epoch 41/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6732 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 42/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6744 - accuracy: 0.6026 - val_loss: 0.6852 - val_accuracy: 0.5732\n",
            "Epoch 43/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6026 - val_loss: 0.6833 - val_accuracy: 0.5732\n",
            "Epoch 44/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6752 - accuracy: 0.6026 - val_loss: 0.6835 - val_accuracy: 0.5732\n",
            "Epoch 45/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6725 - accuracy: 0.6026 - val_loss: 0.6797 - val_accuracy: 0.5732\n",
            "Epoch 46/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.6026 - val_loss: 0.6820 - val_accuracy: 0.5732\n",
            "Epoch 47/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 0.6753 - accuracy: 0.6026 - val_loss: 0.6812 - val_accuracy: 0.5732\n",
            "Epoch 48/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6752 - accuracy: 0.6026 - val_loss: 0.6834 - val_accuracy: 0.5732\n",
            "Epoch 49/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6739 - accuracy: 0.6026 - val_loss: 0.6845 - val_accuracy: 0.5732\n",
            "Epoch 50/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6745 - accuracy: 0.6026 - val_loss: 0.6877 - val_accuracy: 0.5732\n",
            "Epoch 51/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 0.6747 - accuracy: 0.6026 - val_loss: 0.6846 - val_accuracy: 0.5732\n",
            "Epoch 52/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6734 - accuracy: 0.6026 - val_loss: 0.6833 - val_accuracy: 0.5732\n",
            "Epoch 53/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6026 - val_loss: 0.6827 - val_accuracy: 0.5732\n",
            "Epoch 54/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.6026 - val_loss: 0.6841 - val_accuracy: 0.5732\n",
            "Epoch 55/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6716 - accuracy: 0.6026 - val_loss: 0.6833 - val_accuracy: 0.5732\n",
            "Epoch 56/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.6026 - val_loss: 0.6845 - val_accuracy: 0.5732\n",
            "Epoch 57/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6731 - accuracy: 0.6026 - val_loss: 0.6833 - val_accuracy: 0.5732\n",
            "Epoch 58/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6729 - accuracy: 0.6026 - val_loss: 0.6829 - val_accuracy: 0.5732\n",
            "Epoch 59/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.6026 - val_loss: 0.6855 - val_accuracy: 0.5732\n",
            "Epoch 60/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.6026 - val_loss: 0.6833 - val_accuracy: 0.5732\n",
            "Epoch 61/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6026 - val_loss: 0.6839 - val_accuracy: 0.5732\n",
            "Epoch 62/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 63/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6732 - accuracy: 0.6026 - val_loss: 0.6844 - val_accuracy: 0.5732\n",
            "Epoch 64/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.6001 - val_loss: 0.6835 - val_accuracy: 0.5732\n",
            "Epoch 65/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.6026 - val_loss: 0.6839 - val_accuracy: 0.5732\n",
            "Epoch 66/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6723 - accuracy: 0.6026 - val_loss: 0.6842 - val_accuracy: 0.5732\n",
            "Epoch 67/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6026 - val_loss: 0.6839 - val_accuracy: 0.5732\n",
            "Epoch 68/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6026 - val_loss: 0.6844 - val_accuracy: 0.5732\n",
            "Epoch 69/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6727 - accuracy: 0.6026 - val_loss: 0.6830 - val_accuracy: 0.5732\n",
            "Epoch 70/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.6026 - val_loss: 0.6840 - val_accuracy: 0.5732\n",
            "Epoch 71/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6026 - val_loss: 0.6845 - val_accuracy: 0.5732\n",
            "Epoch 72/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.6026 - val_loss: 0.6831 - val_accuracy: 0.5732\n",
            "Epoch 73/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6728 - accuracy: 0.6026 - val_loss: 0.6836 - val_accuracy: 0.5732\n",
            "Epoch 74/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6026 - val_loss: 0.6839 - val_accuracy: 0.5732\n",
            "Epoch 75/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6722 - accuracy: 0.6026 - val_loss: 0.6838 - val_accuracy: 0.5732\n",
            "Epoch 76/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6728 - accuracy: 0.6026 - val_loss: 0.6837 - val_accuracy: 0.5732\n",
            "Epoch 77/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.6026 - val_loss: 0.6849 - val_accuracy: 0.5732\n",
            "Epoch 78/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6026 - val_loss: 0.6846 - val_accuracy: 0.5732\n",
            "Epoch 79/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6725 - accuracy: 0.6026 - val_loss: 0.6837 - val_accuracy: 0.5732\n",
            "Epoch 80/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.6026 - val_loss: 0.6830 - val_accuracy: 0.5732\n",
            "Epoch 81/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6026 - val_loss: 0.6851 - val_accuracy: 0.5732\n",
            "Epoch 82/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6731 - accuracy: 0.6026 - val_loss: 0.6827 - val_accuracy: 0.5732\n",
            "Epoch 83/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6733 - accuracy: 0.6026 - val_loss: 0.6825 - val_accuracy: 0.5732\n",
            "Epoch 84/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.6026 - val_loss: 0.6839 - val_accuracy: 0.5732\n",
            "Epoch 85/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.6026 - val_loss: 0.6857 - val_accuracy: 0.5732\n",
            "Epoch 86/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6731 - accuracy: 0.6026 - val_loss: 0.6850 - val_accuracy: 0.5732\n",
            "Epoch 87/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6026 - val_loss: 0.6848 - val_accuracy: 0.5732\n",
            "Epoch 88/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6726 - accuracy: 0.6026 - val_loss: 0.6835 - val_accuracy: 0.5732\n",
            "Epoch 89/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6026 - val_loss: 0.6843 - val_accuracy: 0.5732\n",
            "Epoch 90/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6723 - accuracy: 0.6026 - val_loss: 0.6841 - val_accuracy: 0.5732\n",
            "Epoch 91/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6026 - val_loss: 0.6850 - val_accuracy: 0.5732\n",
            "Epoch 92/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6728 - accuracy: 0.6026 - val_loss: 0.6854 - val_accuracy: 0.5732\n",
            "Epoch 93/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6726 - accuracy: 0.6026 - val_loss: 0.6846 - val_accuracy: 0.5732\n",
            "Epoch 94/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.6026 - val_loss: 0.6844 - val_accuracy: 0.5732\n",
            "Epoch 95/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6026 - val_loss: 0.6851 - val_accuracy: 0.5732\n",
            "Epoch 96/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.6026 - val_loss: 0.6836 - val_accuracy: 0.5732\n",
            "Epoch 97/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.6026 - val_loss: 0.6850 - val_accuracy: 0.5732\n",
            "Epoch 98/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.6026 - val_loss: 0.6834 - val_accuracy: 0.5732\n",
            "Epoch 99/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 0.6745 - accuracy: 0.6026 - val_loss: 0.6825 - val_accuracy: 0.5732\n",
            "Epoch 100/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.6026 - val_loss: 0.6859 - val_accuracy: 0.5732\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbc936c7160>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "model_4=Sequential([\n",
        "    layers.Lambda(lambda x:tf.expand_dims(x,axis=0)),\n",
        "    Conv1D(filters=32,\n",
        "           kernel_size=2,\n",
        "           padding=\"valid\",\n",
        "           activation=\"sigmoid\"),\n",
        "    layers.GlobalMaxPool1D(),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_4.fit(x_train,y_train,\n",
        "            epochs=100,\n",
        "            validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxTLEj7nEEVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94004afc-1080-41d8-e527-03205e7d11e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "51/51 [==============================] - 1s 3ms/step - loss: 96.5025 - accuracy: 0.5093\n",
            "Epoch 2/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 11.4353 - accuracy: 0.5367\n",
            "Epoch 3/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 10.6009 - accuracy: 0.5379\n",
            "Epoch 4/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 9.2943 - accuracy: 0.5261\n",
            "Epoch 5/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 9.8234 - accuracy: 0.5386\n",
            "Epoch 6/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 9.4376 - accuracy: 0.5423\n",
            "Epoch 7/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 10.2992 - accuracy: 0.5454\n",
            "Epoch 8/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.7669 - accuracy: 0.5236\n",
            "Epoch 9/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.7770 - accuracy: 0.5305\n",
            "Epoch 10/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 9.4025 - accuracy: 0.5535\n",
            "Epoch 11/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.0707 - accuracy: 0.5323\n",
            "Epoch 12/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.8775 - accuracy: 0.5274\n",
            "Epoch 13/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 9.4383 - accuracy: 0.5243\n",
            "Epoch 14/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.9246 - accuracy: 0.5224\n",
            "Epoch 15/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.0583 - accuracy: 0.5168\n",
            "Epoch 16/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 5.7895 - accuracy: 0.5311\n",
            "Epoch 17/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 10.6897 - accuracy: 0.5267\n",
            "Epoch 18/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.5843 - accuracy: 0.5243\n",
            "Epoch 19/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 9.4431 - accuracy: 0.5404\n",
            "Epoch 20/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.6558 - accuracy: 0.5348\n",
            "Epoch 21/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 10.2807 - accuracy: 0.5410\n",
            "Epoch 22/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.0526 - accuracy: 0.5280\n",
            "Epoch 23/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 10.8662 - accuracy: 0.5218\n",
            "Epoch 24/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 9.1505 - accuracy: 0.5404\n",
            "Epoch 25/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 8.3445 - accuracy: 0.5311\n",
            "Epoch 26/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 8.1255 - accuracy: 0.5442\n",
            "Epoch 27/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.5032 - accuracy: 0.5236\n",
            "Epoch 28/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 8.2041 - accuracy: 0.5174\n",
            "Epoch 29/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.0093 - accuracy: 0.5410\n",
            "Epoch 30/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 10.0610 - accuracy: 0.5205\n",
            "Epoch 31/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 9.4925 - accuracy: 0.5243\n",
            "Epoch 32/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 9.1567 - accuracy: 0.5218\n",
            "Epoch 33/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.4769 - accuracy: 0.5274\n",
            "Epoch 34/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.7699 - accuracy: 0.5323\n",
            "Epoch 35/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 5.6816 - accuracy: 0.5124\n",
            "Epoch 36/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.2077 - accuracy: 0.5187\n",
            "Epoch 37/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 15.1845 - accuracy: 0.5199\n",
            "Epoch 38/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 12.8517 - accuracy: 0.5205\n",
            "Epoch 39/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 12.4138 - accuracy: 0.5193\n",
            "Epoch 40/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 11.9442 - accuracy: 0.5131\n",
            "Epoch 41/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 9.4736 - accuracy: 0.5224\n",
            "Epoch 42/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 5.8893 - accuracy: 0.5578\n",
            "Epoch 43/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.7600 - accuracy: 0.5286\n",
            "Epoch 44/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.9512 - accuracy: 0.5373\n",
            "Epoch 45/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 5.7562 - accuracy: 0.5348\n",
            "Epoch 46/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.6091 - accuracy: 0.5292\n",
            "Epoch 47/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.3058 - accuracy: 0.5373\n",
            "Epoch 48/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.5920 - accuracy: 0.5056\n",
            "Epoch 49/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 11.8639 - accuracy: 0.5224\n",
            "Epoch 50/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 11.4493 - accuracy: 0.5317\n",
            "Epoch 51/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 5.0778 - accuracy: 0.5299\n",
            "Epoch 52/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 9.8938 - accuracy: 0.5224\n",
            "Epoch 53/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 21.8186 - accuracy: 0.5199\n",
            "Epoch 54/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.6001 - accuracy: 0.5305\n",
            "Epoch 55/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 13.7512 - accuracy: 0.5168\n",
            "Epoch 56/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 8.0480 - accuracy: 0.5267\n",
            "Epoch 57/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.4056 - accuracy: 0.5286\n",
            "Epoch 58/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.8969 - accuracy: 0.5199\n",
            "Epoch 59/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 5.7160 - accuracy: 0.5131\n",
            "Epoch 60/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.4473 - accuracy: 0.5199\n",
            "Epoch 61/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.9170 - accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 8.5959 - accuracy: 0.5106\n",
            "Epoch 63/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 6.0251 - accuracy: 0.5267\n",
            "Epoch 64/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 6.7717 - accuracy: 0.5100\n",
            "Epoch 65/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 10.5069 - accuracy: 0.5311\n",
            "Epoch 66/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 5.3691 - accuracy: 0.5261\n",
            "Epoch 67/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 11.7060 - accuracy: 0.5180\n",
            "Epoch 68/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 9.7399 - accuracy: 0.5435\n",
            "Epoch 69/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 4.4587 - accuracy: 0.5224\n",
            "Epoch 70/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 5.7678 - accuracy: 0.5261\n",
            "Epoch 71/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 8.4347 - accuracy: 0.5367\n",
            "Epoch 72/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 3.3228 - accuracy: 0.5305\n",
            "Epoch 73/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 4.3759 - accuracy: 0.5323\n",
            "Epoch 74/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 7.0582 - accuracy: 0.5174\n",
            "Epoch 75/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 13.3195 - accuracy: 0.5236\n",
            "Epoch 76/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 5.3895 - accuracy: 0.5323\n",
            "Epoch 77/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 3.3045 - accuracy: 0.5286\n",
            "Epoch 78/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 13.7468 - accuracy: 0.5087\n",
            "Epoch 79/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 8.5799 - accuracy: 0.5367\n",
            "Epoch 80/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.0423 - accuracy: 0.5162\n",
            "Epoch 81/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.6522 - accuracy: 0.5410\n",
            "Epoch 82/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 5.2917 - accuracy: 0.5305\n",
            "Epoch 83/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.4619 - accuracy: 0.5174\n",
            "Epoch 84/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 8.3481 - accuracy: 0.5131\n",
            "Epoch 85/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.1072 - accuracy: 0.5274\n",
            "Epoch 86/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.6082 - accuracy: 0.5162\n",
            "Epoch 87/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.9991 - accuracy: 0.4981\n",
            "Epoch 88/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 15.7363 - accuracy: 0.4944\n",
            "Epoch 89/100\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 8.5502 - accuracy: 0.5012\n",
            "Epoch 90/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 5.9627 - accuracy: 0.5218\n",
            "Epoch 91/100\n",
            "51/51 [==============================] - 0s 6ms/step - loss: 3.3684 - accuracy: 0.5491\n",
            "Epoch 92/100\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 11.1379 - accuracy: 0.5236\n",
            "Epoch 93/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.7995 - accuracy: 0.5087\n",
            "Epoch 94/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8392 - accuracy: 0.5361\n",
            "Epoch 95/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.8451 - accuracy: 0.5299\n",
            "Epoch 96/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 5.4021 - accuracy: 0.5218\n",
            "Epoch 97/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 7.3135 - accuracy: 0.5062\n",
            "Epoch 98/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.3694 - accuracy: 0.5205\n",
            "Epoch 99/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.1180 - accuracy: 0.5572\n",
            "Epoch 100/100\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.1898 - accuracy: 0.5379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbc931c3ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=9, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train,y_train,\n",
        "          epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icmylh7YFYGh"
      },
      "source": [
        "#Upsampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChNB4Gx3Qi0L"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"water_potability.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKVyIUPBQmJU"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp=SimpleImputer(strategy=\"mean\")\n",
        "r=imp.fit_transform(df[[\"ph\"]])\n",
        "s=imp.fit_transform(df[[\"Sulfate\"]])\n",
        "t=imp.fit_transform(df[[\"Trihalomethanes\"]])\n",
        "df[\"ph\"]=r\n",
        "df[\"Sulfate\"]=s\n",
        "df[\"Trihalomethanes\"]=t"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CabH2VbklSkK",
        "outputId": "1f489bfb-ce78-4960-b80d-966ed587d018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "0     7.080795  204.890455  20791.318981     7.300212  368.516441   \n",
              "1     3.716080  129.422921  18630.057858     6.635246  333.775777   \n",
              "2     8.099124  224.236259  19909.541732     9.275884  333.775777   \n",
              "3     8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
              "4     9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
              "...        ...         ...           ...          ...         ...   \n",
              "3271  4.668102  193.681735  47580.991603     7.166639  359.948574   \n",
              "3272  7.808856  193.553212  17329.802160     8.061362  333.775777   \n",
              "3273  9.419510  175.762646  33155.578218     7.350233  333.775777   \n",
              "3274  5.126763  230.603758  11983.869376     6.303357  333.775777   \n",
              "3275  7.874671  195.102299  17404.177061     7.509306  333.775777   \n",
              "\n",
              "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       564.308654       10.379783        86.990970   2.963135           0  \n",
              "1       592.885359       15.180013        56.329076   4.500656           0  \n",
              "2       418.606213       16.868637        66.420093   3.055934           0  \n",
              "3       363.266516       18.436524       100.341674   4.628771           0  \n",
              "4       398.410813       11.558279        31.997993   4.075075           0  \n",
              "...            ...             ...              ...        ...         ...  \n",
              "3271    526.424171       13.894419        66.687695   4.435821           1  \n",
              "3272    392.449580       19.903225        66.396293   2.798243           1  \n",
              "3273    432.044783       11.039070        69.845400   3.298875           1  \n",
              "3274    402.883113       11.168946        77.488213   4.708658           1  \n",
              "3275    327.459760       16.140368        78.698446   2.309149           1  \n",
              "\n",
              "[3276 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71855076-7dfb-4174-a0f9-88919d1b5aa3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.080795</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3271</th>\n",
              "      <td>4.668102</td>\n",
              "      <td>193.681735</td>\n",
              "      <td>47580.991603</td>\n",
              "      <td>7.166639</td>\n",
              "      <td>359.948574</td>\n",
              "      <td>526.424171</td>\n",
              "      <td>13.894419</td>\n",
              "      <td>66.687695</td>\n",
              "      <td>4.435821</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3272</th>\n",
              "      <td>7.808856</td>\n",
              "      <td>193.553212</td>\n",
              "      <td>17329.802160</td>\n",
              "      <td>8.061362</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>392.449580</td>\n",
              "      <td>19.903225</td>\n",
              "      <td>66.396293</td>\n",
              "      <td>2.798243</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3273</th>\n",
              "      <td>9.419510</td>\n",
              "      <td>175.762646</td>\n",
              "      <td>33155.578218</td>\n",
              "      <td>7.350233</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>432.044783</td>\n",
              "      <td>11.039070</td>\n",
              "      <td>69.845400</td>\n",
              "      <td>3.298875</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3274</th>\n",
              "      <td>5.126763</td>\n",
              "      <td>230.603758</td>\n",
              "      <td>11983.869376</td>\n",
              "      <td>6.303357</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>402.883113</td>\n",
              "      <td>11.168946</td>\n",
              "      <td>77.488213</td>\n",
              "      <td>4.708658</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3275</th>\n",
              "      <td>7.874671</td>\n",
              "      <td>195.102299</td>\n",
              "      <td>17404.177061</td>\n",
              "      <td>7.509306</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>327.459760</td>\n",
              "      <td>16.140368</td>\n",
              "      <td>78.698446</td>\n",
              "      <td>2.309149</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3276 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71855076-7dfb-4174-a0f9-88919d1b5aa3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71855076-7dfb-4174-a0f9-88919d1b5aa3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71855076-7dfb-4174-a0f9-88919d1b5aa3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Potability\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNTzkpD7l_n6",
        "outputId": "1c605560-d45c-4487-f3a2-babae5ab0665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1998\n",
              "1    1278\n",
              "Name: Potability, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero=df[df[\"Potability\"]==0]\n",
        "one=df[df[\"Potability\"]==1]\n",
        "from sklearn.utils import resample\n",
        "df_minority_upsampled=resample(one,replace=True,n_samples=1998)\n",
        "df=pd.concat([zero,df_minority_upsampled])"
      ],
      "metadata": {
        "id": "isnJpmtOmKQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzW78_2qQrBL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X=df.iloc[:,:9].values\n",
        "y=df.iloc[:,9:].values\n",
        "\n",
        "sc=StandardScaler()\n",
        "X=sc.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWO8bPIwlsio",
        "outputId": "5c4c16b7-8953-4ad7-b080-609827282b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.39929696e-02,  2.64742139e-01, -1.51046530e-01, ...,\n",
              "        -1.17467442e+00,  1.31201803e+00, -1.28119067e+00],\n",
              "       [-2.33944928e+00, -2.01549621e+00, -3.95565634e-01, ...,\n",
              "         2.70778018e-01, -6.46112725e-01,  6.93197311e-01],\n",
              "       [ 7.26261470e-01,  8.49272216e-01, -2.50808368e-01, ...,\n",
              "         7.79258944e-01, -1.67996169e-03, -1.16202482e+00],\n",
              "       ...,\n",
              "       [ 3.05100659e-01,  1.53295276e+00,  5.71643045e-02, ...,\n",
              "         5.60237915e-01,  8.46755053e-01, -1.57839370e-01],\n",
              "       [ 3.32175770e-01,  7.75433876e-01, -8.25522407e-01, ...,\n",
              "         1.03920070e+00, -4.31727926e-01,  3.17841502e-01],\n",
              "       [ 1.29201890e+00,  1.91342952e-01,  1.30417468e+00, ...,\n",
              "         1.34875958e+00,  8.25367070e-01,  8.73749918e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.2)"
      ],
      "metadata": {
        "id": "BtMHVDqIl8S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train),len(x_test),len(y_train),len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GyUy1B9m2DP",
        "outputId": "23cc5dc4-1fc2-4355-ebe4-d5a1e21ff623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3196, 800, 3196, 800)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL_Lfpyjng8U",
        "outputId": "c3c8759a-ce07-4ad8-ead1-a3cfedd0b2f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [1],\n",
              "       ...,\n",
              "       [0],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6=tf.keras.Sequential([\n",
        "    Dense(100,activation=\"relu\"),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Hxp2AvR0m9Wj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "c9bbd5b5-dca1-461f-e669-a7be1a3f0bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-23f1aafe2161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_6=tf.keras.Sequential([\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dense' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.fit(x_train,y_train,\n",
        "            epochs=50,\n",
        "            validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eijAA6TinWVF",
        "outputId": "3bd0a0f5-0cef-4f46-c6e7-ebd6cc479af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - 3s 5ms/step - loss: 0.6902 - accuracy: 0.5482 - val_loss: 0.6700 - val_accuracy: 0.5738\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6145 - val_loss: 0.6548 - val_accuracy: 0.6100\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.6505 - val_loss: 0.6456 - val_accuracy: 0.6075\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.6221 - accuracy: 0.6630 - val_loss: 0.6323 - val_accuracy: 0.6400\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.6749 - val_loss: 0.6278 - val_accuracy: 0.6313\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.6755 - val_loss: 0.6289 - val_accuracy: 0.6288\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.6793 - val_loss: 0.6240 - val_accuracy: 0.6350\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6812 - val_loss: 0.6245 - val_accuracy: 0.6313\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6896 - val_loss: 0.6292 - val_accuracy: 0.6263\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.6884 - val_loss: 0.6238 - val_accuracy: 0.6388\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.6902 - val_loss: 0.6285 - val_accuracy: 0.6338\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.6890 - val_loss: 0.6234 - val_accuracy: 0.6450\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.6902 - val_loss: 0.6284 - val_accuracy: 0.6463\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.6962 - val_loss: 0.6251 - val_accuracy: 0.6488\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.6962 - val_loss: 0.6302 - val_accuracy: 0.6338\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.6921 - val_loss: 0.6229 - val_accuracy: 0.6425\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.6946 - val_loss: 0.6222 - val_accuracy: 0.6438\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.6962 - val_loss: 0.6277 - val_accuracy: 0.6400\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.6884 - val_loss: 0.6198 - val_accuracy: 0.6513\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.6971 - val_loss: 0.6245 - val_accuracy: 0.6513\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.6956 - val_loss: 0.6263 - val_accuracy: 0.6400\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.6949 - val_loss: 0.6239 - val_accuracy: 0.6488\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7043 - val_loss: 0.6305 - val_accuracy: 0.6450\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7015 - val_loss: 0.6243 - val_accuracy: 0.6475\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.6974 - val_loss: 0.6253 - val_accuracy: 0.6438\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.6968 - val_loss: 0.6242 - val_accuracy: 0.6425\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5619 - accuracy: 0.7078 - val_loss: 0.6236 - val_accuracy: 0.6450\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7028 - val_loss: 0.6212 - val_accuracy: 0.6463\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7037 - val_loss: 0.6201 - val_accuracy: 0.6538\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7081 - val_loss: 0.6247 - val_accuracy: 0.6463\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7074 - val_loss: 0.6154 - val_accuracy: 0.6550\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7090 - val_loss: 0.6210 - val_accuracy: 0.6363\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.7121 - val_loss: 0.6231 - val_accuracy: 0.6413\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.7118 - val_loss: 0.6213 - val_accuracy: 0.6425\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7131 - val_loss: 0.6233 - val_accuracy: 0.6500\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7175 - val_loss: 0.6188 - val_accuracy: 0.6575\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7165 - val_loss: 0.6187 - val_accuracy: 0.6612\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7184 - val_loss: 0.6132 - val_accuracy: 0.6612\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5474 - accuracy: 0.7212 - val_loss: 0.6120 - val_accuracy: 0.6500\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.5469 - accuracy: 0.7193 - val_loss: 0.6157 - val_accuracy: 0.6513\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7184 - val_loss: 0.6157 - val_accuracy: 0.6475\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7222 - val_loss: 0.6229 - val_accuracy: 0.6363\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7203 - val_loss: 0.6167 - val_accuracy: 0.6450\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.7247 - val_loss: 0.6071 - val_accuracy: 0.6575\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7250 - val_loss: 0.6116 - val_accuracy: 0.6587\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7237 - val_loss: 0.6123 - val_accuracy: 0.6575\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7222 - val_loss: 0.6100 - val_accuracy: 0.6600\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7278 - val_loss: 0.6314 - val_accuracy: 0.6413\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7278 - val_loss: 0.6144 - val_accuracy: 0.6463\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7272 - val_loss: 0.6120 - val_accuracy: 0.6550\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d204af0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0dHigzDnkN1",
        "outputId": "4115dd8e-95f7-422c-d093-3d17e510f1c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6270334124565125, 0.6412500143051147]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model=Sequential([\n",
        "    layers.Dense(128, input_shape= (9,), activation= 'relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(64, activation= 'relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(32, activation= 'relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(1, activation= 'sigmoid')\n",
        "\n",
        "])\n",
        "\n",
        "baseline_model.compile(loss=\"binary_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "\n",
        "baseline_model.fit(x_train,y_train,\n",
        "                   epochs=50,\n",
        "                   validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VUu72p1oGuy",
        "outputId": "fe6bdfb0-22b7-44a9-9546-791be5fde162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.7053 - accuracy: 0.5147 - val_loss: 0.6879 - val_accuracy: 0.5587\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5119 - val_loss: 0.6826 - val_accuracy: 0.5775\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5344 - val_loss: 0.6727 - val_accuracy: 0.6012\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.5629 - val_loss: 0.6671 - val_accuracy: 0.6025\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6691 - accuracy: 0.5820 - val_loss: 0.6579 - val_accuracy: 0.6288\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.5820 - val_loss: 0.6499 - val_accuracy: 0.6162\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.6092 - val_loss: 0.6439 - val_accuracy: 0.6137\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.6011 - val_loss: 0.6409 - val_accuracy: 0.6237\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.6011 - val_loss: 0.6410 - val_accuracy: 0.6150\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6123 - val_loss: 0.6382 - val_accuracy: 0.6112\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.6130 - val_loss: 0.6362 - val_accuracy: 0.6375\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6211 - val_loss: 0.6369 - val_accuracy: 0.6338\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.6311 - val_loss: 0.6351 - val_accuracy: 0.6413\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6338 - accuracy: 0.6339 - val_loss: 0.6368 - val_accuracy: 0.6313\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6280 - val_loss: 0.6328 - val_accuracy: 0.6388\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.6342 - val_loss: 0.6340 - val_accuracy: 0.6425\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6374 - val_loss: 0.6342 - val_accuracy: 0.6363\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6395 - val_loss: 0.6316 - val_accuracy: 0.6338\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.6499 - val_loss: 0.6295 - val_accuracy: 0.6413\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.6499 - val_loss: 0.6285 - val_accuracy: 0.6375\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6421 - val_loss: 0.6285 - val_accuracy: 0.6325\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6564 - val_loss: 0.6290 - val_accuracy: 0.6263\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.6524 - val_loss: 0.6286 - val_accuracy: 0.6375\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6226 - accuracy: 0.6492 - val_loss: 0.6304 - val_accuracy: 0.6338\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6508 - val_loss: 0.6317 - val_accuracy: 0.6363\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.6636 - val_loss: 0.6374 - val_accuracy: 0.6187\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6649 - val_loss: 0.6299 - val_accuracy: 0.6225\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.6743 - val_loss: 0.6273 - val_accuracy: 0.6375\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.6568 - val_loss: 0.6286 - val_accuracy: 0.6375\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.6686 - val_loss: 0.6262 - val_accuracy: 0.6288\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.6755 - val_loss: 0.6295 - val_accuracy: 0.6288\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.6652 - val_loss: 0.6268 - val_accuracy: 0.6288\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.6774 - val_loss: 0.6253 - val_accuracy: 0.6212\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.6743 - val_loss: 0.6271 - val_accuracy: 0.6237\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6016 - accuracy: 0.6599 - val_loss: 0.6226 - val_accuracy: 0.6438\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.6796 - val_loss: 0.6224 - val_accuracy: 0.6388\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.6796 - val_loss: 0.6246 - val_accuracy: 0.6375\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.6790 - val_loss: 0.6233 - val_accuracy: 0.6275\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.6708 - val_loss: 0.6247 - val_accuracy: 0.6212\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5934 - accuracy: 0.6815 - val_loss: 0.6224 - val_accuracy: 0.6463\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.6762 - val_loss: 0.6249 - val_accuracy: 0.6388\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.6815 - val_loss: 0.6243 - val_accuracy: 0.6338\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.6777 - val_loss: 0.6201 - val_accuracy: 0.6313\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.6830 - val_loss: 0.6205 - val_accuracy: 0.6325\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.6705 - val_loss: 0.6200 - val_accuracy: 0.6363\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.6837 - val_loss: 0.6193 - val_accuracy: 0.6413\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.6796 - val_loss: 0.6211 - val_accuracy: 0.6350\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.6846 - val_loss: 0.6203 - val_accuracy: 0.6363\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5867 - accuracy: 0.6865 - val_loss: 0.6154 - val_accuracy: 0.6425\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.6859 - val_loss: 0.6167 - val_accuracy: 0.6375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbcaa0c8070>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SnYWcakok8S",
        "outputId": "f38a0895-7f6c-489c-cb70-514d113f7964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.616722047328949, 0.637499988079071]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIRqAj4UzJ-m",
        "outputId": "45e55201-8c5e-483a-b59e-e7735dd9f71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.LSTM(128),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_7.compile(loss=\"mae\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_7.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=70,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=40,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "id": "Nvkt5lknosds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37234a73-183c-4da1-db5f-30a67cea6695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 7s 17ms/step - loss: 0.5004 - accuracy: 0.5006 - val_loss: 0.5003 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5005 - accuracy: 0.5044 - val_loss: 0.5010 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4968 - accuracy: 0.5041 - val_loss: 0.4955 - val_accuracy: 0.4850 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4808 - accuracy: 0.5172 - val_loss: 0.5042 - val_accuracy: 0.4975 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.5275 - val_loss: 0.5033 - val_accuracy: 0.4975 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4606 - accuracy: 0.5363 - val_loss: 0.5142 - val_accuracy: 0.4825 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4487 - accuracy: 0.5516 - val_loss: 0.5112 - val_accuracy: 0.4875 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4473 - accuracy: 0.5541 - val_loss: 0.4736 - val_accuracy: 0.5300 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4532 - accuracy: 0.5466 - val_loss: 0.4853 - val_accuracy: 0.5175 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4388 - accuracy: 0.5623 - val_loss: 0.4809 - val_accuracy: 0.5188 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4379 - accuracy: 0.5623 - val_loss: 0.4783 - val_accuracy: 0.5238 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4365 - accuracy: 0.5632 - val_loss: 0.4837 - val_accuracy: 0.5163 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4315 - accuracy: 0.5704 - val_loss: 0.4614 - val_accuracy: 0.5375 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4373 - accuracy: 0.5635 - val_loss: 0.4851 - val_accuracy: 0.5188 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4261 - accuracy: 0.5738 - val_loss: 0.4552 - val_accuracy: 0.5437 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4322 - accuracy: 0.5685 - val_loss: 0.4455 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4327 - accuracy: 0.5682 - val_loss: 0.4569 - val_accuracy: 0.5412 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4549 - accuracy: 0.5454 - val_loss: 0.4184 - val_accuracy: 0.5850 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4439 - accuracy: 0.5576 - val_loss: 0.4300 - val_accuracy: 0.5788 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4286 - accuracy: 0.5726 - val_loss: 0.4755 - val_accuracy: 0.5250 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4264 - accuracy: 0.5698 - val_loss: 0.4605 - val_accuracy: 0.5400 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4265 - accuracy: 0.5742 - val_loss: 0.4348 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4160 - accuracy: 0.5845 - val_loss: 0.4501 - val_accuracy: 0.5537 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4220 - accuracy: 0.5767 - val_loss: 0.4560 - val_accuracy: 0.5450 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4210 - accuracy: 0.5801 - val_loss: 0.4463 - val_accuracy: 0.5562 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4100 - accuracy: 0.5901 - val_loss: 0.4490 - val_accuracy: 0.5512 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4083 - accuracy: 0.5917 - val_loss: 0.4389 - val_accuracy: 0.5587 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3977 - accuracy: 0.6023 - val_loss: 0.4562 - val_accuracy: 0.5412 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4145 - accuracy: 0.5870 - val_loss: 0.4528 - val_accuracy: 0.5487 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4110 - accuracy: 0.5885 - val_loss: 0.4629 - val_accuracy: 0.5412 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4211 - accuracy: 0.5770 - val_loss: 0.4634 - val_accuracy: 0.5375 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4088 - accuracy: 0.5895 - val_loss: 0.4705 - val_accuracy: 0.5288 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4033 - accuracy: 0.5979 - val_loss: 0.4515 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3988 - accuracy: 0.6033 - val_loss: 0.4443 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4066 - accuracy: 0.5920 - val_loss: 0.4425 - val_accuracy: 0.5587 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4084 - accuracy: 0.5917 - val_loss: 0.4469 - val_accuracy: 0.5512 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3976 - accuracy: 0.6039 - val_loss: 0.4243 - val_accuracy: 0.5763 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3968 - accuracy: 0.6029 - val_loss: 0.4638 - val_accuracy: 0.5362 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3945 - accuracy: 0.6067 - val_loss: 0.4387 - val_accuracy: 0.5638 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4016 - accuracy: 0.5986 - val_loss: 0.4337 - val_accuracy: 0.5612 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3930 - accuracy: 0.6073 - val_loss: 0.4386 - val_accuracy: 0.5638 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3924 - accuracy: 0.6079 - val_loss: 0.4284 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4020 - accuracy: 0.5986 - val_loss: 0.4352 - val_accuracy: 0.5663 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4037 - accuracy: 0.5976 - val_loss: 0.4425 - val_accuracy: 0.5587 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3924 - accuracy: 0.6079 - val_loss: 0.4435 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3985 - accuracy: 0.6026 - val_loss: 0.4216 - val_accuracy: 0.5775 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3826 - accuracy: 0.6173 - val_loss: 0.4355 - val_accuracy: 0.5650 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3952 - accuracy: 0.6054 - val_loss: 0.4479 - val_accuracy: 0.5537 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4005 - accuracy: 0.6001 - val_loss: 0.4534 - val_accuracy: 0.5475 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4129 - accuracy: 0.5892 - val_loss: 0.4485 - val_accuracy: 0.5537 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4011 - accuracy: 0.5995 - val_loss: 0.4519 - val_accuracy: 0.5487 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4063 - accuracy: 0.5926 - val_loss: 0.4422 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3954 - accuracy: 0.6051 - val_loss: 0.4297 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4028 - accuracy: 0.5970 - val_loss: 0.4502 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3869 - accuracy: 0.6139 - val_loss: 0.4247 - val_accuracy: 0.5788 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3756 - accuracy: 0.6273 - val_loss: 0.4200 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3705 - accuracy: 0.6295 - val_loss: 0.4188 - val_accuracy: 0.5788 - lr: 0.0010\n",
            "Epoch 58/500\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 0.3736 - accuracy: 0.6279\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3727 - accuracy: 0.6289 - val_loss: 0.4318 - val_accuracy: 0.5713 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3666 - accuracy: 0.6361 - val_loss: 0.4274 - val_accuracy: 0.5738 - lr: 1.0000e-04\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3657 - accuracy: 0.6358 - val_loss: 0.4231 - val_accuracy: 0.5788 - lr: 1.0000e-04\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3642 - accuracy: 0.6386 - val_loss: 0.4237 - val_accuracy: 0.5825 - lr: 1.0000e-04\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.3623 - accuracy: 0.6405 - val_loss: 0.4208 - val_accuracy: 0.5825 - lr: 1.0000e-04\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3629 - accuracy: 0.6399 - val_loss: 0.4249 - val_accuracy: 0.5775 - lr: 1.0000e-04\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3625 - accuracy: 0.6408 - val_loss: 0.4235 - val_accuracy: 0.5813 - lr: 1.0000e-04\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3610 - accuracy: 0.6424 - val_loss: 0.4200 - val_accuracy: 0.5850 - lr: 1.0000e-04\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.3606 - accuracy: 0.6421 - val_loss: 0.4213 - val_accuracy: 0.5850 - lr: 1.0000e-04\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3618 - accuracy: 0.6408 - val_loss: 0.4199 - val_accuracy: 0.5875 - lr: 1.0000e-04\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3587 - accuracy: 0.6449 - val_loss: 0.4174 - val_accuracy: 0.5875 - lr: 1.0000e-04\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3601 - accuracy: 0.6436 - val_loss: 0.4108 - val_accuracy: 0.5950 - lr: 1.0000e-04\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3570 - accuracy: 0.6461 - val_loss: 0.4172 - val_accuracy: 0.5875 - lr: 1.0000e-04\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3552 - accuracy: 0.6483 - val_loss: 0.4079 - val_accuracy: 0.5962 - lr: 1.0000e-04\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3550 - accuracy: 0.6486 - val_loss: 0.4137 - val_accuracy: 0.5850 - lr: 1.0000e-04\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3551 - accuracy: 0.6483 - val_loss: 0.4054 - val_accuracy: 0.5962 - lr: 1.0000e-04\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3545 - accuracy: 0.6480 - val_loss: 0.4099 - val_accuracy: 0.5900 - lr: 1.0000e-04\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3543 - accuracy: 0.6499 - val_loss: 0.4081 - val_accuracy: 0.5900 - lr: 1.0000e-04\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3526 - accuracy: 0.6505 - val_loss: 0.4007 - val_accuracy: 0.6025 - lr: 1.0000e-04\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3521 - accuracy: 0.6514 - val_loss: 0.4050 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3514 - accuracy: 0.6524 - val_loss: 0.4054 - val_accuracy: 0.5975 - lr: 1.0000e-04\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3507 - accuracy: 0.6546 - val_loss: 0.4075 - val_accuracy: 0.5962 - lr: 1.0000e-04\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3499 - accuracy: 0.6555 - val_loss: 0.4027 - val_accuracy: 0.5987 - lr: 1.0000e-04\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3516 - accuracy: 0.6518 - val_loss: 0.4126 - val_accuracy: 0.5888 - lr: 1.0000e-04\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3487 - accuracy: 0.6549 - val_loss: 0.4046 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3481 - accuracy: 0.6555 - val_loss: 0.4020 - val_accuracy: 0.6037 - lr: 1.0000e-04\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3474 - accuracy: 0.6552 - val_loss: 0.3994 - val_accuracy: 0.6050 - lr: 1.0000e-04\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3479 - accuracy: 0.6568 - val_loss: 0.4013 - val_accuracy: 0.6037 - lr: 1.0000e-04\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3488 - accuracy: 0.6546 - val_loss: 0.4015 - val_accuracy: 0.6050 - lr: 1.0000e-04\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3472 - accuracy: 0.6564 - val_loss: 0.4073 - val_accuracy: 0.5925 - lr: 1.0000e-04\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3466 - accuracy: 0.6574 - val_loss: 0.4007 - val_accuracy: 0.6025 - lr: 1.0000e-04\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3458 - accuracy: 0.6583 - val_loss: 0.4001 - val_accuracy: 0.6037 - lr: 1.0000e-04\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3455 - accuracy: 0.6586 - val_loss: 0.3997 - val_accuracy: 0.6075 - lr: 1.0000e-04\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3449 - accuracy: 0.6596 - val_loss: 0.3979 - val_accuracy: 0.6050 - lr: 1.0000e-04\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3450 - accuracy: 0.6589 - val_loss: 0.4014 - val_accuracy: 0.6025 - lr: 1.0000e-04\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3448 - accuracy: 0.6589 - val_loss: 0.3982 - val_accuracy: 0.6075 - lr: 1.0000e-04\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3445 - accuracy: 0.6593 - val_loss: 0.4015 - val_accuracy: 0.6025 - lr: 1.0000e-04\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3438 - accuracy: 0.6593 - val_loss: 0.3966 - val_accuracy: 0.6075 - lr: 1.0000e-04\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3451 - accuracy: 0.6589 - val_loss: 0.3936 - val_accuracy: 0.6087 - lr: 1.0000e-04\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3639 - accuracy: 0.6395 - val_loss: 0.4006 - val_accuracy: 0.5987 - lr: 1.0000e-04\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3615 - accuracy: 0.6389 - val_loss: 0.3897 - val_accuracy: 0.6137 - lr: 1.0000e-04\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3546 - accuracy: 0.6486 - val_loss: 0.3924 - val_accuracy: 0.6075 - lr: 1.0000e-04\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3519 - accuracy: 0.6499 - val_loss: 0.3892 - val_accuracy: 0.6125 - lr: 1.0000e-04\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3523 - accuracy: 0.6505 - val_loss: 0.3902 - val_accuracy: 0.6125 - lr: 1.0000e-04\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3501 - accuracy: 0.6530 - val_loss: 0.3875 - val_accuracy: 0.6187 - lr: 1.0000e-04\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3495 - accuracy: 0.6539 - val_loss: 0.3879 - val_accuracy: 0.6162 - lr: 1.0000e-04\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3487 - accuracy: 0.6558 - val_loss: 0.3856 - val_accuracy: 0.6212 - lr: 1.0000e-04\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3482 - accuracy: 0.6564 - val_loss: 0.3851 - val_accuracy: 0.6225 - lr: 1.0000e-04\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3474 - accuracy: 0.6561 - val_loss: 0.3860 - val_accuracy: 0.6212 - lr: 1.0000e-04\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.3469 - accuracy: 0.6571 - val_loss: 0.3858 - val_accuracy: 0.6187 - lr: 1.0000e-04\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3463 - accuracy: 0.6583 - val_loss: 0.3892 - val_accuracy: 0.6137 - lr: 1.0000e-04\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3461 - accuracy: 0.6593 - val_loss: 0.3906 - val_accuracy: 0.6112 - lr: 1.0000e-04\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3481 - accuracy: 0.6561 - val_loss: 0.3882 - val_accuracy: 0.6137 - lr: 1.0000e-04\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3470 - accuracy: 0.6571 - val_loss: 0.3870 - val_accuracy: 0.6150 - lr: 1.0000e-04\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3454 - accuracy: 0.6580 - val_loss: 0.3862 - val_accuracy: 0.6187 - lr: 1.0000e-04\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3445 - accuracy: 0.6589 - val_loss: 0.3893 - val_accuracy: 0.6125 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3446 - accuracy: 0.6596 - val_loss: 0.3884 - val_accuracy: 0.6162 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3452 - accuracy: 0.6593 - val_loss: 0.3875 - val_accuracy: 0.6162 - lr: 1.0000e-04\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3432 - accuracy: 0.6615 - val_loss: 0.3880 - val_accuracy: 0.6162 - lr: 1.0000e-04\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3431 - accuracy: 0.6615 - val_loss: 0.3879 - val_accuracy: 0.6162 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3427 - accuracy: 0.6605 - val_loss: 0.3873 - val_accuracy: 0.6150 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3430 - accuracy: 0.6599 - val_loss: 0.3882 - val_accuracy: 0.6137 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3408 - accuracy: 0.6640 - val_loss: 0.3861 - val_accuracy: 0.6175 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3401 - accuracy: 0.6640 - val_loss: 0.3859 - val_accuracy: 0.6175 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3392 - accuracy: 0.6652 - val_loss: 0.3843 - val_accuracy: 0.6212 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3391 - accuracy: 0.6646 - val_loss: 0.3865 - val_accuracy: 0.6150 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3381 - accuracy: 0.6665 - val_loss: 0.3831 - val_accuracy: 0.6212 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3376 - accuracy: 0.6661 - val_loss: 0.3817 - val_accuracy: 0.6225 - lr: 1.0000e-04\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3365 - accuracy: 0.6677 - val_loss: 0.3811 - val_accuracy: 0.6200 - lr: 1.0000e-04\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3365 - accuracy: 0.6674 - val_loss: 0.3796 - val_accuracy: 0.6237 - lr: 1.0000e-04\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3391 - accuracy: 0.6643 - val_loss: 0.3793 - val_accuracy: 0.6200 - lr: 1.0000e-04\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3375 - accuracy: 0.6661 - val_loss: 0.3796 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3350 - accuracy: 0.6683 - val_loss: 0.3822 - val_accuracy: 0.6187 - lr: 1.0000e-04\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3348 - accuracy: 0.6683 - val_loss: 0.3807 - val_accuracy: 0.6212 - lr: 1.0000e-04\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3342 - accuracy: 0.6699 - val_loss: 0.3804 - val_accuracy: 0.6212 - lr: 1.0000e-04\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3340 - accuracy: 0.6702 - val_loss: 0.3805 - val_accuracy: 0.6237 - lr: 1.0000e-04\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3338 - accuracy: 0.6702 - val_loss: 0.3812 - val_accuracy: 0.6200 - lr: 1.0000e-04\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3337 - accuracy: 0.6699 - val_loss: 0.3811 - val_accuracy: 0.6212 - lr: 1.0000e-04\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3371 - accuracy: 0.6668 - val_loss: 0.3779 - val_accuracy: 0.6263 - lr: 1.0000e-04\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3358 - accuracy: 0.6677 - val_loss: 0.3797 - val_accuracy: 0.6263 - lr: 1.0000e-04\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.3332 - accuracy: 0.6699 - val_loss: 0.3804 - val_accuracy: 0.6200 - lr: 1.0000e-04\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3331 - accuracy: 0.6702 - val_loss: 0.3797 - val_accuracy: 0.6212 - lr: 1.0000e-04\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3328 - accuracy: 0.6699 - val_loss: 0.3796 - val_accuracy: 0.6225 - lr: 1.0000e-04\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3326 - accuracy: 0.6702 - val_loss: 0.3804 - val_accuracy: 0.6212 - lr: 1.0000e-04\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.3325 - accuracy: 0.6708 - val_loss: 0.3788 - val_accuracy: 0.6237 - lr: 1.0000e-04\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.3323 - accuracy: 0.6712 - val_loss: 0.3786 - val_accuracy: 0.6225 - lr: 1.0000e-04\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3319 - accuracy: 0.6708 - val_loss: 0.3782 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3315 - accuracy: 0.6712 - val_loss: 0.3789 - val_accuracy: 0.6212 - lr: 1.0000e-04\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3315 - accuracy: 0.6712 - val_loss: 0.3779 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3321 - accuracy: 0.6708 - val_loss: 0.3780 - val_accuracy: 0.6237 - lr: 1.0000e-04\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3309 - accuracy: 0.6718 - val_loss: 0.3781 - val_accuracy: 0.6237 - lr: 1.0000e-04\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3316 - accuracy: 0.6727 - val_loss: 0.3771 - val_accuracy: 0.6263 - lr: 1.0000e-04\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3329 - accuracy: 0.6699 - val_loss: 0.3797 - val_accuracy: 0.6225 - lr: 1.0000e-04\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3310 - accuracy: 0.6718 - val_loss: 0.3801 - val_accuracy: 0.6212 - lr: 1.0000e-04\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3308 - accuracy: 0.6724 - val_loss: 0.3768 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3305 - accuracy: 0.6721 - val_loss: 0.3781 - val_accuracy: 0.6225 - lr: 1.0000e-04\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3303 - accuracy: 0.6724 - val_loss: 0.3752 - val_accuracy: 0.6288 - lr: 1.0000e-04\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3305 - accuracy: 0.6721 - val_loss: 0.3764 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3294 - accuracy: 0.6730 - val_loss: 0.3764 - val_accuracy: 0.6288 - lr: 1.0000e-04\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3291 - accuracy: 0.6737 - val_loss: 0.3788 - val_accuracy: 0.6225 - lr: 1.0000e-04\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3290 - accuracy: 0.6733 - val_loss: 0.3767 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3287 - accuracy: 0.6737 - val_loss: 0.3758 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3286 - accuracy: 0.6737 - val_loss: 0.3763 - val_accuracy: 0.6263 - lr: 1.0000e-04\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3313 - accuracy: 0.6715 - val_loss: 0.3778 - val_accuracy: 0.6237 - lr: 1.0000e-04\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3291 - accuracy: 0.6733 - val_loss: 0.3778 - val_accuracy: 0.6237 - lr: 1.0000e-04\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3340 - accuracy: 0.6686 - val_loss: 0.3824 - val_accuracy: 0.6187 - lr: 1.0000e-04\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3312 - accuracy: 0.6718 - val_loss: 0.3761 - val_accuracy: 0.6288 - lr: 1.0000e-04\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3296 - accuracy: 0.6737 - val_loss: 0.3772 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3294 - accuracy: 0.6724 - val_loss: 0.3754 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3281 - accuracy: 0.6743 - val_loss: 0.3755 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3296 - accuracy: 0.6733 - val_loss: 0.3748 - val_accuracy: 0.6288 - lr: 1.0000e-04\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3279 - accuracy: 0.6743 - val_loss: 0.3769 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3276 - accuracy: 0.6743 - val_loss: 0.3767 - val_accuracy: 0.6237 - lr: 1.0000e-04\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3274 - accuracy: 0.6746 - val_loss: 0.3755 - val_accuracy: 0.6288 - lr: 1.0000e-04\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3273 - accuracy: 0.6749 - val_loss: 0.3759 - val_accuracy: 0.6237 - lr: 1.0000e-04\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3272 - accuracy: 0.6749 - val_loss: 0.3760 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3271 - accuracy: 0.6749 - val_loss: 0.3753 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3271 - accuracy: 0.6749 - val_loss: 0.3760 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.3269 - accuracy: 0.6749 - val_loss: 0.3763 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3268 - accuracy: 0.6749 - val_loss: 0.3740 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.3267 - accuracy: 0.6749 - val_loss: 0.3756 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3269 - accuracy: 0.6749 - val_loss: 0.3750 - val_accuracy: 0.6263 - lr: 1.0000e-04\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3265 - accuracy: 0.6749 - val_loss: 0.3781 - val_accuracy: 0.6237 - lr: 1.0000e-04\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3273 - accuracy: 0.6746 - val_loss: 0.3754 - val_accuracy: 0.6263 - lr: 1.0000e-04\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3262 - accuracy: 0.6758 - val_loss: 0.3798 - val_accuracy: 0.6200 - lr: 1.0000e-04\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3275 - accuracy: 0.6740 - val_loss: 0.3783 - val_accuracy: 0.6212 - lr: 1.0000e-04\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3264 - accuracy: 0.6755 - val_loss: 0.3799 - val_accuracy: 0.6225 - lr: 1.0000e-04\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3276 - accuracy: 0.6749 - val_loss: 0.3751 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3279 - accuracy: 0.6740 - val_loss: 0.3764 - val_accuracy: 0.6288 - lr: 1.0000e-04\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3297 - accuracy: 0.6730 - val_loss: 0.3739 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3260 - accuracy: 0.6758 - val_loss: 0.3748 - val_accuracy: 0.6263 - lr: 1.0000e-04\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3285 - accuracy: 0.6743 - val_loss: 0.3776 - val_accuracy: 0.6225 - lr: 1.0000e-04\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3261 - accuracy: 0.6758 - val_loss: 0.3759 - val_accuracy: 0.6237 - lr: 1.0000e-04\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3284 - accuracy: 0.6730 - val_loss: 0.3731 - val_accuracy: 0.6288 - lr: 1.0000e-04\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3257 - accuracy: 0.6758 - val_loss: 0.3754 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3259 - accuracy: 0.6755 - val_loss: 0.3744 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
            "Epoch 194/500\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.3269 - accuracy: 0.6744\n",
            "Epoch 194: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3252 - accuracy: 0.6762 - val_loss: 0.3748 - val_accuracy: 0.6263 - lr: 1.0000e-04\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3249 - accuracy: 0.6762 - val_loss: 0.3745 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3249 - accuracy: 0.6762 - val_loss: 0.3745 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3249 - accuracy: 0.6762 - val_loss: 0.3742 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3249 - accuracy: 0.6762 - val_loss: 0.3736 - val_accuracy: 0.6288 - lr: 1.0000e-05\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3253 - accuracy: 0.6758 - val_loss: 0.3738 - val_accuracy: 0.6288 - lr: 1.0000e-05\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3253 - accuracy: 0.6758 - val_loss: 0.3739 - val_accuracy: 0.6288 - lr: 1.0000e-05\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3252 - accuracy: 0.6758 - val_loss: 0.3738 - val_accuracy: 0.6288 - lr: 1.0000e-05\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3252 - accuracy: 0.6758 - val_loss: 0.3739 - val_accuracy: 0.6288 - lr: 1.0000e-05\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3252 - accuracy: 0.6758 - val_loss: 0.3738 - val_accuracy: 0.6288 - lr: 1.0000e-05\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3252 - accuracy: 0.6758 - val_loss: 0.3737 - val_accuracy: 0.6288 - lr: 1.0000e-05\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3246 - accuracy: 0.6765 - val_loss: 0.3738 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3243 - accuracy: 0.6768 - val_loss: 0.3736 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.3243 - accuracy: 0.6768 - val_loss: 0.3738 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.3243 - accuracy: 0.6768 - val_loss: 0.3738 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3242 - accuracy: 0.6768 - val_loss: 0.3738 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3242 - accuracy: 0.6768 - val_loss: 0.3739 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3242 - accuracy: 0.6768 - val_loss: 0.3739 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3242 - accuracy: 0.6768 - val_loss: 0.3737 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3242 - accuracy: 0.6768 - val_loss: 0.3739 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3242 - accuracy: 0.6768 - val_loss: 0.3738 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3242 - accuracy: 0.6768 - val_loss: 0.3737 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3242 - accuracy: 0.6768 - val_loss: 0.3737 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3242 - accuracy: 0.6768 - val_loss: 0.3738 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.3242 - accuracy: 0.6768 - val_loss: 0.3738 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3241 - accuracy: 0.6768 - val_loss: 0.3735 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3241 - accuracy: 0.6768 - val_loss: 0.3735 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3241 - accuracy: 0.6768 - val_loss: 0.3736 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3241 - accuracy: 0.6768 - val_loss: 0.3737 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3241 - accuracy: 0.6768 - val_loss: 0.3735 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3241 - accuracy: 0.6768 - val_loss: 0.3737 - val_accuracy: 0.6275 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbc901cd3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZc6czOAqRNY",
        "outputId": "35569687-f026-43f6-bdc5-3abf72062b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.6288\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3751956522464752, 0.6287500262260437]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_8=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_8.compile(loss=\"mae\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_8.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=70,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=40,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jLhURGcrpEo",
        "outputId": "143e1679-532f-43d6-fcc8-6b8097a63176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 8s 21ms/step - loss: 0.5006 - accuracy: 0.5041 - val_loss: 0.5005 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5008 - accuracy: 0.5063 - val_loss: 0.5041 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4966 - accuracy: 0.5056 - val_loss: 0.5041 - val_accuracy: 0.4837 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4926 - accuracy: 0.5091 - val_loss: 0.5080 - val_accuracy: 0.4837 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4826 - accuracy: 0.5219 - val_loss: 0.4991 - val_accuracy: 0.5025 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4896 - accuracy: 0.5078 - val_loss: 0.5093 - val_accuracy: 0.4875 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4804 - accuracy: 0.5247 - val_loss: 0.5152 - val_accuracy: 0.4850 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4910 - accuracy: 0.5088 - val_loss: 0.5183 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5183 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5183 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5182 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5182 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4897 - accuracy: 0.5100 - val_loss: 0.5135 - val_accuracy: 0.4850 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4875 - accuracy: 0.5122 - val_loss: 0.5155 - val_accuracy: 0.4850 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4951 - accuracy: 0.5047 - val_loss: 0.5172 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4804 - accuracy: 0.5200 - val_loss: 0.5102 - val_accuracy: 0.4863 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4752 - accuracy: 0.5253 - val_loss: 0.5137 - val_accuracy: 0.4888 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4781 - accuracy: 0.5225 - val_loss: 0.5094 - val_accuracy: 0.4900 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4748 - accuracy: 0.5260 - val_loss: 0.5080 - val_accuracy: 0.4925 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4814 - accuracy: 0.5175 - val_loss: 0.4798 - val_accuracy: 0.5213 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4763 - accuracy: 0.5247 - val_loss: 0.5051 - val_accuracy: 0.4925 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4645 - accuracy: 0.5360 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5184 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5184 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4953 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4953 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4953 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4953 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4953 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4953 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4953 - accuracy: 0.5047 - val_loss: 0.5184 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4953 - accuracy: 0.5047 - val_loss: 0.5181 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4952 - accuracy: 0.5047 - val_loss: 0.5174 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4951 - accuracy: 0.5047 - val_loss: 0.5168 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4954 - accuracy: 0.5047 - val_loss: 0.5174 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4950 - accuracy: 0.5047 - val_loss: 0.5185 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4951 - accuracy: 0.5047 - val_loss: 0.5179 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4948 - accuracy: 0.5047 - val_loss: 0.5177 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4923 - accuracy: 0.5047 - val_loss: 0.5123 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4875 - accuracy: 0.5160 - val_loss: 0.5132 - val_accuracy: 0.4888 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4931 - accuracy: 0.5075 - val_loss: 0.5149 - val_accuracy: 0.4863 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4763 - accuracy: 0.5260 - val_loss: 0.5136 - val_accuracy: 0.4863 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4786 - accuracy: 0.5219 - val_loss: 0.5096 - val_accuracy: 0.4913 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4713 - accuracy: 0.5291 - val_loss: 0.4824 - val_accuracy: 0.5188 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4712 - accuracy: 0.5291 - val_loss: 0.5080 - val_accuracy: 0.4913 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4701 - accuracy: 0.5297 - val_loss: 0.4988 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4786 - accuracy: 0.5219 - val_loss: 0.4895 - val_accuracy: 0.5113 - lr: 0.0010\n",
            "Epoch 60/500\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.4768 - accuracy: 0.5236\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4754 - accuracy: 0.5250 - val_loss: 0.5002 - val_accuracy: 0.4988 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4726 - accuracy: 0.5272 - val_loss: 0.4986 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4700 - accuracy: 0.5300 - val_loss: 0.4995 - val_accuracy: 0.5013 - lr: 1.0000e-04\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4693 - accuracy: 0.5313 - val_loss: 0.4992 - val_accuracy: 0.5013 - lr: 1.0000e-04\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4678 - accuracy: 0.5338 - val_loss: 0.4982 - val_accuracy: 0.5038 - lr: 1.0000e-04\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4674 - accuracy: 0.5332 - val_loss: 0.4975 - val_accuracy: 0.5038 - lr: 1.0000e-04\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4676 - accuracy: 0.5332 - val_loss: 0.4983 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4676 - accuracy: 0.5335 - val_loss: 0.4981 - val_accuracy: 0.5025 - lr: 1.0000e-04\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.4668 - accuracy: 0.5344 - val_loss: 0.4982 - val_accuracy: 0.5013 - lr: 1.0000e-04\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4666 - accuracy: 0.5350 - val_loss: 0.4986 - val_accuracy: 0.5025 - lr: 1.0000e-04\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4663 - accuracy: 0.5354 - val_loss: 0.4979 - val_accuracy: 0.5025 - lr: 1.0000e-04\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4663 - accuracy: 0.5350 - val_loss: 0.4981 - val_accuracy: 0.5025 - lr: 1.0000e-04\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4664 - accuracy: 0.5344 - val_loss: 0.4985 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4661 - accuracy: 0.5347 - val_loss: 0.4993 - val_accuracy: 0.5013 - lr: 1.0000e-04\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4668 - accuracy: 0.5347 - val_loss: 0.4984 - val_accuracy: 0.5013 - lr: 1.0000e-04\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4661 - accuracy: 0.5344 - val_loss: 0.4985 - val_accuracy: 0.5013 - lr: 1.0000e-04\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4663 - accuracy: 0.5344 - val_loss: 0.4985 - val_accuracy: 0.5025 - lr: 1.0000e-04\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4656 - accuracy: 0.5354 - val_loss: 0.4989 - val_accuracy: 0.5025 - lr: 1.0000e-04\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4660 - accuracy: 0.5350 - val_loss: 0.4988 - val_accuracy: 0.5025 - lr: 1.0000e-04\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4656 - accuracy: 0.5354 - val_loss: 0.5007 - val_accuracy: 0.4988 - lr: 1.0000e-04\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4670 - accuracy: 0.5332 - val_loss: 0.4982 - val_accuracy: 0.5013 - lr: 1.0000e-04\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4663 - accuracy: 0.5341 - val_loss: 0.4990 - val_accuracy: 0.5013 - lr: 1.0000e-04\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4660 - accuracy: 0.5344 - val_loss: 0.4979 - val_accuracy: 0.5038 - lr: 1.0000e-04\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4655 - accuracy: 0.5354 - val_loss: 0.4995 - val_accuracy: 0.5013 - lr: 1.0000e-04\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4660 - accuracy: 0.5347 - val_loss: 0.4983 - val_accuracy: 0.5025 - lr: 1.0000e-04\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4654 - accuracy: 0.5354 - val_loss: 0.4999 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4656 - accuracy: 0.5350 - val_loss: 0.4989 - val_accuracy: 0.5013 - lr: 1.0000e-04\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4658 - accuracy: 0.5347 - val_loss: 0.4991 - val_accuracy: 0.5013 - lr: 1.0000e-04\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4654 - accuracy: 0.5350 - val_loss: 0.4989 - val_accuracy: 0.5013 - lr: 1.0000e-04\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4650 - accuracy: 0.5354 - val_loss: 0.4981 - val_accuracy: 0.5025 - lr: 1.0000e-04\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4650 - accuracy: 0.5354 - val_loss: 0.4981 - val_accuracy: 0.5025 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbca5ff43a0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISKUm4tC8mu-",
        "outputId": "d3d2cdd5-e5c8-4ce2-c76e-c360b08f3e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.5213\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4798150360584259, 0.5212500095367432]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_9=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_9.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_9.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=100,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC7sdtr987im",
        "outputId": "35457d74-a867-43ad-d99e-2b49235caeb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 8s 21ms/step - loss: 0.6940 - accuracy: 0.4937 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6934 - accuracy: 0.4953 - val_loss: 0.6922 - val_accuracy: 0.5400 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6920 - accuracy: 0.5188 - val_loss: 0.6893 - val_accuracy: 0.5275 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6843 - accuracy: 0.5435 - val_loss: 0.6907 - val_accuracy: 0.5300 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6802 - accuracy: 0.5523 - val_loss: 0.6890 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6777 - accuracy: 0.5516 - val_loss: 0.6898 - val_accuracy: 0.5350 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6778 - accuracy: 0.5607 - val_loss: 0.6891 - val_accuracy: 0.5238 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6767 - accuracy: 0.5623 - val_loss: 0.6871 - val_accuracy: 0.5512 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6732 - accuracy: 0.5573 - val_loss: 0.6832 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6728 - accuracy: 0.5585 - val_loss: 0.6836 - val_accuracy: 0.5512 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6699 - accuracy: 0.5701 - val_loss: 0.6832 - val_accuracy: 0.5537 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6676 - accuracy: 0.5620 - val_loss: 0.6769 - val_accuracy: 0.5562 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6640 - accuracy: 0.5742 - val_loss: 0.6767 - val_accuracy: 0.5512 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6557 - accuracy: 0.5807 - val_loss: 0.6743 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6522 - accuracy: 0.5851 - val_loss: 0.6736 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6502 - accuracy: 0.5851 - val_loss: 0.6661 - val_accuracy: 0.5300 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6417 - accuracy: 0.6008 - val_loss: 0.6706 - val_accuracy: 0.5612 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6363 - accuracy: 0.6148 - val_loss: 0.6688 - val_accuracy: 0.5487 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6319 - accuracy: 0.6008 - val_loss: 0.6707 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6281 - accuracy: 0.6033 - val_loss: 0.6621 - val_accuracy: 0.5813 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6221 - accuracy: 0.6252 - val_loss: 0.6939 - val_accuracy: 0.5788 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6231 - accuracy: 0.6192 - val_loss: 0.6556 - val_accuracy: 0.5725 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6125 - accuracy: 0.6283 - val_loss: 0.6682 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6088 - accuracy: 0.6358 - val_loss: 0.6615 - val_accuracy: 0.5838 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6055 - accuracy: 0.6471 - val_loss: 0.6470 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.5923 - accuracy: 0.6524 - val_loss: 0.6728 - val_accuracy: 0.5763 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.5889 - accuracy: 0.6589 - val_loss: 0.6603 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.5812 - accuracy: 0.6593 - val_loss: 0.6431 - val_accuracy: 0.5850 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.5719 - accuracy: 0.6708 - val_loss: 0.6539 - val_accuracy: 0.6050 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5617 - accuracy: 0.6815 - val_loss: 0.6401 - val_accuracy: 0.6200 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5478 - accuracy: 0.6862 - val_loss: 0.6501 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.5327 - accuracy: 0.7034 - val_loss: 0.6512 - val_accuracy: 0.6300 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.5235 - accuracy: 0.7106 - val_loss: 0.6402 - val_accuracy: 0.6513 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.5092 - accuracy: 0.7272 - val_loss: 0.6267 - val_accuracy: 0.6313 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4849 - accuracy: 0.7441 - val_loss: 0.6259 - val_accuracy: 0.6463 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4728 - accuracy: 0.7559 - val_loss: 0.6338 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.4495 - accuracy: 0.7725 - val_loss: 0.6533 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4274 - accuracy: 0.7916 - val_loss: 0.6506 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4035 - accuracy: 0.8054 - val_loss: 0.6186 - val_accuracy: 0.6875 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.3800 - accuracy: 0.8235 - val_loss: 0.6554 - val_accuracy: 0.6950 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.3529 - accuracy: 0.8364 - val_loss: 0.6495 - val_accuracy: 0.7013 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.3367 - accuracy: 0.8360 - val_loss: 0.6362 - val_accuracy: 0.7138 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.2972 - accuracy: 0.8670 - val_loss: 0.6524 - val_accuracy: 0.7200 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.2742 - accuracy: 0.8777 - val_loss: 0.6501 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.2518 - accuracy: 0.8908 - val_loss: 0.6710 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.2195 - accuracy: 0.9071 - val_loss: 0.6952 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.1970 - accuracy: 0.9190 - val_loss: 0.7146 - val_accuracy: 0.7362 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.1740 - accuracy: 0.9283 - val_loss: 0.7352 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.1463 - accuracy: 0.9437 - val_loss: 0.7742 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.1296 - accuracy: 0.9521 - val_loss: 0.7935 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.1386 - accuracy: 0.9465 - val_loss: 0.8014 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.1038 - accuracy: 0.9656 - val_loss: 0.8038 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0891 - accuracy: 0.9693 - val_loss: 0.8620 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0627 - accuracy: 0.9847 - val_loss: 0.8933 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0501 - accuracy: 0.9900 - val_loss: 0.9376 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0368 - accuracy: 0.9941 - val_loss: 0.9554 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0315 - accuracy: 0.9950 - val_loss: 1.0077 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0250 - accuracy: 0.9975 - val_loss: 1.0040 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0199 - accuracy: 0.9984 - val_loss: 1.0281 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0156 - accuracy: 0.9987 - val_loss: 1.0509 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0250 - accuracy: 0.9956 - val_loss: 1.0950 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.1471 - accuracy: 0.9490 - val_loss: 1.1041 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.1191 - accuracy: 0.9556 - val_loss: 0.9895 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0293 - accuracy: 0.9947 - val_loss: 1.0011 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0127 - accuracy: 0.9997 - val_loss: 1.0296 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.0623 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1186 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1351 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1498 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1704 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1900 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1998 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2158 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2324 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2405 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2601 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2742 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2823 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2959 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3114 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3180 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3267 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3438 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3528 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 9.9324e-04 - accuracy: 1.0000 - val_loss: 1.3635 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 9.2014e-04 - accuracy: 1.0000 - val_loss: 1.3774 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 8.5486e-04 - accuracy: 1.0000 - val_loss: 1.3863 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 7.9385e-04 - accuracy: 1.0000 - val_loss: 1.3965 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 7.4063e-04 - accuracy: 1.0000 - val_loss: 1.4092 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 6.9285e-04 - accuracy: 1.0000 - val_loss: 1.4159 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 6.4272e-04 - accuracy: 1.0000 - val_loss: 1.4321 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 93/500\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 6.0079e-04 - accuracy: 1.0000\n",
            "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 6.0025e-04 - accuracy: 1.0000 - val_loss: 1.4421 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.5908e-04 - accuracy: 1.0000 - val_loss: 1.4427 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.5459e-04 - accuracy: 1.0000 - val_loss: 1.4438 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.5041e-04 - accuracy: 1.0000 - val_loss: 1.4448 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.4639e-04 - accuracy: 1.0000 - val_loss: 1.4461 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.4204e-04 - accuracy: 1.0000 - val_loss: 1.4472 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.3771e-04 - accuracy: 1.0000 - val_loss: 1.4484 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.3332e-04 - accuracy: 1.0000 - val_loss: 1.4495 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.2857e-04 - accuracy: 1.0000 - val_loss: 1.4507 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.2376e-04 - accuracy: 1.0000 - val_loss: 1.4524 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.1899e-04 - accuracy: 1.0000 - val_loss: 1.4539 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.1399e-04 - accuracy: 1.0000 - val_loss: 1.4548 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.0878e-04 - accuracy: 1.0000 - val_loss: 1.4570 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 5.0336e-04 - accuracy: 1.0000 - val_loss: 1.4587 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 4.9785e-04 - accuracy: 1.0000 - val_loss: 1.4608 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 4.9200e-04 - accuracy: 1.0000 - val_loss: 1.4626 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 4.8648e-04 - accuracy: 1.0000 - val_loss: 1.4638 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 4.8027e-04 - accuracy: 1.0000 - val_loss: 1.4668 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 4.7398e-04 - accuracy: 1.0000 - val_loss: 1.4684 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 4.6812e-04 - accuracy: 1.0000 - val_loss: 1.4700 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 4.6117e-04 - accuracy: 1.0000 - val_loss: 1.4729 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 4.5473e-04 - accuracy: 1.0000 - val_loss: 1.4749 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 4.4795e-04 - accuracy: 1.0000 - val_loss: 1.4769 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 4.4075e-04 - accuracy: 1.0000 - val_loss: 1.4800 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 4.3416e-04 - accuracy: 1.0000 - val_loss: 1.4821 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 4.2702e-04 - accuracy: 1.0000 - val_loss: 1.4845 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 4.1954e-04 - accuracy: 1.0000 - val_loss: 1.4871 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 4.1202e-04 - accuracy: 1.0000 - val_loss: 1.4908 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 4.0461e-04 - accuracy: 1.0000 - val_loss: 1.4935 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.9670e-04 - accuracy: 1.0000 - val_loss: 1.4961 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.8976e-04 - accuracy: 1.0000 - val_loss: 1.5001 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.8143e-04 - accuracy: 1.0000 - val_loss: 1.5031 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.7346e-04 - accuracy: 1.0000 - val_loss: 1.5056 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.6558e-04 - accuracy: 1.0000 - val_loss: 1.5093 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.5757e-04 - accuracy: 1.0000 - val_loss: 1.5137 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 128/500\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 3.4612e-04 - accuracy: 1.0000\n",
            "Epoch 128: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.4954e-04 - accuracy: 1.0000 - val_loss: 1.5165 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.4114e-04 - accuracy: 1.0000 - val_loss: 1.5169 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.4031e-04 - accuracy: 1.0000 - val_loss: 1.5173 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.3942e-04 - accuracy: 1.0000 - val_loss: 1.5177 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.3856e-04 - accuracy: 1.0000 - val_loss: 1.5181 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.3761e-04 - accuracy: 1.0000 - val_loss: 1.5184 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.3663e-04 - accuracy: 1.0000 - val_loss: 1.5191 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.3567e-04 - accuracy: 1.0000 - val_loss: 1.5194 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.3458e-04 - accuracy: 1.0000 - val_loss: 1.5199 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.3351e-04 - accuracy: 1.0000 - val_loss: 1.5204 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.3244e-04 - accuracy: 1.0000 - val_loss: 1.5211 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.3125e-04 - accuracy: 1.0000 - val_loss: 1.5214 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.2999e-04 - accuracy: 1.0000 - val_loss: 1.5220 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.2871e-04 - accuracy: 1.0000 - val_loss: 1.5226 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.2741e-04 - accuracy: 1.0000 - val_loss: 1.5232 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.2606e-04 - accuracy: 1.0000 - val_loss: 1.5238 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.2461e-04 - accuracy: 1.0000 - val_loss: 1.5245 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.2321e-04 - accuracy: 1.0000 - val_loss: 1.5251 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.2172e-04 - accuracy: 1.0000 - val_loss: 1.5263 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.2015e-04 - accuracy: 1.0000 - val_loss: 1.5266 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.1850e-04 - accuracy: 1.0000 - val_loss: 1.5274 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 3.1688e-04 - accuracy: 1.0000 - val_loss: 1.5282 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.1509e-04 - accuracy: 1.0000 - val_loss: 1.5291 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.1341e-04 - accuracy: 1.0000 - val_loss: 1.5298 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 3.1164e-04 - accuracy: 1.0000 - val_loss: 1.5309 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.0970e-04 - accuracy: 1.0000 - val_loss: 1.5318 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.0781e-04 - accuracy: 1.0000 - val_loss: 1.5328 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.0587e-04 - accuracy: 1.0000 - val_loss: 1.5339 - val_accuracy: 0.7575 - lr: 1.0000e-05\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.0392e-04 - accuracy: 1.0000 - val_loss: 1.5348 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.0181e-04 - accuracy: 1.0000 - val_loss: 1.5358 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.9970e-04 - accuracy: 1.0000 - val_loss: 1.5368 - val_accuracy: 0.7588 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbca3a08580>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_9.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hnjyza7-EP_",
        "outputId": "027e04ff-640b-4bf7-8dd4-89c5a750048e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 4ms/step - loss: 1.0040 - accuracy: 0.7663\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0040321350097656, 0.7662500143051147]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=tf.round(model_9.predict(x_test))\n",
        "preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRSsknia-RE2",
        "outputId": "af032861-8bca-4699-fb92-add80a3838ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXVRE825-e5z",
        "outputId": "e4b5e0b0-085c-4a95-ba26-a6573720b3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_11=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=3,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(64),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "dYNsZe4M-klC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_11.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "model_11.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=100,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX1Dapig_AN-",
        "outputId": "90be8740-d752-4053-e935-35faaadd6398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 10s 25ms/step - loss: 0.6937 - accuracy: 0.4959 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6933 - accuracy: 0.5041 - val_loss: 0.6933 - val_accuracy: 0.4737 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.5041 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6928 - accuracy: 0.5122 - val_loss: 0.6910 - val_accuracy: 0.5200 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.5203 - val_loss: 0.6946 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6893 - accuracy: 0.5350 - val_loss: 0.6984 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6869 - accuracy: 0.5426 - val_loss: 0.6923 - val_accuracy: 0.5312 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6801 - accuracy: 0.5582 - val_loss: 0.6850 - val_accuracy: 0.5575 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6746 - accuracy: 0.5673 - val_loss: 0.6813 - val_accuracy: 0.5675 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6671 - accuracy: 0.5798 - val_loss: 0.6814 - val_accuracy: 0.5587 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6675 - accuracy: 0.5779 - val_loss: 0.6795 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6636 - accuracy: 0.5889 - val_loss: 0.6792 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6534 - accuracy: 0.6101 - val_loss: 0.6886 - val_accuracy: 0.5575 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6478 - accuracy: 0.6095 - val_loss: 0.6765 - val_accuracy: 0.5875 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6385 - accuracy: 0.6248 - val_loss: 0.6812 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6298 - accuracy: 0.6358 - val_loss: 0.6753 - val_accuracy: 0.5600 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6294 - accuracy: 0.6333 - val_loss: 0.6558 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6082 - accuracy: 0.6586 - val_loss: 0.6713 - val_accuracy: 0.5950 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6026 - accuracy: 0.6702 - val_loss: 0.6440 - val_accuracy: 0.6212 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5789 - accuracy: 0.6896 - val_loss: 0.6545 - val_accuracy: 0.6037 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.5639 - accuracy: 0.6893 - val_loss: 0.6697 - val_accuracy: 0.6225 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.5468 - accuracy: 0.7081 - val_loss: 0.6552 - val_accuracy: 0.6338 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5229 - accuracy: 0.7281 - val_loss: 0.6677 - val_accuracy: 0.6237 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5004 - accuracy: 0.7450 - val_loss: 0.6770 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4888 - accuracy: 0.7572 - val_loss: 0.6702 - val_accuracy: 0.6363 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4458 - accuracy: 0.7791 - val_loss: 0.6910 - val_accuracy: 0.6675 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4188 - accuracy: 0.7957 - val_loss: 0.6593 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3895 - accuracy: 0.8116 - val_loss: 0.6978 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3728 - accuracy: 0.8242 - val_loss: 0.7068 - val_accuracy: 0.6862 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3304 - accuracy: 0.8492 - val_loss: 0.7593 - val_accuracy: 0.6850 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3182 - accuracy: 0.8498 - val_loss: 0.7160 - val_accuracy: 0.7038 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.2830 - accuracy: 0.8830 - val_loss: 0.7439 - val_accuracy: 0.7013 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.2605 - accuracy: 0.8845 - val_loss: 0.8381 - val_accuracy: 0.6938 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.2355 - accuracy: 0.9027 - val_loss: 0.8346 - val_accuracy: 0.7038 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.1993 - accuracy: 0.9183 - val_loss: 0.9587 - val_accuracy: 0.7163 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.1905 - accuracy: 0.9237 - val_loss: 0.9608 - val_accuracy: 0.6850 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.1674 - accuracy: 0.9327 - val_loss: 1.0307 - val_accuracy: 0.7125 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.1495 - accuracy: 0.9415 - val_loss: 1.0004 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.1264 - accuracy: 0.9512 - val_loss: 1.0767 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0937 - accuracy: 0.9684 - val_loss: 1.1835 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0870 - accuracy: 0.9675 - val_loss: 1.3293 - val_accuracy: 0.7125 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.1034 - accuracy: 0.9650 - val_loss: 1.2205 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.1115 - accuracy: 0.9653 - val_loss: 1.1541 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0643 - accuracy: 0.9815 - val_loss: 1.3331 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0518 - accuracy: 0.9847 - val_loss: 1.3680 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0812 - accuracy: 0.9743 - val_loss: 1.4684 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0860 - accuracy: 0.9693 - val_loss: 1.3015 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0473 - accuracy: 0.9840 - val_loss: 1.4007 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0238 - accuracy: 0.9937 - val_loss: 1.4295 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0348 - accuracy: 0.9897 - val_loss: 1.6390 - val_accuracy: 0.7163 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0828 - accuracy: 0.9731 - val_loss: 1.3783 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0586 - accuracy: 0.9800 - val_loss: 1.5764 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0658 - accuracy: 0.9781 - val_loss: 1.5582 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0293 - accuracy: 0.9937 - val_loss: 1.5346 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 1.6252 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 1.6773 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 1.6578 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7276 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7722 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8073 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 8.2583e-04 - accuracy: 1.0000 - val_loss: 1.8361 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 6.9198e-04 - accuracy: 1.0000 - val_loss: 1.8575 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 6.1133e-04 - accuracy: 1.0000 - val_loss: 1.8903 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 5.3120e-04 - accuracy: 1.0000 - val_loss: 1.9109 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 4.9406e-04 - accuracy: 1.0000 - val_loss: 1.9408 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 4.3381e-04 - accuracy: 1.0000 - val_loss: 1.9575 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 3.8362e-04 - accuracy: 1.0000 - val_loss: 1.9796 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 3.5198e-04 - accuracy: 1.0000 - val_loss: 1.9956 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 3.2913e-04 - accuracy: 1.0000 - val_loss: 2.0104 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 2.9195e-04 - accuracy: 1.0000 - val_loss: 2.0365 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 2.6198e-04 - accuracy: 1.0000 - val_loss: 2.0555 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 2.3757e-04 - accuracy: 1.0000 - val_loss: 2.0685 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 2.1850e-04 - accuracy: 1.0000 - val_loss: 2.0858 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 2.0120e-04 - accuracy: 1.0000 - val_loss: 2.1033 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.8443e-04 - accuracy: 1.0000 - val_loss: 2.1174 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.7123e-04 - accuracy: 1.0000 - val_loss: 2.1300 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.5901e-04 - accuracy: 1.0000 - val_loss: 2.1459 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 79/500\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.4777e-04 - accuracy: 1.0000\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 1.4645e-04 - accuracy: 1.0000 - val_loss: 2.1598 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 1.3517e-04 - accuracy: 1.0000 - val_loss: 2.1619 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.3402e-04 - accuracy: 1.0000 - val_loss: 2.1637 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.3286e-04 - accuracy: 1.0000 - val_loss: 2.1655 - val_accuracy: 0.7387 - lr: 1.0000e-04\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.3156e-04 - accuracy: 1.0000 - val_loss: 2.1678 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.3045e-04 - accuracy: 1.0000 - val_loss: 2.1697 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.2926e-04 - accuracy: 1.0000 - val_loss: 2.1718 - val_accuracy: 0.7387 - lr: 1.0000e-04\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.2810e-04 - accuracy: 1.0000 - val_loss: 2.1738 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.2670e-04 - accuracy: 1.0000 - val_loss: 2.1755 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.2557e-04 - accuracy: 1.0000 - val_loss: 2.1776 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.2406e-04 - accuracy: 1.0000 - val_loss: 2.1802 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.2290e-04 - accuracy: 1.0000 - val_loss: 2.1823 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.2133e-04 - accuracy: 1.0000 - val_loss: 2.1847 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.1982e-04 - accuracy: 1.0000 - val_loss: 2.1868 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.1845e-04 - accuracy: 1.0000 - val_loss: 2.1896 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.1688e-04 - accuracy: 1.0000 - val_loss: 2.1922 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.1534e-04 - accuracy: 1.0000 - val_loss: 2.1946 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.1379e-04 - accuracy: 1.0000 - val_loss: 2.1975 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.1224e-04 - accuracy: 1.0000 - val_loss: 2.2005 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.1054e-04 - accuracy: 1.0000 - val_loss: 2.2034 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.0885e-04 - accuracy: 1.0000 - val_loss: 2.2069 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.0710e-04 - accuracy: 1.0000 - val_loss: 2.2099 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.0519e-04 - accuracy: 1.0000 - val_loss: 2.2131 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.0353e-04 - accuracy: 1.0000 - val_loss: 2.2167 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.0168e-04 - accuracy: 1.0000 - val_loss: 2.2200 - val_accuracy: 0.7387 - lr: 1.0000e-04\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 9.9742e-05 - accuracy: 1.0000 - val_loss: 2.2241 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 9.8003e-05 - accuracy: 1.0000 - val_loss: 2.2281 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 9.5944e-05 - accuracy: 1.0000 - val_loss: 2.2319 - val_accuracy: 0.7387 - lr: 1.0000e-04\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 9.3920e-05 - accuracy: 1.0000 - val_loss: 2.2355 - val_accuracy: 0.7387 - lr: 1.0000e-04\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 9.2061e-05 - accuracy: 1.0000 - val_loss: 2.2408 - val_accuracy: 0.7387 - lr: 1.0000e-04\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 9.0093e-05 - accuracy: 1.0000 - val_loss: 2.2441 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 8.8327e-05 - accuracy: 1.0000 - val_loss: 2.2486 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 8.6042e-05 - accuracy: 1.0000 - val_loss: 2.2539 - val_accuracy: 0.7400 - lr: 1.0000e-04\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 8.3751e-05 - accuracy: 1.0000 - val_loss: 2.2579 - val_accuracy: 0.7387 - lr: 1.0000e-04\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 8.1958e-05 - accuracy: 1.0000 - val_loss: 2.2631 - val_accuracy: 0.7387 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 8.0546e-05 - accuracy: 1.0000\n",
            "Epoch 114: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 7.9885e-05 - accuracy: 1.0000 - val_loss: 2.2683 - val_accuracy: 0.7387 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 7.7762e-05 - accuracy: 1.0000 - val_loss: 2.2688 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.7525e-05 - accuracy: 1.0000 - val_loss: 2.2694 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.7298e-05 - accuracy: 1.0000 - val_loss: 2.2698 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.7075e-05 - accuracy: 1.0000 - val_loss: 2.2705 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.6841e-05 - accuracy: 1.0000 - val_loss: 2.2711 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.6577e-05 - accuracy: 1.0000 - val_loss: 2.2716 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 7.6321e-05 - accuracy: 1.0000 - val_loss: 2.2723 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.6029e-05 - accuracy: 1.0000 - val_loss: 2.2731 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.5759e-05 - accuracy: 1.0000 - val_loss: 2.2737 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.5467e-05 - accuracy: 1.0000 - val_loss: 2.2746 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.5145e-05 - accuracy: 1.0000 - val_loss: 2.2754 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 7.4835e-05 - accuracy: 1.0000 - val_loss: 2.2762 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.4498e-05 - accuracy: 1.0000 - val_loss: 2.2771 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.4156e-05 - accuracy: 1.0000 - val_loss: 2.2780 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 7.3789e-05 - accuracy: 1.0000 - val_loss: 2.2790 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.3420e-05 - accuracy: 1.0000 - val_loss: 2.2799 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 7.2964e-05 - accuracy: 1.0000 - val_loss: 2.2810 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 7.2635e-05 - accuracy: 1.0000 - val_loss: 2.2823 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 7.2164e-05 - accuracy: 1.0000 - val_loss: 2.2831 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 7.1744e-05 - accuracy: 1.0000 - val_loss: 2.2846 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 7.1315e-05 - accuracy: 1.0000 - val_loss: 2.2856 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 7.0821e-05 - accuracy: 1.0000 - val_loss: 2.2871 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 7.0360e-05 - accuracy: 1.0000 - val_loss: 2.2885 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 6.9818e-05 - accuracy: 1.0000 - val_loss: 2.2900 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 6.9363e-05 - accuracy: 1.0000 - val_loss: 2.2915 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 6.8788e-05 - accuracy: 1.0000 - val_loss: 2.2933 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 6.8257e-05 - accuracy: 1.0000 - val_loss: 2.2945 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 6.7656e-05 - accuracy: 1.0000 - val_loss: 2.2961 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 6.7094e-05 - accuracy: 1.0000 - val_loss: 2.2976 - val_accuracy: 0.7375 - lr: 1.0000e-05\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 6.6435e-05 - accuracy: 1.0000 - val_loss: 2.2993 - val_accuracy: 0.7375 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbca5f84160>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def create_model_checkpoint(model_name,save_path=\"model_experiments\"):\n",
        "  return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path,model_name),\n",
        "                                            verbose=0,\n",
        "                                            save_best_only=True)"
      ],
      "metadata": {
        "id": "Hh1D65EvLq4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_10=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=3,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(64,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.GRU(16),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_10.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "model_10.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=80,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])\n",
        "                       #create_model_checkpoint(model_name=\"model_10\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rNPQFSGvaWeI",
        "outputId": "57d74aa0-ead4-4740-8d0e-3767f76de482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 12s 39ms/step - loss: 0.6934 - accuracy: 0.4937 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6933 - accuracy: 0.5047 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6933 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6933 - accuracy: 0.4947 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6933 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.4872 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6933 - accuracy: 0.5047 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 36/500\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5055\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5047"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-9cd717ba0661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                  metrics=[\"accuracy\"])\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m model_10.fit(x_train,y_train,\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1446\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ-gGrdIarHP",
        "outputId": "c0abde6d-13bd-4d96-91b5-c4274f4b2f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.4812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6934122443199158, 0.48124998807907104]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_SEgYitS6lU",
        "outputId": "90ede88e-2ecd-4dbe-8e8b-4ed82a9b3a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_12=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=3,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(64,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.LSTM(8),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_12.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "model_12.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=80,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUumEblRexh7",
        "outputId": "b5f5b961-bebf-4c71-c164-1fcbb3a00356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 18s 34ms/step - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6933 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6924 - accuracy: 0.5141 - val_loss: 0.6904 - val_accuracy: 0.5200 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6882 - accuracy: 0.5375 - val_loss: 0.6840 - val_accuracy: 0.5450 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6836 - accuracy: 0.5519 - val_loss: 0.6810 - val_accuracy: 0.5487 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6811 - accuracy: 0.5544 - val_loss: 0.6767 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6776 - accuracy: 0.5645 - val_loss: 0.6839 - val_accuracy: 0.5450 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.6737 - accuracy: 0.5638 - val_loss: 0.6864 - val_accuracy: 0.5450 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.6724 - accuracy: 0.5757 - val_loss: 0.6860 - val_accuracy: 0.5400 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6703 - accuracy: 0.5676 - val_loss: 0.6698 - val_accuracy: 0.5763 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6678 - accuracy: 0.5776 - val_loss: 0.6721 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6661 - accuracy: 0.5851 - val_loss: 0.6699 - val_accuracy: 0.5650 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6625 - accuracy: 0.5904 - val_loss: 0.6704 - val_accuracy: 0.5763 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6602 - accuracy: 0.5892 - val_loss: 0.6586 - val_accuracy: 0.5825 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6535 - accuracy: 0.6008 - val_loss: 0.6487 - val_accuracy: 0.5925 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6444 - accuracy: 0.6176 - val_loss: 0.6429 - val_accuracy: 0.6087 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6340 - accuracy: 0.6252 - val_loss: 0.6269 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.6329 - accuracy: 0.6227 - val_loss: 0.6265 - val_accuracy: 0.6475 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 0.6186 - accuracy: 0.6305 - val_loss: 0.6406 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.6133 - accuracy: 0.6380 - val_loss: 0.6297 - val_accuracy: 0.6425 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6057 - accuracy: 0.6589 - val_loss: 0.6144 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.5978 - accuracy: 0.6580 - val_loss: 0.6321 - val_accuracy: 0.6463 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.5961 - accuracy: 0.6630 - val_loss: 0.6113 - val_accuracy: 0.6237 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 0.5838 - accuracy: 0.6752 - val_loss: 0.6256 - val_accuracy: 0.6400 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.5746 - accuracy: 0.6793 - val_loss: 0.6198 - val_accuracy: 0.6363 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.5685 - accuracy: 0.6859 - val_loss: 0.6107 - val_accuracy: 0.6488 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.5512 - accuracy: 0.7015 - val_loss: 0.6343 - val_accuracy: 0.6488 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5349 - accuracy: 0.7109 - val_loss: 0.6111 - val_accuracy: 0.6725 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5282 - accuracy: 0.7200 - val_loss: 0.6143 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5063 - accuracy: 0.7359 - val_loss: 0.6005 - val_accuracy: 0.6675 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4960 - accuracy: 0.7409 - val_loss: 0.5978 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4670 - accuracy: 0.7672 - val_loss: 0.6144 - val_accuracy: 0.6612 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4405 - accuracy: 0.7782 - val_loss: 0.6526 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4380 - accuracy: 0.7800 - val_loss: 0.6380 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4382 - accuracy: 0.7875 - val_loss: 0.6498 - val_accuracy: 0.6862 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4062 - accuracy: 0.8004 - val_loss: 0.6570 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3913 - accuracy: 0.8107 - val_loss: 0.6291 - val_accuracy: 0.6862 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3526 - accuracy: 0.8285 - val_loss: 0.6389 - val_accuracy: 0.6762 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3428 - accuracy: 0.8411 - val_loss: 0.7199 - val_accuracy: 0.7013 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3240 - accuracy: 0.8514 - val_loss: 0.7177 - val_accuracy: 0.6975 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3334 - accuracy: 0.8526 - val_loss: 0.7076 - val_accuracy: 0.6825 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3387 - accuracy: 0.8457 - val_loss: 0.6975 - val_accuracy: 0.7063 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2747 - accuracy: 0.8817 - val_loss: 0.7075 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2424 - accuracy: 0.9011 - val_loss: 0.7383 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2372 - accuracy: 0.9061 - val_loss: 0.7127 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2210 - accuracy: 0.9124 - val_loss: 0.8377 - val_accuracy: 0.7050 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1988 - accuracy: 0.9243 - val_loss: 0.8199 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2075 - accuracy: 0.9199 - val_loss: 0.7826 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1811 - accuracy: 0.9293 - val_loss: 0.7847 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1673 - accuracy: 0.9393 - val_loss: 0.8820 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1721 - accuracy: 0.9337 - val_loss: 0.8378 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1503 - accuracy: 0.9465 - val_loss: 0.8081 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1216 - accuracy: 0.9578 - val_loss: 0.8261 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1265 - accuracy: 0.9540 - val_loss: 0.8505 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1402 - accuracy: 0.9509 - val_loss: 0.8895 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1098 - accuracy: 0.9618 - val_loss: 0.9708 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1142 - accuracy: 0.9612 - val_loss: 0.9309 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0822 - accuracy: 0.9753 - val_loss: 0.9345 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1240 - accuracy: 0.9584 - val_loss: 0.9827 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1234 - accuracy: 0.9590 - val_loss: 0.9329 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1302 - accuracy: 0.9587 - val_loss: 0.8745 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0892 - accuracy: 0.9718 - val_loss: 1.0030 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0763 - accuracy: 0.9756 - val_loss: 0.9034 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0598 - accuracy: 0.9831 - val_loss: 0.9606 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1103 - accuracy: 0.9659 - val_loss: 0.9695 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0805 - accuracy: 0.9743 - val_loss: 1.0227 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0799 - accuracy: 0.9750 - val_loss: 1.0253 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0597 - accuracy: 0.9825 - val_loss: 0.9415 - val_accuracy: 0.7763 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0459 - accuracy: 0.9869 - val_loss: 1.0846 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0394 - accuracy: 0.9881 - val_loss: 1.0237 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0602 - accuracy: 0.9800 - val_loss: 1.0885 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0465 - accuracy: 0.9862 - val_loss: 1.1046 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1138 - accuracy: 0.9643 - val_loss: 0.8532 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0898 - accuracy: 0.9684 - val_loss: 0.9631 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0467 - accuracy: 0.9850 - val_loss: 0.9662 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 1.0547 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0465 - accuracy: 0.9856 - val_loss: 1.0531 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0706 - accuracy: 0.9762 - val_loss: 0.9600 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0494 - accuracy: 0.9856 - val_loss: 1.0488 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0465 - accuracy: 0.9844 - val_loss: 1.0939 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0365 - accuracy: 0.9881 - val_loss: 1.0707 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0623 - accuracy: 0.9784 - val_loss: 1.0165 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0752 - accuracy: 0.9747 - val_loss: 0.9760 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0424 - accuracy: 0.9856 - val_loss: 1.0504 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0430 - accuracy: 0.9840 - val_loss: 0.9954 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0777 - accuracy: 0.9747 - val_loss: 1.0548 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.0498 - accuracy: 0.9837 - val_loss: 1.1015 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0287 - accuracy: 0.9894 - val_loss: 1.0647 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 1.0835 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0239 - accuracy: 0.9912 - val_loss: 1.1775 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0624 - accuracy: 0.9775 - val_loss: 1.1185 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0322 - accuracy: 0.9890 - val_loss: 1.1376 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 1.1170 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0205 - accuracy: 0.9925 - val_loss: 1.1746 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0197 - accuracy: 0.9925 - val_loss: 1.1939 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0192 - accuracy: 0.9925 - val_loss: 1.2078 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0190 - accuracy: 0.9925 - val_loss: 1.2241 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0193 - accuracy: 0.9925 - val_loss: 1.2142 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0197 - accuracy: 0.9925 - val_loss: 1.2212 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0192 - accuracy: 0.9925 - val_loss: 1.2385 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0188 - accuracy: 0.9925 - val_loss: 1.2562 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0185 - accuracy: 0.9925 - val_loss: 1.2654 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9925\n",
            "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0185 - accuracy: 0.9925 - val_loss: 1.2664 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0184 - accuracy: 0.9925 - val_loss: 1.2671 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0184 - accuracy: 0.9925 - val_loss: 1.2680 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0184 - accuracy: 0.9925 - val_loss: 1.2679 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0184 - accuracy: 0.9925 - val_loss: 1.2681 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 1.2686 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 1.2689 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 1.2698 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 1.2700 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 1.2710 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 1.2717 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 1.2726 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 1.2726 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 1.2733 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 1.2740 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 1.2749 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 1.2755 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 1.2765 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 1.2773 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 1.2779 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 1.2787 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 1.2803 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 1.2804 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 1.2820 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 1.2824 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 1.2841 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 1.2845 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 1.2861 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0181 - accuracy: 0.9925 - val_loss: 1.2874 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0181 - accuracy: 0.9925 - val_loss: 1.2887 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0181 - accuracy: 0.9925 - val_loss: 1.2892 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0181 - accuracy: 0.9922 - val_loss: 1.2909 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0181 - accuracy: 0.9925 - val_loss: 1.2920 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 1.2930 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 1.2944 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 143/500\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9948\n",
            "Epoch 143: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 1.2963 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 1.2964 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 1.2964 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 1.2966 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 1.2967 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 1.2968 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 1.2970 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 1.2971 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 1.2973 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0181 - accuracy: 0.9962 - val_loss: 1.2975 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0181 - accuracy: 0.9962 - val_loss: 1.2976 - val_accuracy: 0.7575 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c0e090f10>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_12.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2okCclaRSVN",
        "outputId": "13bbeff8-955c-4df0-ee78-618a08b31fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 6ms/step - loss: 0.9415 - accuracy: 0.7763\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9415484666824341, 0.7762500047683716]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(model=model_12,filepath=\"model_12\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXVlwwahP8WN",
        "outputId": "36e84f6d-56d0-468b-f389-dd311e6ec406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_51_layer_call_fn, lstm_cell_51_layer_call_and_return_conditional_losses while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_1=tf.keras.models.load_model(\"model_12\")"
      ],
      "metadata": {
        "id": "QyyyTJkjRfXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_1.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vPdsyRRR3jW",
        "outputId": "436fb40a-5c75-4b51-af66-e368ac234888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 2s 6ms/step - loss: 0.9415 - accuracy: 0.7763\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9415484666824341, 0.7762500047683716]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_13=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(16,return_sequences=True),\n",
        "    #layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"same\",\n",
        "                  activation=\"sigmoid\"),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"same\",\n",
        "                  activation=\"softmax\"),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=3,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(64,return_sequences=True),\n",
        "    # layers.Conv1D(filters=32,\n",
        "    #               kernel_size=4,\n",
        "    #               padding=\"valid\",\n",
        "    #               activation=\"relu\"),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.LSTM(8,return_sequences=True),\n",
        "    #layers.GlobalAveragePooling1D(),\n",
        "    #layers.Conv1D(filters=16,\n",
        "                  # kernel_size=2,\n",
        "                  # padding=\"same\",\n",
        "                  # activation=\"relu\"),\n",
        "    #layers.GRU(16,return_sequences=True),\n",
        "    layers.LSTM(8),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_13.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "xf21BhwcK_tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_13.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=80,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwvYhDLFUHxa",
        "outputId": "b52db97b-5b7c-414c-ad20-d4ed9369cb28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 17s 44ms/step - loss: 0.6936 - accuracy: 0.4928 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.6933 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 3s 30ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 0.6933 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 4s 36ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 36/500\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5022\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 71/500\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5045\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-04\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-05\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-05\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-05\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-05\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-05\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-05\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-05\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-05\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-05\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c08c250a0>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_14=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(8,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.LSTM(8,return_sequences=True),\n",
        "    layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_14.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model_14.fit(x_train,y_train,\n",
        "            epochs=1000,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=80,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2P7lZt4fJTY",
        "outputId": "88776abf-e2c2-411a-efe1-d8242bad8d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "100/100 [==============================] - 9s 25ms/step - loss: 0.6936 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.4908 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6933 - accuracy: 0.5054 - val_loss: 0.6933 - val_accuracy: 0.4817 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4837 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6930 - val_accuracy: 0.5126 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6933 - val_accuracy: 0.4819 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6931 - accuracy: 0.5052 - val_loss: 0.6929 - val_accuracy: 0.5015 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6927 - accuracy: 0.5129 - val_loss: 0.6919 - val_accuracy: 0.5122 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6921 - accuracy: 0.5132 - val_loss: 0.6904 - val_accuracy: 0.5286 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6913 - accuracy: 0.5167 - val_loss: 0.6904 - val_accuracy: 0.5247 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6908 - accuracy: 0.5132 - val_loss: 0.6890 - val_accuracy: 0.5299 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6902 - accuracy: 0.5145 - val_loss: 0.6904 - val_accuracy: 0.5142 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6895 - accuracy: 0.5172 - val_loss: 0.6911 - val_accuracy: 0.5103 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6886 - accuracy: 0.5222 - val_loss: 0.6975 - val_accuracy: 0.5050 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6885 - accuracy: 0.5202 - val_loss: 0.6879 - val_accuracy: 0.5317 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6871 - accuracy: 0.5265 - val_loss: 0.6875 - val_accuracy: 0.5301 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6855 - accuracy: 0.5251 - val_loss: 0.6887 - val_accuracy: 0.5374 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6854 - accuracy: 0.5278 - val_loss: 0.6897 - val_accuracy: 0.5326 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6849 - accuracy: 0.5356 - val_loss: 0.6857 - val_accuracy: 0.5439 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6835 - accuracy: 0.5352 - val_loss: 0.6861 - val_accuracy: 0.5456 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6826 - accuracy: 0.5411 - val_loss: 0.6923 - val_accuracy: 0.5289 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6815 - accuracy: 0.5438 - val_loss: 0.6825 - val_accuracy: 0.5507 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6812 - accuracy: 0.5479 - val_loss: 0.6816 - val_accuracy: 0.5585 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6787 - accuracy: 0.5566 - val_loss: 0.6937 - val_accuracy: 0.5194 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6784 - accuracy: 0.5521 - val_loss: 0.6837 - val_accuracy: 0.5412 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6788 - accuracy: 0.5491 - val_loss: 0.6843 - val_accuracy: 0.5443 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6764 - accuracy: 0.5503 - val_loss: 0.6809 - val_accuracy: 0.5564 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6751 - accuracy: 0.5526 - val_loss: 0.6780 - val_accuracy: 0.5604 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6750 - accuracy: 0.5529 - val_loss: 0.6818 - val_accuracy: 0.5547 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6730 - accuracy: 0.5514 - val_loss: 0.6796 - val_accuracy: 0.5660 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6731 - accuracy: 0.5622 - val_loss: 0.6752 - val_accuracy: 0.5649 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6708 - accuracy: 0.5624 - val_loss: 0.6737 - val_accuracy: 0.5689 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6683 - accuracy: 0.5674 - val_loss: 0.6720 - val_accuracy: 0.5628 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6692 - accuracy: 0.5582 - val_loss: 0.6735 - val_accuracy: 0.5651 - lr: 0.0010\n",
            "Epoch 35/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6673 - accuracy: 0.5621 - val_loss: 0.6748 - val_accuracy: 0.5633 - lr: 0.0010\n",
            "Epoch 36/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6653 - accuracy: 0.5708 - val_loss: 0.6728 - val_accuracy: 0.5664 - lr: 0.0010\n",
            "Epoch 37/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6645 - accuracy: 0.5665 - val_loss: 0.6746 - val_accuracy: 0.5593 - lr: 0.0010\n",
            "Epoch 38/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6646 - accuracy: 0.5627 - val_loss: 0.6696 - val_accuracy: 0.5694 - lr: 0.0010\n",
            "Epoch 39/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6624 - accuracy: 0.5727 - val_loss: 0.6732 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 40/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6612 - accuracy: 0.5745 - val_loss: 0.6679 - val_accuracy: 0.5685 - lr: 0.0010\n",
            "Epoch 41/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6594 - accuracy: 0.5723 - val_loss: 0.6718 - val_accuracy: 0.5726 - lr: 0.0010\n",
            "Epoch 42/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6618 - accuracy: 0.5699 - val_loss: 0.6668 - val_accuracy: 0.5747 - lr: 0.0010\n",
            "Epoch 43/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6590 - accuracy: 0.5702 - val_loss: 0.6699 - val_accuracy: 0.5679 - lr: 0.0010\n",
            "Epoch 44/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6578 - accuracy: 0.5771 - val_loss: 0.6687 - val_accuracy: 0.5719 - lr: 0.0010\n",
            "Epoch 45/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6559 - accuracy: 0.5758 - val_loss: 0.6661 - val_accuracy: 0.5771 - lr: 0.0010\n",
            "Epoch 46/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6570 - accuracy: 0.5792 - val_loss: 0.6693 - val_accuracy: 0.5676 - lr: 0.0010\n",
            "Epoch 47/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6571 - accuracy: 0.5738 - val_loss: 0.6676 - val_accuracy: 0.5676 - lr: 0.0010\n",
            "Epoch 48/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6553 - accuracy: 0.5773 - val_loss: 0.6671 - val_accuracy: 0.5688 - lr: 0.0010\n",
            "Epoch 49/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6544 - accuracy: 0.5779 - val_loss: 0.6653 - val_accuracy: 0.5722 - lr: 0.0010\n",
            "Epoch 50/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6538 - accuracy: 0.5793 - val_loss: 0.6616 - val_accuracy: 0.5740 - lr: 0.0010\n",
            "Epoch 51/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6526 - accuracy: 0.5800 - val_loss: 0.6682 - val_accuracy: 0.5664 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6524 - accuracy: 0.5811 - val_loss: 0.6665 - val_accuracy: 0.5694 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6515 - accuracy: 0.5794 - val_loss: 0.6681 - val_accuracy: 0.5735 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6500 - accuracy: 0.5820 - val_loss: 0.6669 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6505 - accuracy: 0.5804 - val_loss: 0.6699 - val_accuracy: 0.5697 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6488 - accuracy: 0.5838 - val_loss: 0.6682 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6482 - accuracy: 0.5855 - val_loss: 0.6713 - val_accuracy: 0.5799 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6483 - accuracy: 0.5861 - val_loss: 0.6644 - val_accuracy: 0.5776 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6460 - accuracy: 0.5924 - val_loss: 0.6635 - val_accuracy: 0.5781 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6474 - accuracy: 0.5893 - val_loss: 0.6672 - val_accuracy: 0.5732 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6452 - accuracy: 0.5874 - val_loss: 0.6725 - val_accuracy: 0.5722 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6437 - accuracy: 0.5941 - val_loss: 0.6728 - val_accuracy: 0.5588 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6435 - accuracy: 0.5983 - val_loss: 0.6630 - val_accuracy: 0.5836 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6421 - accuracy: 0.6025 - val_loss: 0.6677 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6423 - accuracy: 0.5966 - val_loss: 0.6677 - val_accuracy: 0.5818 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6408 - accuracy: 0.6001 - val_loss: 0.6687 - val_accuracy: 0.5792 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6407 - accuracy: 0.5997 - val_loss: 0.6709 - val_accuracy: 0.5682 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6004 - val_loss: 0.6763 - val_accuracy: 0.5764 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6388 - accuracy: 0.6016 - val_loss: 0.6707 - val_accuracy: 0.5732 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6386 - accuracy: 0.6027 - val_loss: 0.6747 - val_accuracy: 0.5619 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6365 - accuracy: 0.6038 - val_loss: 0.6711 - val_accuracy: 0.5706 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6355 - accuracy: 0.6092 - val_loss: 0.6698 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6358 - accuracy: 0.6040 - val_loss: 0.6666 - val_accuracy: 0.5828 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6333 - accuracy: 0.6147 - val_loss: 0.6718 - val_accuracy: 0.5732 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6315 - accuracy: 0.6118 - val_loss: 0.6739 - val_accuracy: 0.5832 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6321 - accuracy: 0.6117 - val_loss: 0.6701 - val_accuracy: 0.5876 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6326 - accuracy: 0.6071 - val_loss: 0.6707 - val_accuracy: 0.5908 - lr: 0.0010\n",
            "Epoch 78/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6292 - accuracy: 0.6140 - val_loss: 0.6744 - val_accuracy: 0.5713 - lr: 0.0010\n",
            "Epoch 79/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6289 - accuracy: 0.6147 - val_loss: 0.6785 - val_accuracy: 0.5790 - lr: 0.0010\n",
            "Epoch 80/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6274 - accuracy: 0.6196 - val_loss: 0.6740 - val_accuracy: 0.5829 - lr: 0.0010\n",
            "Epoch 81/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6266 - accuracy: 0.6159 - val_loss: 0.6744 - val_accuracy: 0.5728 - lr: 0.0010\n",
            "Epoch 82/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6255 - accuracy: 0.6196 - val_loss: 0.6691 - val_accuracy: 0.5935 - lr: 0.0010\n",
            "Epoch 83/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6245 - accuracy: 0.6218 - val_loss: 0.6744 - val_accuracy: 0.5767 - lr: 0.0010\n",
            "Epoch 84/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6240 - accuracy: 0.6249 - val_loss: 0.6728 - val_accuracy: 0.6004 - lr: 0.0010\n",
            "Epoch 85/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6215 - accuracy: 0.6236 - val_loss: 0.6708 - val_accuracy: 0.6014 - lr: 0.0010\n",
            "Epoch 86/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6200 - accuracy: 0.6249 - val_loss: 0.6685 - val_accuracy: 0.6006 - lr: 0.0010\n",
            "Epoch 87/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6195 - accuracy: 0.6292 - val_loss: 0.6723 - val_accuracy: 0.5989 - lr: 0.0010\n",
            "Epoch 88/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6166 - accuracy: 0.6265 - val_loss: 0.6754 - val_accuracy: 0.5975 - lr: 0.0010\n",
            "Epoch 89/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6153 - accuracy: 0.6336 - val_loss: 0.6775 - val_accuracy: 0.5943 - lr: 0.0010\n",
            "Epoch 90/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6153 - accuracy: 0.6294 - val_loss: 0.6755 - val_accuracy: 0.5929 - lr: 0.0010\n",
            "Epoch 91/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6115 - accuracy: 0.6357 - val_loss: 0.6831 - val_accuracy: 0.5865 - lr: 0.0010\n",
            "Epoch 92/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6122 - accuracy: 0.6360 - val_loss: 0.6750 - val_accuracy: 0.6014 - lr: 0.0010\n",
            "Epoch 93/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6108 - accuracy: 0.6401 - val_loss: 0.6738 - val_accuracy: 0.6003 - lr: 0.0010\n",
            "Epoch 94/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6069 - accuracy: 0.6411 - val_loss: 0.6707 - val_accuracy: 0.6028 - lr: 0.0010\n",
            "Epoch 95/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6064 - accuracy: 0.6411 - val_loss: 0.6726 - val_accuracy: 0.5829 - lr: 0.0010\n",
            "Epoch 96/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6092 - accuracy: 0.6393 - val_loss: 0.6694 - val_accuracy: 0.6018 - lr: 0.0010\n",
            "Epoch 97/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6023 - accuracy: 0.6464 - val_loss: 0.6836 - val_accuracy: 0.5829 - lr: 0.0010\n",
            "Epoch 98/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6019 - accuracy: 0.6445 - val_loss: 0.6727 - val_accuracy: 0.5986 - lr: 0.0010\n",
            "Epoch 99/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6001 - accuracy: 0.6494 - val_loss: 0.6780 - val_accuracy: 0.5983 - lr: 0.0010\n",
            "Epoch 100/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5968 - accuracy: 0.6511 - val_loss: 0.6920 - val_accuracy: 0.5910 - lr: 0.0010\n",
            "Epoch 101/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5980 - accuracy: 0.6507 - val_loss: 0.6823 - val_accuracy: 0.5999 - lr: 0.0010\n",
            "Epoch 102/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5950 - accuracy: 0.6551 - val_loss: 0.6886 - val_accuracy: 0.5946 - lr: 0.0010\n",
            "Epoch 103/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5932 - accuracy: 0.6540 - val_loss: 0.6812 - val_accuracy: 0.6011 - lr: 0.0010\n",
            "Epoch 104/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5897 - accuracy: 0.6595 - val_loss: 0.6781 - val_accuracy: 0.5961 - lr: 0.0010\n",
            "Epoch 105/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5912 - accuracy: 0.6564 - val_loss: 0.6915 - val_accuracy: 0.5994 - lr: 0.0010\n",
            "Epoch 106/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5902 - accuracy: 0.6601 - val_loss: 0.6812 - val_accuracy: 0.6125 - lr: 0.0010\n",
            "Epoch 107/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5873 - accuracy: 0.6583 - val_loss: 0.6760 - val_accuracy: 0.5908 - lr: 0.0010\n",
            "Epoch 108/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5838 - accuracy: 0.6637 - val_loss: 0.6846 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "Epoch 109/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5829 - accuracy: 0.6621 - val_loss: 0.6890 - val_accuracy: 0.6096 - lr: 0.0010\n",
            "Epoch 110/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5804 - accuracy: 0.6645 - val_loss: 0.6774 - val_accuracy: 0.5999 - lr: 0.0010\n",
            "Epoch 111/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5795 - accuracy: 0.6691 - val_loss: 0.6874 - val_accuracy: 0.6075 - lr: 0.0010\n",
            "Epoch 112/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5758 - accuracy: 0.6688 - val_loss: 0.6902 - val_accuracy: 0.6003 - lr: 0.0010\n",
            "Epoch 113/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5776 - accuracy: 0.6671 - val_loss: 0.6795 - val_accuracy: 0.6121 - lr: 0.0010\n",
            "Epoch 114/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5740 - accuracy: 0.6701 - val_loss: 0.6913 - val_accuracy: 0.6079 - lr: 0.0010\n",
            "Epoch 115/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5736 - accuracy: 0.6679 - val_loss: 0.6962 - val_accuracy: 0.6026 - lr: 0.0010\n",
            "Epoch 116/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5728 - accuracy: 0.6741 - val_loss: 0.6728 - val_accuracy: 0.6118 - lr: 0.0010\n",
            "Epoch 117/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5732 - accuracy: 0.6741 - val_loss: 0.6874 - val_accuracy: 0.6085 - lr: 0.0010\n",
            "Epoch 118/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5683 - accuracy: 0.6764 - val_loss: 0.6858 - val_accuracy: 0.6144 - lr: 0.0010\n",
            "Epoch 119/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5670 - accuracy: 0.6749 - val_loss: 0.6840 - val_accuracy: 0.6058 - lr: 0.0010\n",
            "Epoch 120/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5659 - accuracy: 0.6783 - val_loss: 0.6929 - val_accuracy: 0.6051 - lr: 0.0010\n",
            "Epoch 121/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5641 - accuracy: 0.6790 - val_loss: 0.6898 - val_accuracy: 0.6153 - lr: 0.0010\n",
            "Epoch 122/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5635 - accuracy: 0.6813 - val_loss: 0.6872 - val_accuracy: 0.6179 - lr: 0.0010\n",
            "Epoch 123/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5613 - accuracy: 0.6828 - val_loss: 0.6906 - val_accuracy: 0.6115 - lr: 0.0010\n",
            "Epoch 124/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5587 - accuracy: 0.6812 - val_loss: 0.6981 - val_accuracy: 0.6071 - lr: 0.0010\n",
            "Epoch 125/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5575 - accuracy: 0.6848 - val_loss: 0.6897 - val_accuracy: 0.6210 - lr: 0.0010\n",
            "Epoch 126/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5562 - accuracy: 0.6849 - val_loss: 0.6987 - val_accuracy: 0.6069 - lr: 0.0010\n",
            "Epoch 127/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5519 - accuracy: 0.6880 - val_loss: 0.7027 - val_accuracy: 0.6140 - lr: 0.0010\n",
            "Epoch 128/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5551 - accuracy: 0.6846 - val_loss: 0.7086 - val_accuracy: 0.6156 - lr: 0.0010\n",
            "Epoch 129/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5528 - accuracy: 0.6869 - val_loss: 0.6951 - val_accuracy: 0.6151 - lr: 0.0010\n",
            "Epoch 130/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5475 - accuracy: 0.6896 - val_loss: 0.6970 - val_accuracy: 0.5969 - lr: 0.0010\n",
            "Epoch 131/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5477 - accuracy: 0.6919 - val_loss: 0.7003 - val_accuracy: 0.6121 - lr: 0.0010\n",
            "Epoch 132/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5452 - accuracy: 0.6895 - val_loss: 0.7110 - val_accuracy: 0.6126 - lr: 0.0010\n",
            "Epoch 133/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5514 - accuracy: 0.6894 - val_loss: 0.7019 - val_accuracy: 0.6158 - lr: 0.0010\n",
            "Epoch 134/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5430 - accuracy: 0.6915 - val_loss: 0.7187 - val_accuracy: 0.6069 - lr: 0.0010\n",
            "Epoch 135/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5413 - accuracy: 0.6939 - val_loss: 0.7091 - val_accuracy: 0.6062 - lr: 0.0010\n",
            "Epoch 136/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5415 - accuracy: 0.6943 - val_loss: 0.7077 - val_accuracy: 0.6118 - lr: 0.0010\n",
            "Epoch 137/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5399 - accuracy: 0.6952 - val_loss: 0.7050 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 138/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5405 - accuracy: 0.6947 - val_loss: 0.7102 - val_accuracy: 0.6133 - lr: 0.0010\n",
            "Epoch 139/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5353 - accuracy: 0.6955 - val_loss: 0.6994 - val_accuracy: 0.6154 - lr: 0.0010\n",
            "Epoch 140/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5345 - accuracy: 0.6982 - val_loss: 0.7132 - val_accuracy: 0.6224 - lr: 0.0010\n",
            "Epoch 141/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5321 - accuracy: 0.7022 - val_loss: 0.7115 - val_accuracy: 0.6168 - lr: 0.0010\n",
            "Epoch 142/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5317 - accuracy: 0.6993 - val_loss: 0.7120 - val_accuracy: 0.6217 - lr: 0.0010\n",
            "Epoch 143/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5303 - accuracy: 0.7022 - val_loss: 0.7080 - val_accuracy: 0.6278 - lr: 0.0010\n",
            "Epoch 144/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5306 - accuracy: 0.7033 - val_loss: 0.6925 - val_accuracy: 0.6192 - lr: 0.0010\n",
            "Epoch 145/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.5268 - accuracy: 0.7009 - val_loss: 0.7139 - val_accuracy: 0.6174 - lr: 0.0010\n",
            "Epoch 146/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5241 - accuracy: 0.7037 - val_loss: 0.7125 - val_accuracy: 0.6156 - lr: 0.0010\n",
            "Epoch 147/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5265 - accuracy: 0.7023 - val_loss: 0.7134 - val_accuracy: 0.6203 - lr: 0.0010\n",
            "Epoch 148/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5202 - accuracy: 0.7072 - val_loss: 0.7138 - val_accuracy: 0.6194 - lr: 0.0010\n",
            "Epoch 149/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5205 - accuracy: 0.7073 - val_loss: 0.7092 - val_accuracy: 0.6214 - lr: 0.0010\n",
            "Epoch 150/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5204 - accuracy: 0.7083 - val_loss: 0.7190 - val_accuracy: 0.6126 - lr: 0.0010\n",
            "Epoch 151/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5176 - accuracy: 0.7078 - val_loss: 0.7138 - val_accuracy: 0.6217 - lr: 0.0010\n",
            "Epoch 152/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5172 - accuracy: 0.7064 - val_loss: 0.7143 - val_accuracy: 0.6246 - lr: 0.0010\n",
            "Epoch 153/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5123 - accuracy: 0.7121 - val_loss: 0.7273 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 154/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5092 - accuracy: 0.7150 - val_loss: 0.7163 - val_accuracy: 0.6333 - lr: 0.0010\n",
            "Epoch 155/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5096 - accuracy: 0.7143 - val_loss: 0.7146 - val_accuracy: 0.6235 - lr: 0.0010\n",
            "Epoch 156/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5141 - accuracy: 0.7104 - val_loss: 0.7197 - val_accuracy: 0.6258 - lr: 0.0010\n",
            "Epoch 157/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5132 - accuracy: 0.7107 - val_loss: 0.7159 - val_accuracy: 0.6338 - lr: 0.0010\n",
            "Epoch 158/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5056 - accuracy: 0.7176 - val_loss: 0.7176 - val_accuracy: 0.6283 - lr: 0.0010\n",
            "Epoch 159/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5026 - accuracy: 0.7158 - val_loss: 0.7149 - val_accuracy: 0.6208 - lr: 0.0010\n",
            "Epoch 160/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5040 - accuracy: 0.7184 - val_loss: 0.7144 - val_accuracy: 0.6272 - lr: 0.0010\n",
            "Epoch 161/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4999 - accuracy: 0.7207 - val_loss: 0.7286 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 162/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5051 - accuracy: 0.7190 - val_loss: 0.7174 - val_accuracy: 0.6290 - lr: 0.0010\n",
            "Epoch 163/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4989 - accuracy: 0.7231 - val_loss: 0.7120 - val_accuracy: 0.6322 - lr: 0.0010\n",
            "Epoch 164/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5017 - accuracy: 0.7189 - val_loss: 0.7270 - val_accuracy: 0.6228 - lr: 0.0010\n",
            "Epoch 165/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4986 - accuracy: 0.7224 - val_loss: 0.7299 - val_accuracy: 0.6294 - lr: 0.0010\n",
            "Epoch 166/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4970 - accuracy: 0.7230 - val_loss: 0.7275 - val_accuracy: 0.6189 - lr: 0.0010\n",
            "Epoch 167/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5002 - accuracy: 0.7186 - val_loss: 0.7264 - val_accuracy: 0.6332 - lr: 0.0010\n",
            "Epoch 168/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4902 - accuracy: 0.7259 - val_loss: 0.7189 - val_accuracy: 0.6371 - lr: 0.0010\n",
            "Epoch 169/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4941 - accuracy: 0.7241 - val_loss: 0.7052 - val_accuracy: 0.6353 - lr: 0.0010\n",
            "Epoch 170/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4931 - accuracy: 0.7247 - val_loss: 0.7300 - val_accuracy: 0.6282 - lr: 0.0010\n",
            "Epoch 171/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4866 - accuracy: 0.7293 - val_loss: 0.7350 - val_accuracy: 0.6338 - lr: 0.0010\n",
            "Epoch 172/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4915 - accuracy: 0.7228 - val_loss: 0.7314 - val_accuracy: 0.6283 - lr: 0.0010\n",
            "Epoch 173/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4854 - accuracy: 0.7298 - val_loss: 0.7255 - val_accuracy: 0.6376 - lr: 0.0010\n",
            "Epoch 174/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4815 - accuracy: 0.7342 - val_loss: 0.7270 - val_accuracy: 0.6336 - lr: 0.0010\n",
            "Epoch 175/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4767 - accuracy: 0.7350 - val_loss: 0.7243 - val_accuracy: 0.6383 - lr: 0.0010\n",
            "Epoch 176/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4814 - accuracy: 0.7313 - val_loss: 0.7258 - val_accuracy: 0.6468 - lr: 0.0010\n",
            "Epoch 177/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4787 - accuracy: 0.7344 - val_loss: 0.7333 - val_accuracy: 0.6343 - lr: 0.0010\n",
            "Epoch 178/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4757 - accuracy: 0.7338 - val_loss: 0.7294 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 179/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4759 - accuracy: 0.7350 - val_loss: 0.7249 - val_accuracy: 0.6271 - lr: 0.0010\n",
            "Epoch 180/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4755 - accuracy: 0.7347 - val_loss: 0.7303 - val_accuracy: 0.6376 - lr: 0.0010\n",
            "Epoch 181/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4715 - accuracy: 0.7382 - val_loss: 0.7495 - val_accuracy: 0.6356 - lr: 0.0010\n",
            "Epoch 182/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4717 - accuracy: 0.7382 - val_loss: 0.7353 - val_accuracy: 0.6374 - lr: 0.0010\n",
            "Epoch 183/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4744 - accuracy: 0.7334 - val_loss: 0.7301 - val_accuracy: 0.6371 - lr: 0.0010\n",
            "Epoch 184/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4706 - accuracy: 0.7398 - val_loss: 0.7396 - val_accuracy: 0.6394 - lr: 0.0010\n",
            "Epoch 185/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4659 - accuracy: 0.7412 - val_loss: 0.7401 - val_accuracy: 0.6376 - lr: 0.0010\n",
            "Epoch 186/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4605 - accuracy: 0.7428 - val_loss: 0.7484 - val_accuracy: 0.6404 - lr: 0.0010\n",
            "Epoch 187/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4727 - accuracy: 0.7358 - val_loss: 0.7445 - val_accuracy: 0.6414 - lr: 0.0010\n",
            "Epoch 188/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4719 - accuracy: 0.7365 - val_loss: 0.7498 - val_accuracy: 0.6329 - lr: 0.0010\n",
            "Epoch 189/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4597 - accuracy: 0.7437 - val_loss: 0.7408 - val_accuracy: 0.6374 - lr: 0.0010\n",
            "Epoch 190/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4638 - accuracy: 0.7421 - val_loss: 0.7540 - val_accuracy: 0.6319 - lr: 0.0010\n",
            "Epoch 191/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4615 - accuracy: 0.7433 - val_loss: 0.7435 - val_accuracy: 0.6358 - lr: 0.0010\n",
            "Epoch 192/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4612 - accuracy: 0.7442 - val_loss: 0.7570 - val_accuracy: 0.6371 - lr: 0.0010\n",
            "Epoch 193/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4577 - accuracy: 0.7458 - val_loss: 0.7300 - val_accuracy: 0.6457 - lr: 0.0010\n",
            "Epoch 194/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4557 - accuracy: 0.7450 - val_loss: 0.7348 - val_accuracy: 0.6468 - lr: 0.0010\n",
            "Epoch 195/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4549 - accuracy: 0.7466 - val_loss: 0.7585 - val_accuracy: 0.6401 - lr: 0.0010\n",
            "Epoch 196/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4545 - accuracy: 0.7479 - val_loss: 0.7306 - val_accuracy: 0.6533 - lr: 0.0010\n",
            "Epoch 197/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4572 - accuracy: 0.7458 - val_loss: 0.7596 - val_accuracy: 0.6414 - lr: 0.0010\n",
            "Epoch 198/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4525 - accuracy: 0.7474 - val_loss: 0.7258 - val_accuracy: 0.6460 - lr: 0.0010\n",
            "Epoch 199/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4530 - accuracy: 0.7482 - val_loss: 0.7684 - val_accuracy: 0.6440 - lr: 0.0010\n",
            "Epoch 200/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4435 - accuracy: 0.7538 - val_loss: 0.7632 - val_accuracy: 0.6446 - lr: 0.0010\n",
            "Epoch 201/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4440 - accuracy: 0.7550 - val_loss: 0.7599 - val_accuracy: 0.6401 - lr: 0.0010\n",
            "Epoch 202/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4497 - accuracy: 0.7500 - val_loss: 0.7719 - val_accuracy: 0.6497 - lr: 0.0010\n",
            "Epoch 203/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4453 - accuracy: 0.7516 - val_loss: 0.7683 - val_accuracy: 0.6318 - lr: 0.0010\n",
            "Epoch 204/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4551 - accuracy: 0.7474 - val_loss: 0.7838 - val_accuracy: 0.6411 - lr: 0.0010\n",
            "Epoch 205/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4490 - accuracy: 0.7530 - val_loss: 0.8017 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 206/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4527 - accuracy: 0.7481 - val_loss: 0.7875 - val_accuracy: 0.6343 - lr: 0.0010\n",
            "Epoch 207/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4491 - accuracy: 0.7510 - val_loss: 0.7636 - val_accuracy: 0.6485 - lr: 0.0010\n",
            "Epoch 208/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4429 - accuracy: 0.7506 - val_loss: 0.7502 - val_accuracy: 0.6515 - lr: 0.0010\n",
            "Epoch 209/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4423 - accuracy: 0.7525 - val_loss: 0.7510 - val_accuracy: 0.6442 - lr: 0.0010\n",
            "Epoch 210/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4362 - accuracy: 0.7580 - val_loss: 0.7684 - val_accuracy: 0.6467 - lr: 0.0010\n",
            "Epoch 211/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4348 - accuracy: 0.7587 - val_loss: 0.7807 - val_accuracy: 0.6419 - lr: 0.0010\n",
            "Epoch 212/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4357 - accuracy: 0.7588 - val_loss: 0.7900 - val_accuracy: 0.6404 - lr: 0.0010\n",
            "Epoch 213/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4364 - accuracy: 0.7567 - val_loss: 0.7679 - val_accuracy: 0.6387 - lr: 0.0010\n",
            "Epoch 214/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4378 - accuracy: 0.7571 - val_loss: 0.7809 - val_accuracy: 0.6399 - lr: 0.0010\n",
            "Epoch 215/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4386 - accuracy: 0.7579 - val_loss: 0.7558 - val_accuracy: 0.6422 - lr: 0.0010\n",
            "Epoch 216/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4294 - accuracy: 0.7611 - val_loss: 0.7671 - val_accuracy: 0.6529 - lr: 0.0010\n",
            "Epoch 217/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4269 - accuracy: 0.7639 - val_loss: 0.7771 - val_accuracy: 0.6464 - lr: 0.0010\n",
            "Epoch 218/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4307 - accuracy: 0.7611 - val_loss: 0.7827 - val_accuracy: 0.6485 - lr: 0.0010\n",
            "Epoch 219/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4364 - accuracy: 0.7573 - val_loss: 0.7632 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 220/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4329 - accuracy: 0.7587 - val_loss: 0.7746 - val_accuracy: 0.6488 - lr: 0.0010\n",
            "Epoch 221/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4335 - accuracy: 0.7587 - val_loss: 0.7589 - val_accuracy: 0.6489 - lr: 0.0010\n",
            "Epoch 222/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4321 - accuracy: 0.7590 - val_loss: 0.7536 - val_accuracy: 0.6493 - lr: 0.0010\n",
            "Epoch 223/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4251 - accuracy: 0.7640 - val_loss: 0.7579 - val_accuracy: 0.6553 - lr: 0.0010\n",
            "Epoch 224/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4196 - accuracy: 0.7669 - val_loss: 0.7726 - val_accuracy: 0.6483 - lr: 0.0010\n",
            "Epoch 225/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4176 - accuracy: 0.7678 - val_loss: 0.7757 - val_accuracy: 0.6521 - lr: 0.0010\n",
            "Epoch 226/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4119 - accuracy: 0.7709 - val_loss: 0.7608 - val_accuracy: 0.6506 - lr: 0.0010\n",
            "Epoch 227/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4159 - accuracy: 0.7693 - val_loss: 0.7850 - val_accuracy: 0.6521 - lr: 0.0010\n",
            "Epoch 228/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4251 - accuracy: 0.7626 - val_loss: 0.7705 - val_accuracy: 0.6518 - lr: 0.0010\n",
            "Epoch 229/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4171 - accuracy: 0.7678 - val_loss: 0.7811 - val_accuracy: 0.6469 - lr: 0.0010\n",
            "Epoch 230/1000\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4405 - accuracy: 0.7573 - val_loss: 0.7253 - val_accuracy: 0.6582 - lr: 0.0010\n",
            "Epoch 231/1000\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4349 - accuracy: 0.7586 - val_loss: 0.8026 - val_accuracy: 0.6424 - lr: 0.0010\n",
            "Epoch 232/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4236 - accuracy: 0.7672 - val_loss: 0.8005 - val_accuracy: 0.6406 - lr: 0.0010\n",
            "Epoch 233/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4181 - accuracy: 0.7671 - val_loss: 0.7873 - val_accuracy: 0.6454 - lr: 0.0010\n",
            "Epoch 234/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4069 - accuracy: 0.7745 - val_loss: 0.8093 - val_accuracy: 0.6504 - lr: 0.0010\n",
            "Epoch 235/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4236 - accuracy: 0.7651 - val_loss: 0.7837 - val_accuracy: 0.6493 - lr: 0.0010\n",
            "Epoch 236/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4192 - accuracy: 0.7668 - val_loss: 0.7795 - val_accuracy: 0.6529 - lr: 0.0010\n",
            "Epoch 237/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4261 - accuracy: 0.7656 - val_loss: 0.8047 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 238/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4109 - accuracy: 0.7719 - val_loss: 0.7793 - val_accuracy: 0.6449 - lr: 0.0010\n",
            "Epoch 239/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4066 - accuracy: 0.7724 - val_loss: 0.7879 - val_accuracy: 0.6510 - lr: 0.0010\n",
            "Epoch 240/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4025 - accuracy: 0.7757 - val_loss: 0.7800 - val_accuracy: 0.6528 - lr: 0.0010\n",
            "Epoch 241/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3980 - accuracy: 0.7768 - val_loss: 0.7949 - val_accuracy: 0.6503 - lr: 0.0010\n",
            "Epoch 242/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3970 - accuracy: 0.7780 - val_loss: 0.7881 - val_accuracy: 0.6582 - lr: 0.0010\n",
            "Epoch 243/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3969 - accuracy: 0.7778 - val_loss: 0.7968 - val_accuracy: 0.6581 - lr: 0.0010\n",
            "Epoch 244/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4006 - accuracy: 0.7759 - val_loss: 0.8024 - val_accuracy: 0.6501 - lr: 0.0010\n",
            "Epoch 245/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4464 - accuracy: 0.7570 - val_loss: 0.8004 - val_accuracy: 0.6413 - lr: 0.0010\n",
            "Epoch 246/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4126 - accuracy: 0.7697 - val_loss: 0.7861 - val_accuracy: 0.6557 - lr: 0.0010\n",
            "Epoch 247/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3978 - accuracy: 0.7781 - val_loss: 0.7904 - val_accuracy: 0.6508 - lr: 0.0010\n",
            "Epoch 248/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3996 - accuracy: 0.7767 - val_loss: 0.7958 - val_accuracy: 0.6439 - lr: 0.0010\n",
            "Epoch 249/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3936 - accuracy: 0.7788 - val_loss: 0.8065 - val_accuracy: 0.6465 - lr: 0.0010\n",
            "Epoch 250/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3920 - accuracy: 0.7797 - val_loss: 0.7945 - val_accuracy: 0.6564 - lr: 0.0010\n",
            "Epoch 251/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4060 - accuracy: 0.7762 - val_loss: 0.8150 - val_accuracy: 0.6497 - lr: 0.0010\n",
            "Epoch 252/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3952 - accuracy: 0.7790 - val_loss: 0.8073 - val_accuracy: 0.6517 - lr: 0.0010\n",
            "Epoch 253/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3916 - accuracy: 0.7804 - val_loss: 0.7963 - val_accuracy: 0.6592 - lr: 0.0010\n",
            "Epoch 254/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3875 - accuracy: 0.7842 - val_loss: 0.8149 - val_accuracy: 0.6515 - lr: 0.0010\n",
            "Epoch 255/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3990 - accuracy: 0.7739 - val_loss: 0.8160 - val_accuracy: 0.6446 - lr: 0.0010\n",
            "Epoch 256/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3919 - accuracy: 0.7804 - val_loss: 0.8065 - val_accuracy: 0.6532 - lr: 0.0010\n",
            "Epoch 257/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4189 - accuracy: 0.7692 - val_loss: 0.8193 - val_accuracy: 0.6449 - lr: 0.0010\n",
            "Epoch 258/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3913 - accuracy: 0.7802 - val_loss: 0.8273 - val_accuracy: 0.6543 - lr: 0.0010\n",
            "Epoch 259/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3892 - accuracy: 0.7809 - val_loss: 0.8228 - val_accuracy: 0.6581 - lr: 0.0010\n",
            "Epoch 260/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3845 - accuracy: 0.7832 - val_loss: 0.8225 - val_accuracy: 0.6468 - lr: 0.0010\n",
            "Epoch 261/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3825 - accuracy: 0.7854 - val_loss: 0.8104 - val_accuracy: 0.6532 - lr: 0.0010\n",
            "Epoch 262/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3826 - accuracy: 0.7831 - val_loss: 0.8271 - val_accuracy: 0.6590 - lr: 0.0010\n",
            "Epoch 263/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4118 - accuracy: 0.7704 - val_loss: 0.8249 - val_accuracy: 0.6494 - lr: 0.0010\n",
            "Epoch 264/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3935 - accuracy: 0.7791 - val_loss: 0.8211 - val_accuracy: 0.6549 - lr: 0.0010\n",
            "Epoch 265/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3897 - accuracy: 0.7794 - val_loss: 0.8042 - val_accuracy: 0.6532 - lr: 0.0010\n",
            "Epoch 266/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4081 - accuracy: 0.7729 - val_loss: 0.8393 - val_accuracy: 0.6489 - lr: 0.0010\n",
            "Epoch 267/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3936 - accuracy: 0.7789 - val_loss: 0.8109 - val_accuracy: 0.6521 - lr: 0.0010\n",
            "Epoch 268/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3809 - accuracy: 0.7858 - val_loss: 0.8320 - val_accuracy: 0.6546 - lr: 0.0010\n",
            "Epoch 269/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3744 - accuracy: 0.7882 - val_loss: 0.8322 - val_accuracy: 0.6489 - lr: 0.0010\n",
            "Epoch 270/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3794 - accuracy: 0.7850 - val_loss: 0.8197 - val_accuracy: 0.6572 - lr: 0.0010\n",
            "Epoch 271/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3771 - accuracy: 0.7875 - val_loss: 0.8147 - val_accuracy: 0.6621 - lr: 0.0010\n",
            "Epoch 272/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3871 - accuracy: 0.7817 - val_loss: 0.8359 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 273/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3759 - accuracy: 0.7869 - val_loss: 0.8510 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 274/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3731 - accuracy: 0.7867 - val_loss: 0.8211 - val_accuracy: 0.6533 - lr: 0.0010\n",
            "Epoch 275/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3835 - accuracy: 0.7836 - val_loss: 0.8182 - val_accuracy: 0.6599 - lr: 0.0010\n",
            "Epoch 276/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3983 - accuracy: 0.7773 - val_loss: 0.8151 - val_accuracy: 0.6524 - lr: 0.0010\n",
            "Epoch 277/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3964 - accuracy: 0.7790 - val_loss: 0.8797 - val_accuracy: 0.6442 - lr: 0.0010\n",
            "Epoch 278/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4125 - accuracy: 0.7712 - val_loss: 0.8229 - val_accuracy: 0.6488 - lr: 0.0010\n",
            "Epoch 279/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3756 - accuracy: 0.7872 - val_loss: 0.8230 - val_accuracy: 0.6581 - lr: 0.0010\n",
            "Epoch 280/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3665 - accuracy: 0.7914 - val_loss: 0.8212 - val_accuracy: 0.6574 - lr: 0.0010\n",
            "Epoch 281/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3752 - accuracy: 0.7861 - val_loss: 0.8473 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 282/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3906 - accuracy: 0.7798 - val_loss: 0.8458 - val_accuracy: 0.6542 - lr: 0.0010\n",
            "Epoch 283/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4147 - accuracy: 0.7686 - val_loss: 0.8330 - val_accuracy: 0.6532 - lr: 0.0010\n",
            "Epoch 284/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3819 - accuracy: 0.7858 - val_loss: 0.8466 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 285/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3757 - accuracy: 0.7868 - val_loss: 0.8125 - val_accuracy: 0.6547 - lr: 0.0010\n",
            "Epoch 286/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3751 - accuracy: 0.7882 - val_loss: 0.8320 - val_accuracy: 0.6524 - lr: 0.0010\n",
            "Epoch 287/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3631 - accuracy: 0.7939 - val_loss: 0.8420 - val_accuracy: 0.6515 - lr: 0.0010\n",
            "Epoch 288/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3599 - accuracy: 0.7944 - val_loss: 0.8323 - val_accuracy: 0.6624 - lr: 0.0010\n",
            "Epoch 289/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3587 - accuracy: 0.7949 - val_loss: 0.8447 - val_accuracy: 0.6565 - lr: 0.0010\n",
            "Epoch 290/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3606 - accuracy: 0.7948 - val_loss: 0.8662 - val_accuracy: 0.6525 - lr: 0.0010\n",
            "Epoch 291/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3649 - accuracy: 0.7930 - val_loss: 0.8921 - val_accuracy: 0.6528 - lr: 0.0010\n",
            "Epoch 292/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3574 - accuracy: 0.7949 - val_loss: 0.8518 - val_accuracy: 0.6612 - lr: 0.0010\n",
            "Epoch 293/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3682 - accuracy: 0.7923 - val_loss: 0.8796 - val_accuracy: 0.6496 - lr: 0.0010\n",
            "Epoch 294/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3785 - accuracy: 0.7882 - val_loss: 0.8481 - val_accuracy: 0.6514 - lr: 0.0010\n",
            "Epoch 295/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3665 - accuracy: 0.7924 - val_loss: 0.8417 - val_accuracy: 0.6551 - lr: 0.0010\n",
            "Epoch 296/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3587 - accuracy: 0.7967 - val_loss: 0.8798 - val_accuracy: 0.6563 - lr: 0.0010\n",
            "Epoch 297/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3740 - accuracy: 0.7893 - val_loss: 0.8900 - val_accuracy: 0.6507 - lr: 0.0010\n",
            "Epoch 298/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3689 - accuracy: 0.7903 - val_loss: 0.8816 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 299/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3561 - accuracy: 0.7947 - val_loss: 0.8611 - val_accuracy: 0.6592 - lr: 0.0010\n",
            "Epoch 300/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3604 - accuracy: 0.7944 - val_loss: 0.8793 - val_accuracy: 0.6560 - lr: 0.0010\n",
            "Epoch 301/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3941 - accuracy: 0.7807 - val_loss: 0.8974 - val_accuracy: 0.6468 - lr: 0.0010\n",
            "Epoch 302/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3686 - accuracy: 0.7897 - val_loss: 0.8767 - val_accuracy: 0.6597 - lr: 0.0010\n",
            "Epoch 303/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3536 - accuracy: 0.7985 - val_loss: 0.8791 - val_accuracy: 0.6615 - lr: 0.0010\n",
            "Epoch 304/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3476 - accuracy: 0.8019 - val_loss: 0.8764 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 305/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3479 - accuracy: 0.8001 - val_loss: 0.8828 - val_accuracy: 0.6583 - lr: 0.0010\n",
            "Epoch 306/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3456 - accuracy: 0.8021 - val_loss: 0.8946 - val_accuracy: 0.6608 - lr: 0.0010\n",
            "Epoch 307/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3510 - accuracy: 0.7998 - val_loss: 0.9095 - val_accuracy: 0.6568 - lr: 0.0010\n",
            "Epoch 308/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3922 - accuracy: 0.7817 - val_loss: 0.8810 - val_accuracy: 0.6532 - lr: 0.0010\n",
            "Epoch 309/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3920 - accuracy: 0.7845 - val_loss: 0.8715 - val_accuracy: 0.6668 - lr: 0.0010\n",
            "Epoch 310/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3650 - accuracy: 0.7930 - val_loss: 0.8772 - val_accuracy: 0.6519 - lr: 0.0010\n",
            "Epoch 311/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3781 - accuracy: 0.7888 - val_loss: 0.8794 - val_accuracy: 0.6644 - lr: 0.0010\n",
            "Epoch 312/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3535 - accuracy: 0.7981 - val_loss: 0.9116 - val_accuracy: 0.6511 - lr: 0.0010\n",
            "Epoch 313/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3498 - accuracy: 0.7991 - val_loss: 0.8933 - val_accuracy: 0.6636 - lr: 0.0010\n",
            "Epoch 314/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3510 - accuracy: 0.7996 - val_loss: 0.8715 - val_accuracy: 0.6615 - lr: 0.0010\n",
            "Epoch 315/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3500 - accuracy: 0.7988 - val_loss: 0.9167 - val_accuracy: 0.6607 - lr: 0.0010\n",
            "Epoch 316/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3519 - accuracy: 0.7991 - val_loss: 0.9133 - val_accuracy: 0.6579 - lr: 0.0010\n",
            "Epoch 317/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3449 - accuracy: 0.8007 - val_loss: 0.9023 - val_accuracy: 0.6657 - lr: 0.0010\n",
            "Epoch 318/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3760 - accuracy: 0.7870 - val_loss: 0.9054 - val_accuracy: 0.6579 - lr: 0.0010\n",
            "Epoch 319/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3507 - accuracy: 0.7994 - val_loss: 0.9265 - val_accuracy: 0.6522 - lr: 0.0010\n",
            "Epoch 320/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3963 - accuracy: 0.7815 - val_loss: 0.9000 - val_accuracy: 0.6586 - lr: 0.0010\n",
            "Epoch 321/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3588 - accuracy: 0.7965 - val_loss: 0.9237 - val_accuracy: 0.6596 - lr: 0.0010\n",
            "Epoch 322/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3423 - accuracy: 0.8045 - val_loss: 0.9089 - val_accuracy: 0.6699 - lr: 0.0010\n",
            "Epoch 323/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3404 - accuracy: 0.8047 - val_loss: 0.9375 - val_accuracy: 0.6492 - lr: 0.0010\n",
            "Epoch 324/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3387 - accuracy: 0.8044 - val_loss: 0.9384 - val_accuracy: 0.6569 - lr: 0.0010\n",
            "Epoch 325/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3431 - accuracy: 0.8016 - val_loss: 0.9181 - val_accuracy: 0.6601 - lr: 0.0010\n",
            "Epoch 326/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3388 - accuracy: 0.8057 - val_loss: 0.9394 - val_accuracy: 0.6668 - lr: 0.0010\n",
            "Epoch 327/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3383 - accuracy: 0.8045 - val_loss: 0.9168 - val_accuracy: 0.6668 - lr: 0.0010\n",
            "Epoch 328/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3357 - accuracy: 0.8047 - val_loss: 0.9244 - val_accuracy: 0.6675 - lr: 0.0010\n",
            "Epoch 329/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3704 - accuracy: 0.7945 - val_loss: 1.0011 - val_accuracy: 0.6412 - lr: 0.0010\n",
            "Epoch 330/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4266 - accuracy: 0.7769 - val_loss: 0.9323 - val_accuracy: 0.6567 - lr: 0.0010\n",
            "Epoch 331/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4017 - accuracy: 0.7818 - val_loss: 0.9323 - val_accuracy: 0.6540 - lr: 0.0010\n",
            "Epoch 332/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3622 - accuracy: 0.7959 - val_loss: 0.9281 - val_accuracy: 0.6529 - lr: 0.0010\n",
            "Epoch 333/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3462 - accuracy: 0.8013 - val_loss: 0.9135 - val_accuracy: 0.6581 - lr: 0.0010\n",
            "Epoch 334/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3458 - accuracy: 0.8020 - val_loss: 0.9094 - val_accuracy: 0.6692 - lr: 0.0010\n",
            "Epoch 335/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3459 - accuracy: 0.8029 - val_loss: 0.9018 - val_accuracy: 0.6626 - lr: 0.0010\n",
            "Epoch 336/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3354 - accuracy: 0.8072 - val_loss: 0.9329 - val_accuracy: 0.6690 - lr: 0.0010\n",
            "Epoch 337/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3319 - accuracy: 0.8086 - val_loss: 0.9257 - val_accuracy: 0.6608 - lr: 0.0010\n",
            "Epoch 338/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3314 - accuracy: 0.8087 - val_loss: 0.9315 - val_accuracy: 0.6701 - lr: 0.0010\n",
            "Epoch 339/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3339 - accuracy: 0.8077 - val_loss: 0.9476 - val_accuracy: 0.6556 - lr: 0.0010\n",
            "Epoch 340/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3420 - accuracy: 0.8024 - val_loss: 0.9376 - val_accuracy: 0.6651 - lr: 0.0010\n",
            "Epoch 341/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3371 - accuracy: 0.8054 - val_loss: 0.9513 - val_accuracy: 0.6629 - lr: 0.0010\n",
            "Epoch 342/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3381 - accuracy: 0.8040 - val_loss: 0.9345 - val_accuracy: 0.6651 - lr: 0.0010\n",
            "Epoch 343/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3577 - accuracy: 0.7965 - val_loss: 0.9891 - val_accuracy: 0.6503 - lr: 0.0010\n",
            "Epoch 344/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4052 - accuracy: 0.7828 - val_loss: 0.9524 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 345/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3592 - accuracy: 0.7959 - val_loss: 0.9357 - val_accuracy: 0.6606 - lr: 0.0010\n",
            "Epoch 346/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3424 - accuracy: 0.8057 - val_loss: 0.9563 - val_accuracy: 0.6635 - lr: 0.0010\n",
            "Epoch 347/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3327 - accuracy: 0.8084 - val_loss: 0.9363 - val_accuracy: 0.6718 - lr: 0.0010\n",
            "Epoch 348/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3285 - accuracy: 0.8100 - val_loss: 0.9551 - val_accuracy: 0.6661 - lr: 0.0010\n",
            "Epoch 349/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3287 - accuracy: 0.8090 - val_loss: 0.9509 - val_accuracy: 0.6572 - lr: 0.0010\n",
            "Epoch 350/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3271 - accuracy: 0.8109 - val_loss: 0.9735 - val_accuracy: 0.6612 - lr: 0.0010\n",
            "Epoch 351/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3256 - accuracy: 0.8125 - val_loss: 0.9829 - val_accuracy: 0.6582 - lr: 0.0010\n",
            "Epoch 352/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3252 - accuracy: 0.8112 - val_loss: 0.9802 - val_accuracy: 0.6515 - lr: 0.0010\n",
            "Epoch 353/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3269 - accuracy: 0.8120 - val_loss: 0.9552 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 354/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3953 - accuracy: 0.7846 - val_loss: 0.9729 - val_accuracy: 0.6482 - lr: 0.0010\n",
            "Epoch 355/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4103 - accuracy: 0.7798 - val_loss: 0.9374 - val_accuracy: 0.6557 - lr: 0.0010\n",
            "Epoch 356/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3431 - accuracy: 0.8035 - val_loss: 0.9419 - val_accuracy: 0.6560 - lr: 0.0010\n",
            "Epoch 357/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3369 - accuracy: 0.8051 - val_loss: 0.9105 - val_accuracy: 0.6676 - lr: 0.0010\n",
            "Epoch 358/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3354 - accuracy: 0.8067 - val_loss: 0.9468 - val_accuracy: 0.6574 - lr: 0.0010\n",
            "Epoch 359/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3250 - accuracy: 0.8124 - val_loss: 0.9359 - val_accuracy: 0.6664 - lr: 0.0010\n",
            "Epoch 360/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3235 - accuracy: 0.8136 - val_loss: 0.9727 - val_accuracy: 0.6654 - lr: 0.0010\n",
            "Epoch 361/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3241 - accuracy: 0.8112 - val_loss: 0.9472 - val_accuracy: 0.6651 - lr: 0.0010\n",
            "Epoch 362/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3235 - accuracy: 0.8114 - val_loss: 0.9685 - val_accuracy: 0.6672 - lr: 0.0010\n",
            "Epoch 363/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3251 - accuracy: 0.8121 - val_loss: 0.9752 - val_accuracy: 0.6633 - lr: 0.0010\n",
            "Epoch 364/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3590 - accuracy: 0.7989 - val_loss: 0.9798 - val_accuracy: 0.6567 - lr: 0.0010\n",
            "Epoch 365/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3625 - accuracy: 0.7959 - val_loss: 0.9654 - val_accuracy: 0.6610 - lr: 0.0010\n",
            "Epoch 366/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3449 - accuracy: 0.8034 - val_loss: 0.9799 - val_accuracy: 0.6617 - lr: 0.0010\n",
            "Epoch 367/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3318 - accuracy: 0.8092 - val_loss: 0.9873 - val_accuracy: 0.6628 - lr: 0.0010\n",
            "Epoch 368/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3228 - accuracy: 0.8141 - val_loss: 0.9772 - val_accuracy: 0.6664 - lr: 0.0010\n",
            "Epoch 369/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3211 - accuracy: 0.8133 - val_loss: 0.9959 - val_accuracy: 0.6574 - lr: 0.0010\n",
            "Epoch 370/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3200 - accuracy: 0.8149 - val_loss: 0.9827 - val_accuracy: 0.6644 - lr: 0.0010\n",
            "Epoch 371/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3193 - accuracy: 0.8142 - val_loss: 1.0007 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 372/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3192 - accuracy: 0.8155 - val_loss: 1.0366 - val_accuracy: 0.6513 - lr: 0.0010\n",
            "Epoch 373/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3319 - accuracy: 0.8094 - val_loss: 1.0973 - val_accuracy: 0.6408 - lr: 0.0010\n",
            "Epoch 374/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4572 - accuracy: 0.7702 - val_loss: 0.9204 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 375/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3481 - accuracy: 0.8042 - val_loss: 1.0152 - val_accuracy: 0.6522 - lr: 0.0010\n",
            "Epoch 376/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3449 - accuracy: 0.8032 - val_loss: 0.9519 - val_accuracy: 0.6665 - lr: 0.0010\n",
            "Epoch 377/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3215 - accuracy: 0.8146 - val_loss: 0.9813 - val_accuracy: 0.6599 - lr: 0.0010\n",
            "Epoch 378/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3194 - accuracy: 0.8137 - val_loss: 0.9759 - val_accuracy: 0.6651 - lr: 0.0010\n",
            "Epoch 379/1000\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.3199 - accuracy: 0.8139 - val_loss: 0.9817 - val_accuracy: 0.6603 - lr: 0.0010\n",
            "Epoch 380/1000\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3168 - accuracy: 0.8155 - val_loss: 0.9862 - val_accuracy: 0.6599 - lr: 0.0010\n",
            "Epoch 381/1000\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3165 - accuracy: 0.8165 - val_loss: 0.9956 - val_accuracy: 0.6657 - lr: 0.0010\n",
            "Epoch 382/1000\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3260 - accuracy: 0.8120\n",
            "Epoch 382: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3257 - accuracy: 0.8123 - val_loss: 1.0019 - val_accuracy: 0.6533 - lr: 0.0010\n",
            "Epoch 383/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3198 - accuracy: 0.8133 - val_loss: 1.0031 - val_accuracy: 0.6607 - lr: 1.0000e-04\n",
            "Epoch 384/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3144 - accuracy: 0.8156 - val_loss: 1.0015 - val_accuracy: 0.6643 - lr: 1.0000e-04\n",
            "Epoch 385/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3135 - accuracy: 0.8162 - val_loss: 1.0021 - val_accuracy: 0.6664 - lr: 1.0000e-04\n",
            "Epoch 386/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3129 - accuracy: 0.8182 - val_loss: 1.0050 - val_accuracy: 0.6656 - lr: 1.0000e-04\n",
            "Epoch 387/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3126 - accuracy: 0.8172 - val_loss: 1.0055 - val_accuracy: 0.6646 - lr: 1.0000e-04\n",
            "Epoch 388/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3122 - accuracy: 0.8178 - val_loss: 1.0060 - val_accuracy: 0.6662 - lr: 1.0000e-04\n",
            "Epoch 389/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3121 - accuracy: 0.8188 - val_loss: 1.0070 - val_accuracy: 0.6650 - lr: 1.0000e-04\n",
            "Epoch 390/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3119 - accuracy: 0.8186 - val_loss: 1.0072 - val_accuracy: 0.6660 - lr: 1.0000e-04\n",
            "Epoch 391/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3117 - accuracy: 0.8190 - val_loss: 1.0078 - val_accuracy: 0.6664 - lr: 1.0000e-04\n",
            "Epoch 392/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3116 - accuracy: 0.8190 - val_loss: 1.0069 - val_accuracy: 0.6676 - lr: 1.0000e-04\n",
            "Epoch 393/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3115 - accuracy: 0.8193 - val_loss: 1.0095 - val_accuracy: 0.6660 - lr: 1.0000e-04\n",
            "Epoch 394/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3114 - accuracy: 0.8200 - val_loss: 1.0101 - val_accuracy: 0.6661 - lr: 1.0000e-04\n",
            "Epoch 395/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3113 - accuracy: 0.8197 - val_loss: 1.0093 - val_accuracy: 0.6668 - lr: 1.0000e-04\n",
            "Epoch 396/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3111 - accuracy: 0.8195 - val_loss: 1.0151 - val_accuracy: 0.6649 - lr: 1.0000e-04\n",
            "Epoch 397/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3109 - accuracy: 0.8201 - val_loss: 1.0131 - val_accuracy: 0.6657 - lr: 1.0000e-04\n",
            "Epoch 398/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3108 - accuracy: 0.8199 - val_loss: 1.0151 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 399/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3107 - accuracy: 0.8202 - val_loss: 1.0155 - val_accuracy: 0.6650 - lr: 1.0000e-04\n",
            "Epoch 400/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3107 - accuracy: 0.8200 - val_loss: 1.0140 - val_accuracy: 0.6669 - lr: 1.0000e-04\n",
            "Epoch 401/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3105 - accuracy: 0.8197 - val_loss: 1.0170 - val_accuracy: 0.6628 - lr: 1.0000e-04\n",
            "Epoch 402/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3104 - accuracy: 0.8198 - val_loss: 1.0171 - val_accuracy: 0.6651 - lr: 1.0000e-04\n",
            "Epoch 403/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3103 - accuracy: 0.8202 - val_loss: 1.0170 - val_accuracy: 0.6656 - lr: 1.0000e-04\n",
            "Epoch 404/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3102 - accuracy: 0.8205 - val_loss: 1.0182 - val_accuracy: 0.6649 - lr: 1.0000e-04\n",
            "Epoch 405/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3100 - accuracy: 0.8204 - val_loss: 1.0217 - val_accuracy: 0.6656 - lr: 1.0000e-04\n",
            "Epoch 406/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3099 - accuracy: 0.8200 - val_loss: 1.0201 - val_accuracy: 0.6651 - lr: 1.0000e-04\n",
            "Epoch 407/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3097 - accuracy: 0.8209 - val_loss: 1.0242 - val_accuracy: 0.6642 - lr: 1.0000e-04\n",
            "Epoch 408/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3097 - accuracy: 0.8202 - val_loss: 1.0184 - val_accuracy: 0.6651 - lr: 1.0000e-04\n",
            "Epoch 409/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3095 - accuracy: 0.8208 - val_loss: 1.0287 - val_accuracy: 0.6657 - lr: 1.0000e-04\n",
            "Epoch 410/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3095 - accuracy: 0.8206 - val_loss: 1.0245 - val_accuracy: 0.6661 - lr: 1.0000e-04\n",
            "Epoch 411/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3093 - accuracy: 0.8211 - val_loss: 1.0262 - val_accuracy: 0.6675 - lr: 1.0000e-04\n",
            "Epoch 412/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3093 - accuracy: 0.8213 - val_loss: 1.0271 - val_accuracy: 0.6651 - lr: 1.0000e-04\n",
            "Epoch 413/1000\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.3091 - accuracy: 0.8210 - val_loss: 1.0299 - val_accuracy: 0.6619 - lr: 1.0000e-04\n",
            "Epoch 414/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3089 - accuracy: 0.8214 - val_loss: 1.0278 - val_accuracy: 0.6675 - lr: 1.0000e-04\n",
            "Epoch 415/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3088 - accuracy: 0.8213 - val_loss: 1.0299 - val_accuracy: 0.6657 - lr: 1.0000e-04\n",
            "Epoch 416/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3087 - accuracy: 0.8212 - val_loss: 1.0297 - val_accuracy: 0.6669 - lr: 1.0000e-04\n",
            "Epoch 417/1000\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 0.3086 - accuracy: 0.8203\n",
            "Epoch 417: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3086 - accuracy: 0.8208 - val_loss: 1.0312 - val_accuracy: 0.6651 - lr: 1.0000e-04\n",
            "Epoch 418/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3077 - accuracy: 0.8224 - val_loss: 1.0309 - val_accuracy: 0.6657 - lr: 1.0000e-05\n",
            "Epoch 419/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3077 - accuracy: 0.8223 - val_loss: 1.0308 - val_accuracy: 0.6658 - lr: 1.0000e-05\n",
            "Epoch 420/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3076 - accuracy: 0.8224 - val_loss: 1.0309 - val_accuracy: 0.6671 - lr: 1.0000e-05\n",
            "Epoch 421/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3076 - accuracy: 0.8222 - val_loss: 1.0310 - val_accuracy: 0.6669 - lr: 1.0000e-05\n",
            "Epoch 422/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3076 - accuracy: 0.8226 - val_loss: 1.0311 - val_accuracy: 0.6669 - lr: 1.0000e-05\n",
            "Epoch 423/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3076 - accuracy: 0.8222 - val_loss: 1.0309 - val_accuracy: 0.6672 - lr: 1.0000e-05\n",
            "Epoch 424/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3075 - accuracy: 0.8225 - val_loss: 1.0310 - val_accuracy: 0.6672 - lr: 1.0000e-05\n",
            "Epoch 425/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3075 - accuracy: 0.8223 - val_loss: 1.0309 - val_accuracy: 0.6669 - lr: 1.0000e-05\n",
            "Epoch 426/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3075 - accuracy: 0.8224 - val_loss: 1.0309 - val_accuracy: 0.6665 - lr: 1.0000e-05\n",
            "Epoch 427/1000\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.3075 - accuracy: 0.8223 - val_loss: 1.0312 - val_accuracy: 0.6676 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0bfacea340>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "model_15=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=2,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(8),\n",
        "    layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_15.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "model_15.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=100,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMrGwGpYgwJg",
        "outputId": "cc21a8f7-05b7-46b3-b0bf-ecb3f995f7a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 3s 9ms/step - loss: 0.6927 - accuracy: 0.5166 - val_loss: 0.6933 - val_accuracy: 0.5088 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6914 - accuracy: 0.5332 - val_loss: 0.6950 - val_accuracy: 0.4913 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6898 - accuracy: 0.5385 - val_loss: 0.6938 - val_accuracy: 0.5038 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6874 - accuracy: 0.5460 - val_loss: 0.6954 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6852 - accuracy: 0.5507 - val_loss: 0.6928 - val_accuracy: 0.5075 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6833 - accuracy: 0.5526 - val_loss: 0.6925 - val_accuracy: 0.5175 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.5560 - val_loss: 0.6994 - val_accuracy: 0.5275 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6811 - accuracy: 0.5554 - val_loss: 0.6941 - val_accuracy: 0.5188 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6790 - accuracy: 0.5732 - val_loss: 0.6920 - val_accuracy: 0.5250 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6763 - accuracy: 0.5748 - val_loss: 0.6913 - val_accuracy: 0.5250 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6742 - accuracy: 0.5735 - val_loss: 0.6998 - val_accuracy: 0.5450 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6723 - accuracy: 0.5801 - val_loss: 0.6903 - val_accuracy: 0.5425 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6685 - accuracy: 0.5776 - val_loss: 0.6968 - val_accuracy: 0.5462 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6685 - accuracy: 0.5879 - val_loss: 0.6887 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6675 - accuracy: 0.5870 - val_loss: 0.6882 - val_accuracy: 0.5537 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6637 - accuracy: 0.5911 - val_loss: 0.6863 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.5870 - val_loss: 0.6909 - val_accuracy: 0.5362 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6622 - accuracy: 0.5914 - val_loss: 0.6854 - val_accuracy: 0.5675 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6603 - accuracy: 0.5951 - val_loss: 0.6837 - val_accuracy: 0.5650 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6607 - accuracy: 0.5973 - val_loss: 0.6842 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6589 - accuracy: 0.6086 - val_loss: 0.6824 - val_accuracy: 0.5675 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6589 - accuracy: 0.6026 - val_loss: 0.6872 - val_accuracy: 0.5412 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6578 - accuracy: 0.5998 - val_loss: 0.6809 - val_accuracy: 0.5650 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6567 - accuracy: 0.6036 - val_loss: 0.6832 - val_accuracy: 0.5575 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6555 - accuracy: 0.6070 - val_loss: 0.6818 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.6029 - val_loss: 0.6868 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.6543 - accuracy: 0.6117 - val_loss: 0.6764 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.6559 - accuracy: 0.5964 - val_loss: 0.6814 - val_accuracy: 0.5612 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6531 - accuracy: 0.6070 - val_loss: 0.6852 - val_accuracy: 0.5562 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6541 - accuracy: 0.6008 - val_loss: 0.6802 - val_accuracy: 0.5612 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6516 - accuracy: 0.6151 - val_loss: 0.6828 - val_accuracy: 0.5400 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6508 - accuracy: 0.6048 - val_loss: 0.6828 - val_accuracy: 0.5575 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.6108 - val_loss: 0.6803 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6490 - accuracy: 0.6095 - val_loss: 0.6782 - val_accuracy: 0.5838 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.6126 - val_loss: 0.6799 - val_accuracy: 0.5713 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6486 - accuracy: 0.6108 - val_loss: 0.6757 - val_accuracy: 0.5863 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6476 - accuracy: 0.6086 - val_loss: 0.6852 - val_accuracy: 0.5487 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6455 - accuracy: 0.6167 - val_loss: 0.6810 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6444 - accuracy: 0.6151 - val_loss: 0.6753 - val_accuracy: 0.5813 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6446 - accuracy: 0.6155 - val_loss: 0.6832 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6450 - accuracy: 0.6189 - val_loss: 0.6744 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6437 - accuracy: 0.6136 - val_loss: 0.6790 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6430 - accuracy: 0.6167 - val_loss: 0.6754 - val_accuracy: 0.5962 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6405 - accuracy: 0.6239 - val_loss: 0.6765 - val_accuracy: 0.5838 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6386 - accuracy: 0.6214 - val_loss: 0.6765 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6391 - accuracy: 0.6295 - val_loss: 0.6735 - val_accuracy: 0.5900 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6375 - accuracy: 0.6239 - val_loss: 0.6721 - val_accuracy: 0.6050 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.6382 - accuracy: 0.6270 - val_loss: 0.6953 - val_accuracy: 0.5350 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6368 - accuracy: 0.6295 - val_loss: 0.6738 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6341 - accuracy: 0.6267 - val_loss: 0.6789 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6342 - accuracy: 0.6286 - val_loss: 0.6711 - val_accuracy: 0.6025 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6321 - accuracy: 0.6374 - val_loss: 0.6883 - val_accuracy: 0.5450 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6338 - accuracy: 0.6292 - val_loss: 0.6719 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6319 - accuracy: 0.6305 - val_loss: 0.6680 - val_accuracy: 0.5950 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6303 - accuracy: 0.6339 - val_loss: 0.6667 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6295 - accuracy: 0.6283 - val_loss: 0.6688 - val_accuracy: 0.5838 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.6330 - val_loss: 0.6634 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6282 - accuracy: 0.6411 - val_loss: 0.6630 - val_accuracy: 0.6150 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6272 - accuracy: 0.6377 - val_loss: 0.6634 - val_accuracy: 0.5925 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6260 - accuracy: 0.6370 - val_loss: 0.6638 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6258 - accuracy: 0.6421 - val_loss: 0.6626 - val_accuracy: 0.6012 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6260 - accuracy: 0.6421 - val_loss: 0.6672 - val_accuracy: 0.5925 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6244 - accuracy: 0.6405 - val_loss: 0.6630 - val_accuracy: 0.5962 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6240 - accuracy: 0.6417 - val_loss: 0.6591 - val_accuracy: 0.6175 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.6352 - val_loss: 0.6622 - val_accuracy: 0.5987 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6207 - accuracy: 0.6389 - val_loss: 0.6581 - val_accuracy: 0.6137 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6201 - accuracy: 0.6452 - val_loss: 0.6600 - val_accuracy: 0.6087 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6188 - accuracy: 0.6417 - val_loss: 0.6585 - val_accuracy: 0.5975 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6208 - accuracy: 0.6530 - val_loss: 0.6540 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6201 - accuracy: 0.6480 - val_loss: 0.6521 - val_accuracy: 0.6137 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6168 - accuracy: 0.6467 - val_loss: 0.6555 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6153 - accuracy: 0.6527 - val_loss: 0.6571 - val_accuracy: 0.6112 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6152 - accuracy: 0.6496 - val_loss: 0.6546 - val_accuracy: 0.6075 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6136 - accuracy: 0.6502 - val_loss: 0.6526 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.6124 - accuracy: 0.6486 - val_loss: 0.6554 - val_accuracy: 0.6112 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6125 - accuracy: 0.6511 - val_loss: 0.6571 - val_accuracy: 0.6150 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6136 - accuracy: 0.6511 - val_loss: 0.6525 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6112 - accuracy: 0.6458 - val_loss: 0.6569 - val_accuracy: 0.6175 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6099 - accuracy: 0.6586 - val_loss: 0.6539 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6099 - accuracy: 0.6549 - val_loss: 0.6558 - val_accuracy: 0.6150 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6071 - accuracy: 0.6586 - val_loss: 0.6530 - val_accuracy: 0.6225 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6072 - accuracy: 0.6564 - val_loss: 0.6562 - val_accuracy: 0.6037 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.6073 - accuracy: 0.6558 - val_loss: 0.6504 - val_accuracy: 0.6300 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6054 - accuracy: 0.6615 - val_loss: 0.6530 - val_accuracy: 0.6150 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6044 - accuracy: 0.6608 - val_loss: 0.6553 - val_accuracy: 0.6237 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6062 - accuracy: 0.6571 - val_loss: 0.6535 - val_accuracy: 0.6087 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6055 - accuracy: 0.6589 - val_loss: 0.6564 - val_accuracy: 0.6162 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6024 - accuracy: 0.6661 - val_loss: 0.6648 - val_accuracy: 0.6075 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6031 - accuracy: 0.6564 - val_loss: 0.6682 - val_accuracy: 0.5925 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.6038 - accuracy: 0.6602 - val_loss: 0.6551 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5987 - accuracy: 0.6715 - val_loss: 0.6649 - val_accuracy: 0.6050 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5982 - accuracy: 0.6699 - val_loss: 0.6590 - val_accuracy: 0.6087 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6014 - accuracy: 0.6568 - val_loss: 0.6516 - val_accuracy: 0.6313 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5971 - accuracy: 0.6683 - val_loss: 0.6491 - val_accuracy: 0.6375 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5946 - accuracy: 0.6721 - val_loss: 0.6572 - val_accuracy: 0.6162 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5963 - accuracy: 0.6643 - val_loss: 0.6489 - val_accuracy: 0.6338 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5949 - accuracy: 0.6677 - val_loss: 0.6521 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5966 - accuracy: 0.6661 - val_loss: 0.6520 - val_accuracy: 0.6175 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.5917 - accuracy: 0.6693 - val_loss: 0.6545 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5950 - accuracy: 0.6640 - val_loss: 0.6482 - val_accuracy: 0.6388 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5931 - accuracy: 0.6661 - val_loss: 0.6698 - val_accuracy: 0.6112 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5906 - accuracy: 0.6665 - val_loss: 0.6483 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5907 - accuracy: 0.6674 - val_loss: 0.6528 - val_accuracy: 0.6237 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5899 - accuracy: 0.6699 - val_loss: 0.6561 - val_accuracy: 0.6100 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5902 - accuracy: 0.6746 - val_loss: 0.6454 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5862 - accuracy: 0.6652 - val_loss: 0.6613 - val_accuracy: 0.6125 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5878 - accuracy: 0.6683 - val_loss: 0.6589 - val_accuracy: 0.6162 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5884 - accuracy: 0.6693 - val_loss: 0.6576 - val_accuracy: 0.6212 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5840 - accuracy: 0.6743 - val_loss: 0.6534 - val_accuracy: 0.6162 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5863 - accuracy: 0.6724 - val_loss: 0.6452 - val_accuracy: 0.6413 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5833 - accuracy: 0.6696 - val_loss: 0.6536 - val_accuracy: 0.6187 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5814 - accuracy: 0.6780 - val_loss: 0.6523 - val_accuracy: 0.6212 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5814 - accuracy: 0.6740 - val_loss: 0.6429 - val_accuracy: 0.6350 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5808 - accuracy: 0.6780 - val_loss: 0.6524 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5805 - accuracy: 0.6771 - val_loss: 0.6443 - val_accuracy: 0.6475 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5793 - accuracy: 0.6796 - val_loss: 0.6433 - val_accuracy: 0.6350 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5796 - accuracy: 0.6740 - val_loss: 0.6526 - val_accuracy: 0.6313 - lr: 0.0010\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5780 - accuracy: 0.6780 - val_loss: 0.6511 - val_accuracy: 0.6363 - lr: 0.0010\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5777 - accuracy: 0.6774 - val_loss: 0.6474 - val_accuracy: 0.6463 - lr: 0.0010\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5815 - accuracy: 0.6737 - val_loss: 0.6530 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5757 - accuracy: 0.6783 - val_loss: 0.6450 - val_accuracy: 0.6463 - lr: 0.0010\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5750 - accuracy: 0.6793 - val_loss: 0.6486 - val_accuracy: 0.6388 - lr: 0.0010\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5753 - accuracy: 0.6758 - val_loss: 0.6431 - val_accuracy: 0.6438 - lr: 0.0010\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5723 - accuracy: 0.6780 - val_loss: 0.6615 - val_accuracy: 0.6263 - lr: 0.0010\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5722 - accuracy: 0.6799 - val_loss: 0.6560 - val_accuracy: 0.6288 - lr: 0.0010\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5714 - accuracy: 0.6855 - val_loss: 0.6609 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5722 - accuracy: 0.6802 - val_loss: 0.6534 - val_accuracy: 0.6338 - lr: 0.0010\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5713 - accuracy: 0.6809 - val_loss: 0.6486 - val_accuracy: 0.6475 - lr: 0.0010\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5690 - accuracy: 0.6862 - val_loss: 0.6441 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5688 - accuracy: 0.6855 - val_loss: 0.6569 - val_accuracy: 0.6413 - lr: 0.0010\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5715 - accuracy: 0.6855 - val_loss: 0.6601 - val_accuracy: 0.6263 - lr: 0.0010\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5685 - accuracy: 0.6809 - val_loss: 0.6414 - val_accuracy: 0.6388 - lr: 0.0010\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5659 - accuracy: 0.6887 - val_loss: 0.6500 - val_accuracy: 0.6438 - lr: 0.0010\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5664 - accuracy: 0.6818 - val_loss: 0.6540 - val_accuracy: 0.6288 - lr: 0.0010\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5627 - accuracy: 0.6934 - val_loss: 0.6508 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5662 - accuracy: 0.6868 - val_loss: 0.6583 - val_accuracy: 0.6413 - lr: 0.0010\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5644 - accuracy: 0.6899 - val_loss: 0.6524 - val_accuracy: 0.6313 - lr: 0.0010\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5630 - accuracy: 0.6946 - val_loss: 0.6538 - val_accuracy: 0.6363 - lr: 0.0010\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5593 - accuracy: 0.6890 - val_loss: 0.6521 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5616 - accuracy: 0.6931 - val_loss: 0.6471 - val_accuracy: 0.6187 - lr: 0.0010\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5613 - accuracy: 0.6918 - val_loss: 0.6511 - val_accuracy: 0.6375 - lr: 0.0010\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5629 - accuracy: 0.6918 - val_loss: 0.6711 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5600 - accuracy: 0.6965 - val_loss: 0.6718 - val_accuracy: 0.6350 - lr: 0.0010\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5603 - accuracy: 0.7012 - val_loss: 0.6444 - val_accuracy: 0.6425 - lr: 0.0010\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5643 - accuracy: 0.6921 - val_loss: 0.6451 - val_accuracy: 0.6375 - lr: 0.0010\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5586 - accuracy: 0.6915 - val_loss: 0.6548 - val_accuracy: 0.6388 - lr: 0.0010\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5591 - accuracy: 0.6968 - val_loss: 0.6700 - val_accuracy: 0.6288 - lr: 0.0010\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5556 - accuracy: 0.6956 - val_loss: 0.6571 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5528 - accuracy: 0.7012 - val_loss: 0.6632 - val_accuracy: 0.6488 - lr: 0.0010\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5576 - accuracy: 0.6977 - val_loss: 0.6488 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5546 - accuracy: 0.6971 - val_loss: 0.6559 - val_accuracy: 0.6525 - lr: 0.0010\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5559 - accuracy: 0.7015 - val_loss: 0.6542 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5525 - accuracy: 0.7049 - val_loss: 0.6497 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5550 - accuracy: 0.6977 - val_loss: 0.6437 - val_accuracy: 0.6363 - lr: 0.0010\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5511 - accuracy: 0.7031 - val_loss: 0.6416 - val_accuracy: 0.6488 - lr: 0.0010\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5525 - accuracy: 0.7065 - val_loss: 0.6402 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5503 - accuracy: 0.7024 - val_loss: 0.6515 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5512 - accuracy: 0.7056 - val_loss: 0.6526 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5540 - accuracy: 0.7028 - val_loss: 0.6449 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5544 - accuracy: 0.7024 - val_loss: 0.6456 - val_accuracy: 0.6475 - lr: 0.0010\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5487 - accuracy: 0.7099 - val_loss: 0.6493 - val_accuracy: 0.6388 - lr: 0.0010\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5451 - accuracy: 0.7084 - val_loss: 0.6687 - val_accuracy: 0.6525 - lr: 0.0010\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5479 - accuracy: 0.7074 - val_loss: 0.6532 - val_accuracy: 0.6525 - lr: 0.0010\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5460 - accuracy: 0.7134 - val_loss: 0.6497 - val_accuracy: 0.6438 - lr: 0.0010\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5461 - accuracy: 0.7099 - val_loss: 0.6534 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5463 - accuracy: 0.7090 - val_loss: 0.6391 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5457 - accuracy: 0.7065 - val_loss: 0.6490 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5436 - accuracy: 0.7137 - val_loss: 0.6477 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.7140 - val_loss: 0.6435 - val_accuracy: 0.6413 - lr: 0.0010\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5423 - accuracy: 0.7121 - val_loss: 0.6676 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5427 - accuracy: 0.7056 - val_loss: 0.6489 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5420 - accuracy: 0.7162 - val_loss: 0.6510 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5393 - accuracy: 0.7196 - val_loss: 0.6527 - val_accuracy: 0.6612 - lr: 0.0010\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5439 - accuracy: 0.7125 - val_loss: 0.6380 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5381 - accuracy: 0.7153 - val_loss: 0.6727 - val_accuracy: 0.6425 - lr: 0.0010\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5404 - accuracy: 0.7187 - val_loss: 0.6619 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5388 - accuracy: 0.7203 - val_loss: 0.6433 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5390 - accuracy: 0.7175 - val_loss: 0.6507 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5380 - accuracy: 0.7247 - val_loss: 0.6415 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5345 - accuracy: 0.7162 - val_loss: 0.6387 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5387 - accuracy: 0.7175 - val_loss: 0.6606 - val_accuracy: 0.6438 - lr: 0.0010\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5366 - accuracy: 0.7231 - val_loss: 0.6588 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5367 - accuracy: 0.7256 - val_loss: 0.6541 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5372 - accuracy: 0.7184 - val_loss: 0.6445 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5352 - accuracy: 0.7178 - val_loss: 0.6401 - val_accuracy: 0.6712 - lr: 0.0010\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5333 - accuracy: 0.7212 - val_loss: 0.6465 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5323 - accuracy: 0.7250 - val_loss: 0.6415 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5332 - accuracy: 0.7234 - val_loss: 0.6449 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5316 - accuracy: 0.7287 - val_loss: 0.6456 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5300 - accuracy: 0.7196 - val_loss: 0.6508 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5288 - accuracy: 0.7243 - val_loss: 0.6447 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5292 - accuracy: 0.7284 - val_loss: 0.6499 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5306 - accuracy: 0.7253 - val_loss: 0.6446 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5304 - accuracy: 0.7193 - val_loss: 0.6418 - val_accuracy: 0.6675 - lr: 0.0010\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5282 - accuracy: 0.7319 - val_loss: 0.6642 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5259 - accuracy: 0.7262 - val_loss: 0.6454 - val_accuracy: 0.6725 - lr: 0.0010\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5272 - accuracy: 0.7322 - val_loss: 0.6789 - val_accuracy: 0.6513 - lr: 0.0010\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5285 - accuracy: 0.7275 - val_loss: 0.6406 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5248 - accuracy: 0.7290 - val_loss: 0.6611 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5233 - accuracy: 0.7293 - val_loss: 0.6584 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5250 - accuracy: 0.7268 - val_loss: 0.6652 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5228 - accuracy: 0.7340 - val_loss: 0.6455 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5244 - accuracy: 0.7281 - val_loss: 0.6651 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5232 - accuracy: 0.7369 - val_loss: 0.6412 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5224 - accuracy: 0.7303 - val_loss: 0.6404 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5199 - accuracy: 0.7372 - val_loss: 0.6357 - val_accuracy: 0.6725 - lr: 0.0010\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5175 - accuracy: 0.7359 - val_loss: 0.6670 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5195 - accuracy: 0.7344 - val_loss: 0.6400 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5174 - accuracy: 0.7344 - val_loss: 0.6422 - val_accuracy: 0.6725 - lr: 0.0010\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5199 - accuracy: 0.7319 - val_loss: 0.6330 - val_accuracy: 0.6675 - lr: 0.0010\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5192 - accuracy: 0.7359 - val_loss: 0.6551 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5170 - accuracy: 0.7353 - val_loss: 0.6530 - val_accuracy: 0.6712 - lr: 0.0010\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5149 - accuracy: 0.7447 - val_loss: 0.6348 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5150 - accuracy: 0.7387 - val_loss: 0.6530 - val_accuracy: 0.6712 - lr: 0.0010\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5139 - accuracy: 0.7409 - val_loss: 0.6440 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5186 - accuracy: 0.7381 - val_loss: 0.6483 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5158 - accuracy: 0.7428 - val_loss: 0.6397 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5150 - accuracy: 0.7353 - val_loss: 0.6333 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5135 - accuracy: 0.7412 - val_loss: 0.6338 - val_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5105 - accuracy: 0.7387 - val_loss: 0.6425 - val_accuracy: 0.6762 - lr: 0.0010\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5097 - accuracy: 0.7365 - val_loss: 0.6515 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5106 - accuracy: 0.7472 - val_loss: 0.6328 - val_accuracy: 0.6762 - lr: 0.0010\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5106 - accuracy: 0.7381 - val_loss: 0.6304 - val_accuracy: 0.6737 - lr: 0.0010\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5111 - accuracy: 0.7419 - val_loss: 0.6525 - val_accuracy: 0.6762 - lr: 0.0010\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5082 - accuracy: 0.7409 - val_loss: 0.6466 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5078 - accuracy: 0.7419 - val_loss: 0.6654 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5076 - accuracy: 0.7437 - val_loss: 0.6410 - val_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5066 - accuracy: 0.7459 - val_loss: 0.6346 - val_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5074 - accuracy: 0.7387 - val_loss: 0.6539 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5057 - accuracy: 0.7447 - val_loss: 0.6560 - val_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5066 - accuracy: 0.7434 - val_loss: 0.6505 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5041 - accuracy: 0.7447 - val_loss: 0.6499 - val_accuracy: 0.6812 - lr: 0.0010\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5041 - accuracy: 0.7462 - val_loss: 0.6384 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5024 - accuracy: 0.7469 - val_loss: 0.6545 - val_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5002 - accuracy: 0.7475 - val_loss: 0.6506 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5040 - accuracy: 0.7437 - val_loss: 0.6513 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5003 - accuracy: 0.7431 - val_loss: 0.6538 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4996 - accuracy: 0.7506 - val_loss: 0.6573 - val_accuracy: 0.6800 - lr: 0.0010\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5002 - accuracy: 0.7481 - val_loss: 0.6419 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4981 - accuracy: 0.7513 - val_loss: 0.6724 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5006 - accuracy: 0.7434 - val_loss: 0.6544 - val_accuracy: 0.6712 - lr: 0.0010\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4976 - accuracy: 0.7516 - val_loss: 0.6493 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4987 - accuracy: 0.7466 - val_loss: 0.6620 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4974 - accuracy: 0.7528 - val_loss: 0.6741 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4959 - accuracy: 0.7466 - val_loss: 0.6521 - val_accuracy: 0.6712 - lr: 0.0010\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4977 - accuracy: 0.7550 - val_loss: 0.6553 - val_accuracy: 0.6787 - lr: 0.0010\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4952 - accuracy: 0.7487 - val_loss: 0.6606 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4966 - accuracy: 0.7491 - val_loss: 0.6433 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4935 - accuracy: 0.7513 - val_loss: 0.6623 - val_accuracy: 0.6675 - lr: 0.0010\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4964 - accuracy: 0.7516 - val_loss: 0.6462 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4958 - accuracy: 0.7469 - val_loss: 0.6569 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4924 - accuracy: 0.7544 - val_loss: 0.6408 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4937 - accuracy: 0.7541 - val_loss: 0.6753 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4957 - accuracy: 0.7553 - val_loss: 0.6585 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4904 - accuracy: 0.7553 - val_loss: 0.6653 - val_accuracy: 0.6488 - lr: 0.0010\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4885 - accuracy: 0.7584 - val_loss: 0.6438 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4904 - accuracy: 0.7563 - val_loss: 0.6490 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4921 - accuracy: 0.7550 - val_loss: 0.6532 - val_accuracy: 0.6737 - lr: 0.0010\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4882 - accuracy: 0.7572 - val_loss: 0.6565 - val_accuracy: 0.6525 - lr: 0.0010\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4884 - accuracy: 0.7566 - val_loss: 0.6843 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4872 - accuracy: 0.7588 - val_loss: 0.6678 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4891 - accuracy: 0.7628 - val_loss: 0.6624 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4874 - accuracy: 0.7563 - val_loss: 0.6505 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4889 - accuracy: 0.7613 - val_loss: 0.6489 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4874 - accuracy: 0.7572 - val_loss: 0.6450 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4856 - accuracy: 0.7550 - val_loss: 0.6690 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.7581\n",
            "Epoch 267: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4866 - accuracy: 0.7581 - val_loss: 0.6641 - val_accuracy: 0.6525 - lr: 0.0010\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.7675 - val_loss: 0.6589 - val_accuracy: 0.6513 - lr: 1.0000e-04\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4730 - accuracy: 0.7644 - val_loss: 0.6583 - val_accuracy: 0.6463 - lr: 1.0000e-04\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4721 - accuracy: 0.7660 - val_loss: 0.6601 - val_accuracy: 0.6425 - lr: 1.0000e-04\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4723 - accuracy: 0.7660 - val_loss: 0.6586 - val_accuracy: 0.6475 - lr: 1.0000e-04\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4719 - accuracy: 0.7653 - val_loss: 0.6559 - val_accuracy: 0.6475 - lr: 1.0000e-04\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4721 - accuracy: 0.7663 - val_loss: 0.6600 - val_accuracy: 0.6463 - lr: 1.0000e-04\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4720 - accuracy: 0.7653 - val_loss: 0.6627 - val_accuracy: 0.6475 - lr: 1.0000e-04\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4716 - accuracy: 0.7688 - val_loss: 0.6631 - val_accuracy: 0.6500 - lr: 1.0000e-04\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4718 - accuracy: 0.7663 - val_loss: 0.6626 - val_accuracy: 0.6488 - lr: 1.0000e-04\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4712 - accuracy: 0.7713 - val_loss: 0.6611 - val_accuracy: 0.6525 - lr: 1.0000e-04\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4713 - accuracy: 0.7700 - val_loss: 0.6609 - val_accuracy: 0.6488 - lr: 1.0000e-04\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4709 - accuracy: 0.7681 - val_loss: 0.6614 - val_accuracy: 0.6488 - lr: 1.0000e-04\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4708 - accuracy: 0.7681 - val_loss: 0.6570 - val_accuracy: 0.6500 - lr: 1.0000e-04\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4705 - accuracy: 0.7663 - val_loss: 0.6652 - val_accuracy: 0.6513 - lr: 1.0000e-04\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4709 - accuracy: 0.7672 - val_loss: 0.6614 - val_accuracy: 0.6500 - lr: 1.0000e-04\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4707 - accuracy: 0.7688 - val_loss: 0.6589 - val_accuracy: 0.6513 - lr: 1.0000e-04\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4711 - accuracy: 0.7669 - val_loss: 0.6596 - val_accuracy: 0.6488 - lr: 1.0000e-04\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4704 - accuracy: 0.7666 - val_loss: 0.6652 - val_accuracy: 0.6525 - lr: 1.0000e-04\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4705 - accuracy: 0.7710 - val_loss: 0.6611 - val_accuracy: 0.6525 - lr: 1.0000e-04\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4704 - accuracy: 0.7678 - val_loss: 0.6589 - val_accuracy: 0.6525 - lr: 1.0000e-04\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4703 - accuracy: 0.7669 - val_loss: 0.6640 - val_accuracy: 0.6500 - lr: 1.0000e-04\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4701 - accuracy: 0.7707 - val_loss: 0.6588 - val_accuracy: 0.6525 - lr: 1.0000e-04\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7669 - val_loss: 0.6625 - val_accuracy: 0.6513 - lr: 1.0000e-04\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4706 - accuracy: 0.7672 - val_loss: 0.6609 - val_accuracy: 0.6550 - lr: 1.0000e-04\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4698 - accuracy: 0.7688 - val_loss: 0.6648 - val_accuracy: 0.6513 - lr: 1.0000e-04\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7688 - val_loss: 0.6626 - val_accuracy: 0.6550 - lr: 1.0000e-04\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4700 - accuracy: 0.7707 - val_loss: 0.6637 - val_accuracy: 0.6513 - lr: 1.0000e-04\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.7703 - val_loss: 0.6638 - val_accuracy: 0.6450 - lr: 1.0000e-04\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4700 - accuracy: 0.7691 - val_loss: 0.6616 - val_accuracy: 0.6513 - lr: 1.0000e-04\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4694 - accuracy: 0.7700 - val_loss: 0.6654 - val_accuracy: 0.6513 - lr: 1.0000e-04\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4695 - accuracy: 0.7694 - val_loss: 0.6607 - val_accuracy: 0.6513 - lr: 1.0000e-04\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4695 - accuracy: 0.7716 - val_loss: 0.6630 - val_accuracy: 0.6525 - lr: 1.0000e-04\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4694 - accuracy: 0.7700 - val_loss: 0.6633 - val_accuracy: 0.6550 - lr: 1.0000e-04\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4694 - accuracy: 0.7732 - val_loss: 0.6621 - val_accuracy: 0.6538 - lr: 1.0000e-04\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.7710\n",
            "Epoch 302: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4688 - accuracy: 0.7710 - val_loss: 0.6681 - val_accuracy: 0.6525 - lr: 1.0000e-04\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4681 - accuracy: 0.7728 - val_loss: 0.6667 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4677 - accuracy: 0.7722 - val_loss: 0.6652 - val_accuracy: 0.6538 - lr: 1.0000e-05\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4676 - accuracy: 0.7713 - val_loss: 0.6644 - val_accuracy: 0.6538 - lr: 1.0000e-05\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.7703 - val_loss: 0.6637 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4676 - accuracy: 0.7697 - val_loss: 0.6638 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7697 - val_loss: 0.6635 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
            "Epoch 309/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7703 - val_loss: 0.6636 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7703 - val_loss: 0.6633 - val_accuracy: 0.6525 - lr: 1.0000e-05\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7700 - val_loss: 0.6635 - val_accuracy: 0.6525 - lr: 1.0000e-05\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7703 - val_loss: 0.6633 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7703 - val_loss: 0.6633 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7700 - val_loss: 0.6637 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7703 - val_loss: 0.6634 - val_accuracy: 0.6525 - lr: 1.0000e-05\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7703 - val_loss: 0.6632 - val_accuracy: 0.6525 - lr: 1.0000e-05\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7700 - val_loss: 0.6632 - val_accuracy: 0.6500 - lr: 1.0000e-05\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7691 - val_loss: 0.6633 - val_accuracy: 0.6525 - lr: 1.0000e-05\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7700 - val_loss: 0.6630 - val_accuracy: 0.6500 - lr: 1.0000e-05\n",
            "Epoch 320/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4674 - accuracy: 0.7710 - val_loss: 0.6634 - val_accuracy: 0.6500 - lr: 1.0000e-05\n",
            "Epoch 321/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4674 - accuracy: 0.7707 - val_loss: 0.6637 - val_accuracy: 0.6525 - lr: 1.0000e-05\n",
            "Epoch 322/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4674 - accuracy: 0.7700 - val_loss: 0.6631 - val_accuracy: 0.6525 - lr: 1.0000e-05\n",
            "Epoch 323/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4674 - accuracy: 0.7700 - val_loss: 0.6637 - val_accuracy: 0.6525 - lr: 1.0000e-05\n",
            "Epoch 324/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4674 - accuracy: 0.7703 - val_loss: 0.6637 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
            "Epoch 325/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4674 - accuracy: 0.7697 - val_loss: 0.6632 - val_accuracy: 0.6525 - lr: 1.0000e-05\n",
            "Epoch 326/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4674 - accuracy: 0.7700 - val_loss: 0.6638 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
            "Epoch 327/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4674 - accuracy: 0.7703 - val_loss: 0.6635 - val_accuracy: 0.6525 - lr: 1.0000e-05\n",
            "Epoch 328/500\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.7707 - val_loss: 0.6637 - val_accuracy: 0.6525 - lr: 1.0000e-05\n",
            "Epoch 329/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4674 - accuracy: 0.7710 - val_loss: 0.6635 - val_accuracy: 0.6525 - lr: 1.0000e-05\n",
            "Epoch 330/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4673 - accuracy: 0.7707 - val_loss: 0.6637 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
            "Epoch 331/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4674 - accuracy: 0.7697 - val_loss: 0.6637 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
            "Epoch 332/500\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4674 - accuracy: 0.7697 - val_loss: 0.6635 - val_accuracy: 0.6525 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f04523e8940>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_15.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZZPznIFjDEP",
        "outputId": "52dd5ec6-b28b-40e6-a5d1-7ba9067aad7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.6812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6499374508857727, 0.6812499761581421]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_16=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=3,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(64,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.LSTM(8),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_16.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "model_16.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=80,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKRmOJhQGmeb",
        "outputId": "f17113db-b276-4a8b-c3f8-b8da2d2137da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 22s 36ms/step - loss: 0.6933 - accuracy: 0.4909 - val_loss: 0.6933 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6933 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6933 - accuracy: 0.4903 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6933 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6898 - accuracy: 0.5410 - val_loss: 0.6853 - val_accuracy: 0.5587 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6906 - accuracy: 0.5354 - val_loss: 0.6911 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6901 - accuracy: 0.5375 - val_loss: 0.6880 - val_accuracy: 0.5537 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6875 - accuracy: 0.5519 - val_loss: 0.6861 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6833 - accuracy: 0.5532 - val_loss: 0.6894 - val_accuracy: 0.5562 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6800 - accuracy: 0.5688 - val_loss: 0.6878 - val_accuracy: 0.5537 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6797 - accuracy: 0.5645 - val_loss: 0.6881 - val_accuracy: 0.5663 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.6757 - accuracy: 0.5638 - val_loss: 0.6803 - val_accuracy: 0.5663 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6700 - accuracy: 0.5788 - val_loss: 0.6810 - val_accuracy: 0.5962 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.6667 - accuracy: 0.5879 - val_loss: 0.6818 - val_accuracy: 0.5462 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6707 - accuracy: 0.5817 - val_loss: 0.6891 - val_accuracy: 0.5450 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6637 - accuracy: 0.5898 - val_loss: 0.6829 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6650 - accuracy: 0.6014 - val_loss: 0.6830 - val_accuracy: 0.5638 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6582 - accuracy: 0.5942 - val_loss: 0.6798 - val_accuracy: 0.5512 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6572 - accuracy: 0.5939 - val_loss: 0.6885 - val_accuracy: 0.5350 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6563 - accuracy: 0.5986 - val_loss: 0.6739 - val_accuracy: 0.5850 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6499 - accuracy: 0.6111 - val_loss: 0.6784 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6411 - accuracy: 0.6161 - val_loss: 0.6948 - val_accuracy: 0.5562 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6449 - accuracy: 0.6311 - val_loss: 0.6781 - val_accuracy: 0.5863 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6322 - accuracy: 0.6377 - val_loss: 0.6772 - val_accuracy: 0.5838 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6298 - accuracy: 0.6380 - val_loss: 0.6826 - val_accuracy: 0.5775 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6261 - accuracy: 0.6424 - val_loss: 0.6760 - val_accuracy: 0.5925 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6251 - accuracy: 0.6408 - val_loss: 0.6686 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6172 - accuracy: 0.6505 - val_loss: 0.6716 - val_accuracy: 0.5987 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6118 - accuracy: 0.6492 - val_loss: 0.6795 - val_accuracy: 0.5987 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6092 - accuracy: 0.6568 - val_loss: 0.6758 - val_accuracy: 0.5875 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6112 - accuracy: 0.6593 - val_loss: 0.6863 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5995 - accuracy: 0.6661 - val_loss: 0.6662 - val_accuracy: 0.6137 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5873 - accuracy: 0.6677 - val_loss: 0.6580 - val_accuracy: 0.6200 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5808 - accuracy: 0.6874 - val_loss: 0.6557 - val_accuracy: 0.6288 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5757 - accuracy: 0.6837 - val_loss: 0.6670 - val_accuracy: 0.6263 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5787 - accuracy: 0.6746 - val_loss: 0.6768 - val_accuracy: 0.6150 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5687 - accuracy: 0.6999 - val_loss: 0.6659 - val_accuracy: 0.6225 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5582 - accuracy: 0.6962 - val_loss: 0.6559 - val_accuracy: 0.6100 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5568 - accuracy: 0.6990 - val_loss: 0.6940 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5618 - accuracy: 0.6924 - val_loss: 0.6540 - val_accuracy: 0.6375 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5380 - accuracy: 0.7159 - val_loss: 0.6623 - val_accuracy: 0.6175 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5355 - accuracy: 0.7131 - val_loss: 0.6699 - val_accuracy: 0.6263 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5257 - accuracy: 0.7162 - val_loss: 0.6575 - val_accuracy: 0.6513 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5159 - accuracy: 0.7234 - val_loss: 0.6386 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5059 - accuracy: 0.7390 - val_loss: 0.6643 - val_accuracy: 0.6400 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5098 - accuracy: 0.7253 - val_loss: 0.6719 - val_accuracy: 0.6513 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4943 - accuracy: 0.7369 - val_loss: 0.6468 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4999 - accuracy: 0.7425 - val_loss: 0.7145 - val_accuracy: 0.6012 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4905 - accuracy: 0.7362 - val_loss: 0.6586 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4711 - accuracy: 0.7519 - val_loss: 0.6749 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4627 - accuracy: 0.7538 - val_loss: 0.6861 - val_accuracy: 0.6350 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4520 - accuracy: 0.7559 - val_loss: 0.7044 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4634 - accuracy: 0.7631 - val_loss: 0.7025 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4626 - accuracy: 0.7594 - val_loss: 0.6667 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4311 - accuracy: 0.7800 - val_loss: 0.7239 - val_accuracy: 0.6525 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4396 - accuracy: 0.7728 - val_loss: 0.7038 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4287 - accuracy: 0.7894 - val_loss: 0.6687 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4008 - accuracy: 0.7957 - val_loss: 0.6920 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4046 - accuracy: 0.7944 - val_loss: 0.7240 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3921 - accuracy: 0.8010 - val_loss: 0.6971 - val_accuracy: 0.6775 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3654 - accuracy: 0.8088 - val_loss: 0.6944 - val_accuracy: 0.6900 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3540 - accuracy: 0.8204 - val_loss: 0.7180 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3700 - accuracy: 0.8176 - val_loss: 0.6804 - val_accuracy: 0.6950 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3585 - accuracy: 0.8254 - val_loss: 0.7080 - val_accuracy: 0.6825 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3536 - accuracy: 0.8254 - val_loss: 0.7365 - val_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3812 - accuracy: 0.8107 - val_loss: 0.7301 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3283 - accuracy: 0.8382 - val_loss: 0.7177 - val_accuracy: 0.7013 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3375 - accuracy: 0.8342 - val_loss: 0.7132 - val_accuracy: 0.6963 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3306 - accuracy: 0.8401 - val_loss: 0.8005 - val_accuracy: 0.6925 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3516 - accuracy: 0.8332 - val_loss: 0.6818 - val_accuracy: 0.6950 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3150 - accuracy: 0.8526 - val_loss: 0.7464 - val_accuracy: 0.6950 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2933 - accuracy: 0.8611 - val_loss: 0.7811 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2946 - accuracy: 0.8655 - val_loss: 0.7593 - val_accuracy: 0.6862 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2888 - accuracy: 0.8623 - val_loss: 0.7830 - val_accuracy: 0.7025 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2754 - accuracy: 0.8705 - val_loss: 0.7476 - val_accuracy: 0.7075 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2812 - accuracy: 0.8698 - val_loss: 0.7204 - val_accuracy: 0.7163 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2528 - accuracy: 0.8880 - val_loss: 0.7565 - val_accuracy: 0.7125 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2687 - accuracy: 0.8830 - val_loss: 0.7608 - val_accuracy: 0.7150 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2584 - accuracy: 0.8770 - val_loss: 0.8853 - val_accuracy: 0.6850 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2545 - accuracy: 0.8820 - val_loss: 0.7923 - val_accuracy: 0.7013 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2369 - accuracy: 0.8902 - val_loss: 0.7497 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2457 - accuracy: 0.8855 - val_loss: 0.7712 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2295 - accuracy: 0.8942 - val_loss: 0.8328 - val_accuracy: 0.7113 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2121 - accuracy: 0.9080 - val_loss: 0.8070 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2048 - accuracy: 0.9105 - val_loss: 0.8614 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2128 - accuracy: 0.9077 - val_loss: 0.8144 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2012 - accuracy: 0.9140 - val_loss: 0.8777 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1723 - accuracy: 0.9280 - val_loss: 0.8507 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2191 - accuracy: 0.9089 - val_loss: 0.7340 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2179 - accuracy: 0.9193 - val_loss: 0.7909 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1848 - accuracy: 0.9221 - val_loss: 0.8037 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2003 - accuracy: 0.9180 - val_loss: 0.8145 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1719 - accuracy: 0.9271 - val_loss: 0.8887 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1841 - accuracy: 0.9230 - val_loss: 0.8822 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1766 - accuracy: 0.9305 - val_loss: 0.8235 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2113 - accuracy: 0.9155 - val_loss: 0.8291 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1499 - accuracy: 0.9406 - val_loss: 0.8802 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1445 - accuracy: 0.9434 - val_loss: 0.8831 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1564 - accuracy: 0.9393 - val_loss: 0.8335 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1322 - accuracy: 0.9446 - val_loss: 0.9162 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1334 - accuracy: 0.9465 - val_loss: 0.8606 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1187 - accuracy: 0.9518 - val_loss: 1.0042 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1491 - accuracy: 0.9452 - val_loss: 0.8888 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1174 - accuracy: 0.9549 - val_loss: 0.8356 - val_accuracy: 0.7800 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1228 - accuracy: 0.9543 - val_loss: 0.9561 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1348 - accuracy: 0.9509 - val_loss: 0.9705 - val_accuracy: 0.7362 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1171 - accuracy: 0.9574 - val_loss: 0.9605 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1067 - accuracy: 0.9574 - val_loss: 1.0223 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0915 - accuracy: 0.9643 - val_loss: 1.0088 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1120 - accuracy: 0.9559 - val_loss: 1.0014 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1064 - accuracy: 0.9565 - val_loss: 0.9233 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0915 - accuracy: 0.9650 - val_loss: 0.9712 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0748 - accuracy: 0.9725 - val_loss: 1.0243 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.1052 - accuracy: 0.9609 - val_loss: 1.0157 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.0871 - accuracy: 0.9681 - val_loss: 1.0486 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.1013 - accuracy: 0.9621 - val_loss: 0.9641 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.0986 - accuracy: 0.9606 - val_loss: 0.9817 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.0880 - accuracy: 0.9662 - val_loss: 1.0979 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 3s 30ms/step - loss: 0.0745 - accuracy: 0.9709 - val_loss: 1.0594 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.0724 - accuracy: 0.9703 - val_loss: 1.1110 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.1014 - accuracy: 0.9681 - val_loss: 1.0196 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0708 - accuracy: 0.9775 - val_loss: 1.1481 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0796 - accuracy: 0.9740 - val_loss: 1.0183 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0745 - accuracy: 0.9734 - val_loss: 1.1334 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0704 - accuracy: 0.9784 - val_loss: 1.1425 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0917 - accuracy: 0.9681 - val_loss: 1.0088 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0722 - accuracy: 0.9750 - val_loss: 1.1447 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0695 - accuracy: 0.9756 - val_loss: 1.0409 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0725 - accuracy: 0.9737 - val_loss: 0.9952 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0476 - accuracy: 0.9840 - val_loss: 1.1674 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0683 - accuracy: 0.9731 - val_loss: 1.0530 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0732 - accuracy: 0.9737 - val_loss: 1.1882 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0856 - accuracy: 0.9703 - val_loss: 1.1142 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1118 - accuracy: 0.9634 - val_loss: 1.0225 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0634 - accuracy: 0.9797 - val_loss: 1.0764 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0641 - accuracy: 0.9784 - val_loss: 1.1159 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0481 - accuracy: 0.9875 - val_loss: 1.1753 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0424 - accuracy: 0.9872 - val_loss: 1.2200 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 149/500\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9853\n",
            "Epoch 149: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0457 - accuracy: 0.9850 - val_loss: 1.2798 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 1.1937 - val_accuracy: 0.7513 - lr: 1.0000e-04\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 1.1817 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0200 - accuracy: 0.9953 - val_loss: 1.1929 - val_accuracy: 0.7638 - lr: 1.0000e-04\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0212 - accuracy: 0.9941 - val_loss: 1.2186 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 1.2274 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 1.2433 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0188 - accuracy: 0.9956 - val_loss: 1.2324 - val_accuracy: 0.7675 - lr: 1.0000e-04\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 1.2484 - val_accuracy: 0.7700 - lr: 1.0000e-04\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0158 - accuracy: 0.9966 - val_loss: 1.2736 - val_accuracy: 0.7700 - lr: 1.0000e-04\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 1.2562 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 1.2673 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 1.2516 - val_accuracy: 0.7725 - lr: 1.0000e-04\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 1.3096 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 1.3120 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 1.3051 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 1.3313 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 1.3626 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 1.3444 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0156 - accuracy: 0.9959 - val_loss: 1.3611 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 1.3401 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 1.3530 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 1.3523 - val_accuracy: 0.7725 - lr: 1.0000e-04\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 1.3933 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 1.3885 - val_accuracy: 0.7638 - lr: 1.0000e-04\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 1.3774 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0104 - accuracy: 0.9978 - val_loss: 1.3724 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 1.3899 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 1.4017 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.3703 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 1.3861 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 1.3679 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 1.3666 - val_accuracy: 0.7675 - lr: 1.0000e-04\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 1.3982 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 1.3741 - val_accuracy: 0.7700 - lr: 1.0000e-04\n",
            "Epoch 184/500\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9968\n",
            "Epoch 184: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 1.4109 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 1.4133 - val_accuracy: 0.7675 - lr: 1.0000e-05\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 1.4200 - val_accuracy: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 1.4218 - val_accuracy: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 1.4215 - val_accuracy: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 1.4172 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 1.4159 - val_accuracy: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 1.4190 - val_accuracy: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 1.4218 - val_accuracy: 0.7625 - lr: 1.0000e-05\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 1.4219 - val_accuracy: 0.7625 - lr: 1.0000e-05\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 1.4182 - val_accuracy: 0.7650 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff93c6a6850>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_16.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo1VXgYuHzf_",
        "outputId": "e1611ef9-fc27-471a-b115-b42fba6079f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 7ms/step - loss: 0.8356 - accuracy: 0.7800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.83562171459198, 0.7799999713897705]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(model=model_16,filepath=\"model_16\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj2KZ4jGJLTR",
        "outputId": "dc56023f-4aec-4222-c99a-a22ef4b1b225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKl92NqGIsyB",
        "outputId": "5b32449d-8b5d-401a-f36f-5dc3734ade3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3196, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model_17=Sequential([\n",
        "\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=3,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(64,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.LSTM(8),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_17.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "model_17.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=80,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsFPz354IeMI",
        "outputId": "6040417c-bf2f-4387-fe3d-2beea6dac2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 14s 38ms/step - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6933 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6911 - accuracy: 0.5341 - val_loss: 0.6889 - val_accuracy: 0.5400 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6925 - accuracy: 0.5163 - val_loss: 0.6949 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6934 - accuracy: 0.4978 - val_loss: 0.6940 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6926 - accuracy: 0.5053 - val_loss: 0.6959 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6921 - accuracy: 0.5150 - val_loss: 0.6901 - val_accuracy: 0.5575 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6894 - accuracy: 0.5372 - val_loss: 0.6867 - val_accuracy: 0.5450 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6864 - accuracy: 0.5369 - val_loss: 0.6861 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6843 - accuracy: 0.5394 - val_loss: 0.6862 - val_accuracy: 0.5612 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6839 - accuracy: 0.5557 - val_loss: 0.6826 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6811 - accuracy: 0.5488 - val_loss: 0.6843 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6808 - accuracy: 0.5404 - val_loss: 0.6829 - val_accuracy: 0.5612 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6792 - accuracy: 0.5582 - val_loss: 0.6813 - val_accuracy: 0.5612 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6764 - accuracy: 0.5635 - val_loss: 0.6786 - val_accuracy: 0.5688 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6766 - accuracy: 0.5591 - val_loss: 0.6809 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6752 - accuracy: 0.5635 - val_loss: 0.6813 - val_accuracy: 0.5900 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6725 - accuracy: 0.5695 - val_loss: 0.6817 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6700 - accuracy: 0.5763 - val_loss: 0.6679 - val_accuracy: 0.6062 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6686 - accuracy: 0.5804 - val_loss: 0.6678 - val_accuracy: 0.5975 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6643 - accuracy: 0.5857 - val_loss: 0.6690 - val_accuracy: 0.6137 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6639 - accuracy: 0.5892 - val_loss: 0.6665 - val_accuracy: 0.5838 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6617 - accuracy: 0.5964 - val_loss: 0.6631 - val_accuracy: 0.5975 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6585 - accuracy: 0.5936 - val_loss: 0.6612 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6550 - accuracy: 0.5986 - val_loss: 0.6690 - val_accuracy: 0.5850 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6608 - accuracy: 0.5873 - val_loss: 0.6696 - val_accuracy: 0.6050 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6572 - accuracy: 0.5986 - val_loss: 0.6648 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6522 - accuracy: 0.6033 - val_loss: 0.6538 - val_accuracy: 0.6112 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6497 - accuracy: 0.6045 - val_loss: 0.6661 - val_accuracy: 0.5987 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6490 - accuracy: 0.6101 - val_loss: 0.6690 - val_accuracy: 0.6037 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6473 - accuracy: 0.6079 - val_loss: 0.6600 - val_accuracy: 0.5950 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6487 - accuracy: 0.6073 - val_loss: 0.6544 - val_accuracy: 0.6187 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6443 - accuracy: 0.6101 - val_loss: 0.6560 - val_accuracy: 0.6025 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6452 - accuracy: 0.6142 - val_loss: 0.6565 - val_accuracy: 0.6125 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6375 - accuracy: 0.6189 - val_loss: 0.6463 - val_accuracy: 0.6187 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6300 - accuracy: 0.6277 - val_loss: 0.6490 - val_accuracy: 0.6012 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6255 - accuracy: 0.6289 - val_loss: 0.6625 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6251 - accuracy: 0.6349 - val_loss: 0.6538 - val_accuracy: 0.6100 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6237 - accuracy: 0.6292 - val_loss: 0.6537 - val_accuracy: 0.6225 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6189 - accuracy: 0.6339 - val_loss: 0.6605 - val_accuracy: 0.5825 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6106 - accuracy: 0.6527 - val_loss: 0.6483 - val_accuracy: 0.6300 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6146 - accuracy: 0.6477 - val_loss: 0.6493 - val_accuracy: 0.6237 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6062 - accuracy: 0.6496 - val_loss: 0.6569 - val_accuracy: 0.6100 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5971 - accuracy: 0.6549 - val_loss: 0.6499 - val_accuracy: 0.6150 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6005 - accuracy: 0.6571 - val_loss: 0.6553 - val_accuracy: 0.6112 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5888 - accuracy: 0.6740 - val_loss: 0.6551 - val_accuracy: 0.5875 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5851 - accuracy: 0.6640 - val_loss: 0.6477 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5773 - accuracy: 0.6821 - val_loss: 0.6440 - val_accuracy: 0.6363 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5712 - accuracy: 0.6843 - val_loss: 0.6694 - val_accuracy: 0.5950 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5646 - accuracy: 0.6971 - val_loss: 0.6439 - val_accuracy: 0.6400 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5625 - accuracy: 0.6940 - val_loss: 0.6395 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5468 - accuracy: 0.7115 - val_loss: 0.6493 - val_accuracy: 0.6212 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5421 - accuracy: 0.7121 - val_loss: 0.6606 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5309 - accuracy: 0.7243 - val_loss: 0.6552 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5292 - accuracy: 0.7272 - val_loss: 0.6417 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5269 - accuracy: 0.7268 - val_loss: 0.6404 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5002 - accuracy: 0.7494 - val_loss: 0.6646 - val_accuracy: 0.6425 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5027 - accuracy: 0.7422 - val_loss: 0.6582 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4789 - accuracy: 0.7728 - val_loss: 0.6781 - val_accuracy: 0.6525 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4771 - accuracy: 0.7691 - val_loss: 0.6822 - val_accuracy: 0.6463 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4692 - accuracy: 0.7747 - val_loss: 0.6876 - val_accuracy: 0.6612 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4646 - accuracy: 0.7829 - val_loss: 0.6727 - val_accuracy: 0.6675 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4477 - accuracy: 0.7947 - val_loss: 0.6817 - val_accuracy: 0.6812 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4397 - accuracy: 0.7972 - val_loss: 0.6866 - val_accuracy: 0.6675 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4305 - accuracy: 0.8076 - val_loss: 0.7111 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4256 - accuracy: 0.8082 - val_loss: 0.6867 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4067 - accuracy: 0.8248 - val_loss: 0.7092 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4091 - accuracy: 0.8151 - val_loss: 0.7095 - val_accuracy: 0.6900 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3958 - accuracy: 0.8285 - val_loss: 0.7109 - val_accuracy: 0.6900 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3841 - accuracy: 0.8382 - val_loss: 0.7155 - val_accuracy: 0.6900 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3737 - accuracy: 0.8385 - val_loss: 0.7073 - val_accuracy: 0.7063 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3571 - accuracy: 0.8536 - val_loss: 0.7329 - val_accuracy: 0.6950 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3589 - accuracy: 0.8533 - val_loss: 0.7539 - val_accuracy: 0.6913 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3423 - accuracy: 0.8617 - val_loss: 0.7244 - val_accuracy: 0.7025 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3460 - accuracy: 0.8551 - val_loss: 0.7297 - val_accuracy: 0.6963 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3169 - accuracy: 0.8714 - val_loss: 0.7752 - val_accuracy: 0.6900 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3134 - accuracy: 0.8711 - val_loss: 0.7416 - val_accuracy: 0.6900 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3220 - accuracy: 0.8702 - val_loss: 0.7330 - val_accuracy: 0.7163 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3005 - accuracy: 0.8805 - val_loss: 0.7118 - val_accuracy: 0.7175 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2878 - accuracy: 0.8914 - val_loss: 0.7372 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2867 - accuracy: 0.8895 - val_loss: 0.7544 - val_accuracy: 0.7212 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2752 - accuracy: 0.8946 - val_loss: 0.6690 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3154 - accuracy: 0.8742 - val_loss: 0.6878 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2706 - accuracy: 0.8949 - val_loss: 0.7296 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2618 - accuracy: 0.9030 - val_loss: 0.7315 - val_accuracy: 0.7200 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2350 - accuracy: 0.9143 - val_loss: 0.7561 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2727 - accuracy: 0.8942 - val_loss: 0.7769 - val_accuracy: 0.7175 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2185 - accuracy: 0.9183 - val_loss: 0.7458 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2451 - accuracy: 0.9074 - val_loss: 0.7243 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2036 - accuracy: 0.9255 - val_loss: 0.7937 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2189 - accuracy: 0.9193 - val_loss: 0.7868 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2127 - accuracy: 0.9218 - val_loss: 0.7406 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1955 - accuracy: 0.9277 - val_loss: 0.8196 - val_accuracy: 0.7212 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2085 - accuracy: 0.9237 - val_loss: 0.7858 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2059 - accuracy: 0.9240 - val_loss: 0.8072 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2048 - accuracy: 0.9258 - val_loss: 0.8307 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1751 - accuracy: 0.9390 - val_loss: 0.7660 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1730 - accuracy: 0.9380 - val_loss: 0.7946 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1676 - accuracy: 0.9393 - val_loss: 0.8348 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1561 - accuracy: 0.9449 - val_loss: 0.8838 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1550 - accuracy: 0.9481 - val_loss: 0.8995 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1644 - accuracy: 0.9434 - val_loss: 0.8352 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1457 - accuracy: 0.9515 - val_loss: 0.8344 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1399 - accuracy: 0.9524 - val_loss: 0.9257 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1445 - accuracy: 0.9515 - val_loss: 0.8680 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1582 - accuracy: 0.9468 - val_loss: 0.9024 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1425 - accuracy: 0.9490 - val_loss: 0.8575 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1341 - accuracy: 0.9506 - val_loss: 0.8503 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1369 - accuracy: 0.9543 - val_loss: 0.8888 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1485 - accuracy: 0.9493 - val_loss: 0.8377 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1275 - accuracy: 0.9574 - val_loss: 0.8361 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1321 - accuracy: 0.9515 - val_loss: 0.7838 - val_accuracy: 0.7763 - lr: 0.0010\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1278 - accuracy: 0.9574 - val_loss: 0.8751 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1448 - accuracy: 0.9481 - val_loss: 0.8718 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1167 - accuracy: 0.9590 - val_loss: 0.9663 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1111 - accuracy: 0.9634 - val_loss: 0.8319 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1312 - accuracy: 0.9546 - val_loss: 0.9353 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1209 - accuracy: 0.9581 - val_loss: 0.8184 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0963 - accuracy: 0.9659 - val_loss: 1.0046 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0772 - accuracy: 0.9768 - val_loss: 0.9099 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0844 - accuracy: 0.9722 - val_loss: 0.9272 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0979 - accuracy: 0.9681 - val_loss: 0.8555 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0966 - accuracy: 0.9659 - val_loss: 0.9485 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1135 - accuracy: 0.9599 - val_loss: 1.0387 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1075 - accuracy: 0.9640 - val_loss: 0.9196 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0851 - accuracy: 0.9734 - val_loss: 0.9529 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0608 - accuracy: 0.9812 - val_loss: 0.9993 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0640 - accuracy: 0.9800 - val_loss: 1.0548 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1020 - accuracy: 0.9628 - val_loss: 0.9672 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1049 - accuracy: 0.9625 - val_loss: 0.8749 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0869 - accuracy: 0.9737 - val_loss: 0.8622 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0741 - accuracy: 0.9775 - val_loss: 0.9140 - val_accuracy: 0.7837 - lr: 0.0010\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0857 - accuracy: 0.9684 - val_loss: 0.9616 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1068 - accuracy: 0.9618 - val_loss: 0.8791 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0670 - accuracy: 0.9762 - val_loss: 0.9417 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0892 - accuracy: 0.9703 - val_loss: 0.9149 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0655 - accuracy: 0.9793 - val_loss: 0.9937 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0657 - accuracy: 0.9793 - val_loss: 0.9865 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0497 - accuracy: 0.9847 - val_loss: 1.0423 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0484 - accuracy: 0.9837 - val_loss: 1.0073 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0497 - accuracy: 0.9828 - val_loss: 1.0645 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0554 - accuracy: 0.9819 - val_loss: 1.0065 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0589 - accuracy: 0.9806 - val_loss: 0.9376 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0939 - accuracy: 0.9706 - val_loss: 0.8941 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0678 - accuracy: 0.9775 - val_loss: 1.0475 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0434 - accuracy: 0.9850 - val_loss: 1.0810 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0392 - accuracy: 0.9881 - val_loss: 1.3024 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0615 - accuracy: 0.9800 - val_loss: 1.1014 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0963 - accuracy: 0.9675 - val_loss: 0.8958 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0579 - accuracy: 0.9797 - val_loss: 1.0331 - val_accuracy: 0.7800 - lr: 0.0010\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 1.1472 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0542 - accuracy: 0.9815 - val_loss: 1.0092 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0632 - accuracy: 0.9819 - val_loss: 1.0446 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0644 - accuracy: 0.9815 - val_loss: 1.0328 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0510 - accuracy: 0.9840 - val_loss: 1.1118 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0499 - accuracy: 0.9819 - val_loss: 1.0153 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0532 - accuracy: 0.9831 - val_loss: 1.0480 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0560 - accuracy: 0.9837 - val_loss: 1.0348 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0626 - accuracy: 0.9793 - val_loss: 0.9141 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0646 - accuracy: 0.9800 - val_loss: 0.9185 - val_accuracy: 0.7825 - lr: 0.0010\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0595 - accuracy: 0.9812 - val_loss: 1.0610 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0366 - accuracy: 0.9903 - val_loss: 1.0074 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0469 - accuracy: 0.9865 - val_loss: 1.1455 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0486 - accuracy: 0.9847 - val_loss: 1.0470 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0478 - accuracy: 0.9859 - val_loss: 1.0199 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0331 - accuracy: 0.9900 - val_loss: 1.0932 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 175/500\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9902\n",
            "Epoch 175: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 1.1038 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0218 - accuracy: 0.9912 - val_loss: 1.0858 - val_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 1.0965 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 1.1011 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0119 - accuracy: 0.9950 - val_loss: 1.1063 - val_accuracy: 0.7887 - lr: 1.0000e-04\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 1.1147 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 1.1112 - val_accuracy: 0.7887 - lr: 1.0000e-04\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 1.1306 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 1.1495 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 1.1404 - val_accuracy: 0.7837 - lr: 1.0000e-04\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 1.1484 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 1.1725 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 1.1805 - val_accuracy: 0.7825 - lr: 1.0000e-04\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 1.1847 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0132 - accuracy: 0.9972 - val_loss: 1.1862 - val_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 1.1893 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.1969 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 1.1873 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 1.1911 - val_accuracy: 0.7825 - lr: 1.0000e-04\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 1.2075 - val_accuracy: 0.7825 - lr: 1.0000e-04\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 1.2126 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 1.2044 - val_accuracy: 0.7875 - lr: 1.0000e-04\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 1.2040 - val_accuracy: 0.7825 - lr: 1.0000e-04\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 1.2063 - val_accuracy: 0.7837 - lr: 1.0000e-04\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 1.2102 - val_accuracy: 0.7887 - lr: 1.0000e-04\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 1.2016 - val_accuracy: 0.7887 - lr: 1.0000e-04\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 1.2464 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 1.2545 - val_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 1.2454 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 1.2636 - val_accuracy: 0.7837 - lr: 1.0000e-04\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 1.2719 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.2368 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 1.2445 - val_accuracy: 0.7825 - lr: 1.0000e-04\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0072 - accuracy: 0.9969 - val_loss: 1.2717 - val_accuracy: 0.7837 - lr: 1.0000e-04\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 1.2871 - val_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 1.2508 - val_accuracy: 0.7875 - lr: 1.0000e-04\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 1.2636 - val_accuracy: 0.7900 - lr: 1.0000e-04\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 1.2724 - val_accuracy: 0.7875 - lr: 1.0000e-04\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 1.2812 - val_accuracy: 0.7887 - lr: 1.0000e-04\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 1.2972 - val_accuracy: 0.7825 - lr: 1.0000e-04\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 1.2906 - val_accuracy: 0.7887 - lr: 1.0000e-04\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 1.2731 - val_accuracy: 0.7837 - lr: 1.0000e-04\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 1.2830 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 1.2899 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 1.2889 - val_accuracy: 0.7825 - lr: 1.0000e-04\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0058 - accuracy: 0.9978 - val_loss: 1.3012 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 1.3126 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 1.3062 - val_accuracy: 0.7875 - lr: 1.0000e-04\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 1.2929 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0048 - accuracy: 0.9978 - val_loss: 1.2839 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 1.2905 - val_accuracy: 0.7837 - lr: 1.0000e-04\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 1.3166 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 1.3081 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0061 - accuracy: 0.9975 - val_loss: 1.2968 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 1.2967 - val_accuracy: 0.7875 - lr: 1.0000e-04\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 1.3020 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 1.3257 - val_accuracy: 0.7825 - lr: 1.0000e-04\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.2901 - val_accuracy: 0.7875 - lr: 1.0000e-04\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 1.2974 - val_accuracy: 0.7887 - lr: 1.0000e-04\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 1.3174 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0092 - accuracy: 0.9966 - val_loss: 1.3298 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.3118 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 1.3319 - val_accuracy: 0.7825 - lr: 1.0000e-04\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 1.3254 - val_accuracy: 0.7750 - lr: 1.0000e-04\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 1.3066 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 1.3233 - val_accuracy: 0.7837 - lr: 1.0000e-04\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0061 - accuracy: 0.9975 - val_loss: 1.3396 - val_accuracy: 0.7825 - lr: 1.0000e-04\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 1.3451 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 1.3369 - val_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 1.3498 - val_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 1.3470 - val_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 246/500\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9981\n",
            "Epoch 246: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0046 - accuracy: 0.9981 - val_loss: 1.3215 - val_accuracy: 0.7875 - lr: 1.0000e-04\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 1.3242 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 1.3247 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 1.3222 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.3217 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 1.3220 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 1.3238 - val_accuracy: 0.7900 - lr: 1.0000e-05\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 1.3290 - val_accuracy: 0.7875 - lr: 1.0000e-05\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 1.3307 - val_accuracy: 0.7887 - lr: 1.0000e-05\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.3308 - val_accuracy: 0.7875 - lr: 1.0000e-05\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 1.3320 - val_accuracy: 0.7875 - lr: 1.0000e-05\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 1.3323 - val_accuracy: 0.7875 - lr: 1.0000e-05\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 1.3347 - val_accuracy: 0.7837 - lr: 1.0000e-05\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 1.3382 - val_accuracy: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 1.3391 - val_accuracy: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 1.3387 - val_accuracy: 0.7837 - lr: 1.0000e-05\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 1.3371 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 1.3403 - val_accuracy: 0.7850 - lr: 1.0000e-05\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 1.3407 - val_accuracy: 0.7837 - lr: 1.0000e-05\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 1.3420 - val_accuracy: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 1.3413 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 1.3425 - val_accuracy: 0.7850 - lr: 1.0000e-05\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 1.3413 - val_accuracy: 0.7875 - lr: 1.0000e-05\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 1.3457 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3475 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 1.3478 - val_accuracy: 0.7850 - lr: 1.0000e-05\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 1.3486 - val_accuracy: 0.7850 - lr: 1.0000e-05\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 1.3498 - val_accuracy: 0.7850 - lr: 1.0000e-05\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 1.3526 - val_accuracy: 0.7837 - lr: 1.0000e-05\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 1.3494 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 1.3481 - val_accuracy: 0.7875 - lr: 1.0000e-05\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 1.3499 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 1.3488 - val_accuracy: 0.7875 - lr: 1.0000e-05\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.3482 - val_accuracy: 0.7887 - lr: 1.0000e-05\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 1.3497 - val_accuracy: 0.7887 - lr: 1.0000e-05\n",
            "Epoch 281/500\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9990\n",
            "Epoch 281: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 1.3489 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 1.3488 - val_accuracy: 0.7862 - lr: 1.0000e-06\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 1.3485 - val_accuracy: 0.7862 - lr: 1.0000e-06\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0055 - accuracy: 0.9975 - val_loss: 1.3485 - val_accuracy: 0.7862 - lr: 1.0000e-06\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 1.3485 - val_accuracy: 0.7862 - lr: 1.0000e-06\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3487 - val_accuracy: 0.7862 - lr: 1.0000e-06\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 1.3489 - val_accuracy: 0.7862 - lr: 1.0000e-06\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3491 - val_accuracy: 0.7862 - lr: 1.0000e-06\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 1.3493 - val_accuracy: 0.7850 - lr: 1.0000e-06\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 1.3493 - val_accuracy: 0.7850 - lr: 1.0000e-06\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 1.3494 - val_accuracy: 0.7850 - lr: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff8c5a34640>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(model=model_17,filepath=\"model_17\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bANE5R1ROkLa",
        "outputId": "4283531e-dacc-428b-c733-6eaeac5fa129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_17.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfiMmdIEOfU8",
        "outputId": "5434d21a-a90e-43d6-8554-d6a0991da0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 6ms/step - loss: 1.2636 - accuracy: 0.7900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2636141777038574, 0.7900000214576721]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model_18=Sequential([\n",
        "\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=3,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(64,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.LSTM(8),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_18.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "model_18.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=80,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "num792uTPexP",
        "outputId": "da5fd8e7-0bbf-4c82-b0bf-2b81df195eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 15s 35ms/step - loss: 0.6933 - accuracy: 0.5013 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6924 - accuracy: 0.5025 - val_loss: 0.6907 - val_accuracy: 0.4913 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6892 - accuracy: 0.5188 - val_loss: 0.6859 - val_accuracy: 0.5713 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6837 - accuracy: 0.5507 - val_loss: 0.6812 - val_accuracy: 0.5638 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6826 - accuracy: 0.5497 - val_loss: 0.6857 - val_accuracy: 0.5725 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6792 - accuracy: 0.5588 - val_loss: 0.6780 - val_accuracy: 0.5725 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6790 - accuracy: 0.5673 - val_loss: 0.6791 - val_accuracy: 0.5587 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6757 - accuracy: 0.5591 - val_loss: 0.6750 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6734 - accuracy: 0.5792 - val_loss: 0.6765 - val_accuracy: 0.5688 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6727 - accuracy: 0.5748 - val_loss: 0.6783 - val_accuracy: 0.5587 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6710 - accuracy: 0.5713 - val_loss: 0.6778 - val_accuracy: 0.5713 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6669 - accuracy: 0.5823 - val_loss: 0.6698 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6686 - accuracy: 0.5920 - val_loss: 0.6655 - val_accuracy: 0.5763 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6620 - accuracy: 0.5867 - val_loss: 0.6620 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6573 - accuracy: 0.5929 - val_loss: 0.6608 - val_accuracy: 0.5888 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6499 - accuracy: 0.6045 - val_loss: 0.6714 - val_accuracy: 0.5987 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6455 - accuracy: 0.6076 - val_loss: 0.6460 - val_accuracy: 0.5975 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6354 - accuracy: 0.6164 - val_loss: 0.6538 - val_accuracy: 0.6200 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6370 - accuracy: 0.6167 - val_loss: 0.6649 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6360 - accuracy: 0.6130 - val_loss: 0.6434 - val_accuracy: 0.6263 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6264 - accuracy: 0.6236 - val_loss: 0.6434 - val_accuracy: 0.6225 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6230 - accuracy: 0.6395 - val_loss: 0.6510 - val_accuracy: 0.6162 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6131 - accuracy: 0.6424 - val_loss: 0.6377 - val_accuracy: 0.6237 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6093 - accuracy: 0.6527 - val_loss: 0.6445 - val_accuracy: 0.6175 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6120 - accuracy: 0.6527 - val_loss: 0.6259 - val_accuracy: 0.6338 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5965 - accuracy: 0.6599 - val_loss: 0.6134 - val_accuracy: 0.6388 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5901 - accuracy: 0.6621 - val_loss: 0.6245 - val_accuracy: 0.6400 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5816 - accuracy: 0.6783 - val_loss: 0.6175 - val_accuracy: 0.6612 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5773 - accuracy: 0.6708 - val_loss: 0.6093 - val_accuracy: 0.6712 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5740 - accuracy: 0.6843 - val_loss: 0.6243 - val_accuracy: 0.6438 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5681 - accuracy: 0.6890 - val_loss: 0.6088 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5569 - accuracy: 0.6952 - val_loss: 0.6161 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5523 - accuracy: 0.7037 - val_loss: 0.6112 - val_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5346 - accuracy: 0.7137 - val_loss: 0.6152 - val_accuracy: 0.6300 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5244 - accuracy: 0.7284 - val_loss: 0.5967 - val_accuracy: 0.6837 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5139 - accuracy: 0.7306 - val_loss: 0.6135 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5013 - accuracy: 0.7331 - val_loss: 0.6476 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5035 - accuracy: 0.7400 - val_loss: 0.5979 - val_accuracy: 0.6875 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4793 - accuracy: 0.7491 - val_loss: 0.6064 - val_accuracy: 0.7025 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4711 - accuracy: 0.7635 - val_loss: 0.5983 - val_accuracy: 0.6950 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4629 - accuracy: 0.7747 - val_loss: 0.6047 - val_accuracy: 0.7063 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4541 - accuracy: 0.7719 - val_loss: 0.6129 - val_accuracy: 0.6875 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4251 - accuracy: 0.7932 - val_loss: 0.6014 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4115 - accuracy: 0.7972 - val_loss: 0.6298 - val_accuracy: 0.7063 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4164 - accuracy: 0.8082 - val_loss: 0.6105 - val_accuracy: 0.7138 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4124 - accuracy: 0.8132 - val_loss: 0.6264 - val_accuracy: 0.7125 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3797 - accuracy: 0.8260 - val_loss: 0.6488 - val_accuracy: 0.7038 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3835 - accuracy: 0.8235 - val_loss: 0.6177 - val_accuracy: 0.7212 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3751 - accuracy: 0.8279 - val_loss: 0.6283 - val_accuracy: 0.7100 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3597 - accuracy: 0.8398 - val_loss: 0.6415 - val_accuracy: 0.7100 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3659 - accuracy: 0.8404 - val_loss: 0.6820 - val_accuracy: 0.6938 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3547 - accuracy: 0.8354 - val_loss: 0.6756 - val_accuracy: 0.7312 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.3437 - accuracy: 0.8442 - val_loss: 0.6125 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3173 - accuracy: 0.8601 - val_loss: 0.6217 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3106 - accuracy: 0.8664 - val_loss: 0.6505 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3046 - accuracy: 0.8630 - val_loss: 0.6603 - val_accuracy: 0.7362 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2859 - accuracy: 0.8780 - val_loss: 0.6544 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2721 - accuracy: 0.8798 - val_loss: 0.6662 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2720 - accuracy: 0.8758 - val_loss: 0.6821 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2644 - accuracy: 0.8845 - val_loss: 0.7027 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2540 - accuracy: 0.8914 - val_loss: 0.6938 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2472 - accuracy: 0.8936 - val_loss: 0.7296 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2443 - accuracy: 0.8952 - val_loss: 0.7762 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2215 - accuracy: 0.9068 - val_loss: 0.7221 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2196 - accuracy: 0.9093 - val_loss: 0.7720 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2286 - accuracy: 0.9033 - val_loss: 0.7872 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2361 - accuracy: 0.9030 - val_loss: 0.7907 - val_accuracy: 0.7312 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1975 - accuracy: 0.9215 - val_loss: 0.8139 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2035 - accuracy: 0.9212 - val_loss: 0.7484 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1877 - accuracy: 0.9221 - val_loss: 0.7720 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1700 - accuracy: 0.9340 - val_loss: 0.7752 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1895 - accuracy: 0.9271 - val_loss: 0.7876 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1734 - accuracy: 0.9359 - val_loss: 0.7770 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1748 - accuracy: 0.9321 - val_loss: 0.8145 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1697 - accuracy: 0.9352 - val_loss: 0.7975 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1723 - accuracy: 0.9346 - val_loss: 0.8101 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1564 - accuracy: 0.9406 - val_loss: 0.8493 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1463 - accuracy: 0.9437 - val_loss: 0.8911 - val_accuracy: 0.7200 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1632 - accuracy: 0.9365 - val_loss: 0.8694 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1534 - accuracy: 0.9431 - val_loss: 0.7392 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1382 - accuracy: 0.9509 - val_loss: 0.8444 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1118 - accuracy: 0.9612 - val_loss: 0.9157 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1091 - accuracy: 0.9574 - val_loss: 0.8829 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1288 - accuracy: 0.9534 - val_loss: 0.8119 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1097 - accuracy: 0.9587 - val_loss: 0.8855 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1101 - accuracy: 0.9615 - val_loss: 0.8805 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1033 - accuracy: 0.9631 - val_loss: 0.8949 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1294 - accuracy: 0.9506 - val_loss: 0.9853 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1269 - accuracy: 0.9543 - val_loss: 0.8595 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1003 - accuracy: 0.9643 - val_loss: 0.9248 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1071 - accuracy: 0.9650 - val_loss: 0.8901 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1052 - accuracy: 0.9640 - val_loss: 0.8984 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0878 - accuracy: 0.9718 - val_loss: 0.9009 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0791 - accuracy: 0.9750 - val_loss: 1.0457 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1157 - accuracy: 0.9593 - val_loss: 0.8972 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0918 - accuracy: 0.9700 - val_loss: 0.9619 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.1162 - accuracy: 0.9584 - val_loss: 0.8771 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0705 - accuracy: 0.9790 - val_loss: 0.9906 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0774 - accuracy: 0.9753 - val_loss: 0.9510 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0979 - accuracy: 0.9665 - val_loss: 0.9589 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0778 - accuracy: 0.9750 - val_loss: 0.9838 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0860 - accuracy: 0.9690 - val_loss: 0.9885 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0880 - accuracy: 0.9722 - val_loss: 0.9869 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0691 - accuracy: 0.9781 - val_loss: 1.0586 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1152 - accuracy: 0.9631 - val_loss: 0.8934 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0615 - accuracy: 0.9828 - val_loss: 0.9569 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0713 - accuracy: 0.9797 - val_loss: 0.9670 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0943 - accuracy: 0.9712 - val_loss: 0.9089 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1029 - accuracy: 0.9653 - val_loss: 0.9120 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0530 - accuracy: 0.9822 - val_loss: 0.9834 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0471 - accuracy: 0.9865 - val_loss: 0.9616 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0526 - accuracy: 0.9834 - val_loss: 0.9515 - val_accuracy: 0.7763 - lr: 0.0010\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0716 - accuracy: 0.9753 - val_loss: 0.9565 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0645 - accuracy: 0.9815 - val_loss: 0.9663 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0503 - accuracy: 0.9862 - val_loss: 0.9336 - val_accuracy: 0.7850 - lr: 0.0010\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0531 - accuracy: 0.9834 - val_loss: 0.9390 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0855 - accuracy: 0.9718 - val_loss: 0.8566 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0926 - accuracy: 0.9743 - val_loss: 0.9871 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0454 - accuracy: 0.9869 - val_loss: 1.0679 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0738 - accuracy: 0.9784 - val_loss: 1.0176 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0772 - accuracy: 0.9759 - val_loss: 0.8406 - val_accuracy: 0.8050 - lr: 0.0010\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0448 - accuracy: 0.9900 - val_loss: 0.9888 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0349 - accuracy: 0.9919 - val_loss: 1.0518 - val_accuracy: 0.7763 - lr: 0.0010\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0580 - accuracy: 0.9853 - val_loss: 0.9481 - val_accuracy: 0.7912 - lr: 0.0010\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0564 - accuracy: 0.9850 - val_loss: 0.9712 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0487 - accuracy: 0.9881 - val_loss: 1.0512 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0594 - accuracy: 0.9822 - val_loss: 0.9672 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0532 - accuracy: 0.9859 - val_loss: 0.9781 - val_accuracy: 0.7887 - lr: 0.0010\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0565 - accuracy: 0.9853 - val_loss: 0.9936 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0566 - accuracy: 0.9834 - val_loss: 0.9750 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0392 - accuracy: 0.9900 - val_loss: 1.0513 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0545 - accuracy: 0.9825 - val_loss: 1.0075 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0461 - accuracy: 0.9875 - val_loss: 0.9033 - val_accuracy: 0.7862 - lr: 0.0010\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0409 - accuracy: 0.9894 - val_loss: 1.0947 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0358 - accuracy: 0.9900 - val_loss: 1.1459 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0494 - accuracy: 0.9872 - val_loss: 1.0558 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0434 - accuracy: 0.9900 - val_loss: 1.0837 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0626 - accuracy: 0.9819 - val_loss: 1.0404 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0456 - accuracy: 0.9881 - val_loss: 1.1009 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0499 - accuracy: 0.9865 - val_loss: 1.0343 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0480 - accuracy: 0.9872 - val_loss: 1.0642 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0250 - accuracy: 0.9934 - val_loss: 1.1816 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0534 - accuracy: 0.9859 - val_loss: 1.1110 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0460 - accuracy: 0.9887 - val_loss: 1.1274 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0387 - accuracy: 0.9906 - val_loss: 1.0413 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0407 - accuracy: 0.9894 - val_loss: 1.1689 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0915 - accuracy: 0.9762 - val_loss: 0.9189 - val_accuracy: 0.7825 - lr: 0.0010\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0679 - accuracy: 0.9793 - val_loss: 1.0215 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0394 - accuracy: 0.9884 - val_loss: 1.1000 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 1.1463 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0450 - accuracy: 0.9878 - val_loss: 1.1430 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0841 - accuracy: 0.9781 - val_loss: 1.0806 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0346 - accuracy: 0.9906 - val_loss: 1.0323 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0300 - accuracy: 0.9928 - val_loss: 1.1571 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0797 - accuracy: 0.9772 - val_loss: 1.0347 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 161/500\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9926\n",
            "Epoch 161: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0352 - accuracy: 0.9928 - val_loss: 1.1063 - val_accuracy: 0.7763 - lr: 0.0010\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.0232 - accuracy: 0.9953 - val_loss: 1.1092 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.0220 - accuracy: 0.9962 - val_loss: 1.1030 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.0226 - accuracy: 0.9959 - val_loss: 1.1006 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 0.0227 - accuracy: 0.9959 - val_loss: 1.0971 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 0.0209 - accuracy: 0.9962 - val_loss: 1.0966 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.0204 - accuracy: 0.9962 - val_loss: 1.0932 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.0201 - accuracy: 0.9959 - val_loss: 1.0996 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.0219 - accuracy: 0.9959 - val_loss: 1.1131 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0186 - accuracy: 0.9966 - val_loss: 1.1119 - val_accuracy: 0.7750 - lr: 1.0000e-04\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 1.1214 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0196 - accuracy: 0.9959 - val_loss: 1.1167 - val_accuracy: 0.7750 - lr: 1.0000e-04\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 1.1179 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0170 - accuracy: 0.9972 - val_loss: 1.1219 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0181 - accuracy: 0.9962 - val_loss: 1.1285 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0180 - accuracy: 0.9959 - val_loss: 1.1276 - val_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0180 - accuracy: 0.9972 - val_loss: 1.1366 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0175 - accuracy: 0.9975 - val_loss: 1.1451 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 1.1625 - val_accuracy: 0.7750 - lr: 1.0000e-04\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0193 - accuracy: 0.9959 - val_loss: 1.1716 - val_accuracy: 0.7725 - lr: 1.0000e-04\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 1.1760 - val_accuracy: 0.7750 - lr: 1.0000e-04\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0159 - accuracy: 0.9975 - val_loss: 1.1887 - val_accuracy: 0.7713 - lr: 1.0000e-04\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0173 - accuracy: 0.9966 - val_loss: 1.1975 - val_accuracy: 0.7700 - lr: 1.0000e-04\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0192 - accuracy: 0.9962 - val_loss: 1.2104 - val_accuracy: 0.7700 - lr: 1.0000e-04\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0201 - accuracy: 0.9959 - val_loss: 1.1767 - val_accuracy: 0.7750 - lr: 1.0000e-04\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0175 - accuracy: 0.9972 - val_loss: 1.1861 - val_accuracy: 0.7713 - lr: 1.0000e-04\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 1.2062 - val_accuracy: 0.7713 - lr: 1.0000e-04\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0185 - accuracy: 0.9962 - val_loss: 1.2115 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0159 - accuracy: 0.9972 - val_loss: 1.2316 - val_accuracy: 0.7700 - lr: 1.0000e-04\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0160 - accuracy: 0.9978 - val_loss: 1.2183 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0164 - accuracy: 0.9978 - val_loss: 1.2262 - val_accuracy: 0.7738 - lr: 1.0000e-04\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0186 - accuracy: 0.9962 - val_loss: 1.2031 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0176 - accuracy: 0.9975 - val_loss: 1.2204 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0154 - accuracy: 0.9978 - val_loss: 1.2525 - val_accuracy: 0.7725 - lr: 1.0000e-04\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0185 - accuracy: 0.9972 - val_loss: 1.3092 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9969\n",
            "Epoch 196: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0178 - accuracy: 0.9969 - val_loss: 1.2905 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0171 - accuracy: 0.9975 - val_loss: 1.2907 - val_accuracy: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0154 - accuracy: 0.9978 - val_loss: 1.2904 - val_accuracy: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0170 - accuracy: 0.9969 - val_loss: 1.2882 - val_accuracy: 0.7663 - lr: 1.0000e-05\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0160 - accuracy: 0.9972 - val_loss: 1.2918 - val_accuracy: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0195 - accuracy: 0.9966 - val_loss: 1.2917 - val_accuracy: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0189 - accuracy: 0.9959 - val_loss: 1.2863 - val_accuracy: 0.7663 - lr: 1.0000e-05\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0172 - accuracy: 0.9972 - val_loss: 1.2864 - val_accuracy: 0.7663 - lr: 1.0000e-05\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0169 - accuracy: 0.9975 - val_loss: 1.2853 - val_accuracy: 0.7663 - lr: 1.0000e-05\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0183 - accuracy: 0.9966 - val_loss: 1.2904 - val_accuracy: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0185 - accuracy: 0.9972 - val_loss: 1.2954 - val_accuracy: 0.7638 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff89dd3e280>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_18.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kub1BGTTQqt0",
        "outputId": "2316e920-6597-4e20-de49-c2a49dec0f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 8ms/step - loss: 0.8406 - accuracy: 0.8050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8405712842941284, 0.8050000071525574]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(model_18,\"model_18\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wyyz9CiQRf0Q",
        "outputId": "04fec9b3-4154-4703-b897-a03d7a6214eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_18_l=tf.keras.models.load_model(\"model_18\")\n",
        "model_18_l.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_0W7nuTRoE6",
        "outputId": "f165ec11-47f7-487c-a280-13746fd592c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 2s 6ms/step - loss: 0.8406 - accuracy: 0.8050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8405712842941284, 0.8050000071525574]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model_19=Sequential([\n",
        "\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=3,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(64,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.LSTM(8),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_19.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "model_19.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=80,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs6lPpR2SaVj",
        "outputId": "32464295-f151-4ba0-a4e6-690e2f241ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 14s 37ms/step - loss: 0.6933 - accuracy: 0.5006 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6929 - accuracy: 0.5034 - val_loss: 0.6918 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6931 - accuracy: 0.5003 - val_loss: 0.6927 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6909 - accuracy: 0.5175 - val_loss: 0.6908 - val_accuracy: 0.5325 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6909 - accuracy: 0.5210 - val_loss: 0.6903 - val_accuracy: 0.5300 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6886 - accuracy: 0.5213 - val_loss: 0.6896 - val_accuracy: 0.5412 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6850 - accuracy: 0.5344 - val_loss: 0.6864 - val_accuracy: 0.5462 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6842 - accuracy: 0.5466 - val_loss: 0.6868 - val_accuracy: 0.5487 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6811 - accuracy: 0.5519 - val_loss: 0.6821 - val_accuracy: 0.5638 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6785 - accuracy: 0.5613 - val_loss: 0.6798 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6762 - accuracy: 0.5641 - val_loss: 0.6805 - val_accuracy: 0.5688 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6744 - accuracy: 0.5576 - val_loss: 0.6794 - val_accuracy: 0.5763 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6728 - accuracy: 0.5782 - val_loss: 0.6875 - val_accuracy: 0.5113 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6717 - accuracy: 0.5666 - val_loss: 0.6820 - val_accuracy: 0.5612 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6710 - accuracy: 0.5770 - val_loss: 0.6770 - val_accuracy: 0.5650 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6729 - accuracy: 0.5704 - val_loss: 0.6763 - val_accuracy: 0.5638 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6682 - accuracy: 0.5757 - val_loss: 0.6777 - val_accuracy: 0.5813 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6639 - accuracy: 0.5829 - val_loss: 0.6826 - val_accuracy: 0.5425 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6635 - accuracy: 0.5854 - val_loss: 0.6637 - val_accuracy: 0.5950 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6574 - accuracy: 0.5995 - val_loss: 0.6653 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6563 - accuracy: 0.5929 - val_loss: 0.6642 - val_accuracy: 0.5875 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6435 - accuracy: 0.6176 - val_loss: 0.6533 - val_accuracy: 0.6300 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6399 - accuracy: 0.6205 - val_loss: 0.6633 - val_accuracy: 0.5987 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6324 - accuracy: 0.6248 - val_loss: 0.6471 - val_accuracy: 0.6388 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6277 - accuracy: 0.6383 - val_loss: 0.6405 - val_accuracy: 0.6012 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6273 - accuracy: 0.6392 - val_loss: 0.6333 - val_accuracy: 0.6438 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6171 - accuracy: 0.6539 - val_loss: 0.6365 - val_accuracy: 0.6338 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6153 - accuracy: 0.6577 - val_loss: 0.6418 - val_accuracy: 0.6263 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6035 - accuracy: 0.6680 - val_loss: 0.6297 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6045 - accuracy: 0.6568 - val_loss: 0.6170 - val_accuracy: 0.6612 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5903 - accuracy: 0.6815 - val_loss: 0.6249 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5825 - accuracy: 0.6790 - val_loss: 0.6192 - val_accuracy: 0.6425 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5727 - accuracy: 0.6996 - val_loss: 0.6135 - val_accuracy: 0.6612 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5571 - accuracy: 0.6987 - val_loss: 0.6286 - val_accuracy: 0.6762 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5565 - accuracy: 0.7053 - val_loss: 0.6076 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5367 - accuracy: 0.7240 - val_loss: 0.6007 - val_accuracy: 0.6900 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5231 - accuracy: 0.7416 - val_loss: 0.6111 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5159 - accuracy: 0.7312 - val_loss: 0.5888 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4977 - accuracy: 0.7462 - val_loss: 0.6027 - val_accuracy: 0.6800 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4804 - accuracy: 0.7613 - val_loss: 0.6195 - val_accuracy: 0.6938 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4474 - accuracy: 0.7794 - val_loss: 0.6201 - val_accuracy: 0.6988 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4548 - accuracy: 0.7807 - val_loss: 0.6011 - val_accuracy: 0.6900 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4285 - accuracy: 0.7954 - val_loss: 0.6117 - val_accuracy: 0.6950 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4138 - accuracy: 0.8116 - val_loss: 0.6208 - val_accuracy: 0.7175 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3920 - accuracy: 0.8217 - val_loss: 0.6313 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3916 - accuracy: 0.8232 - val_loss: 0.6199 - val_accuracy: 0.7100 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3569 - accuracy: 0.8470 - val_loss: 0.6354 - val_accuracy: 0.7163 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3354 - accuracy: 0.8539 - val_loss: 0.6654 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3459 - accuracy: 0.8504 - val_loss: 0.6203 - val_accuracy: 0.7212 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3069 - accuracy: 0.8714 - val_loss: 0.6565 - val_accuracy: 0.7163 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3017 - accuracy: 0.8692 - val_loss: 0.6742 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2660 - accuracy: 0.8955 - val_loss: 0.7071 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2680 - accuracy: 0.8864 - val_loss: 0.6652 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2318 - accuracy: 0.9080 - val_loss: 0.6903 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.2505 - accuracy: 0.8992 - val_loss: 0.7072 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2389 - accuracy: 0.9043 - val_loss: 0.7291 - val_accuracy: 0.7312 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2275 - accuracy: 0.9096 - val_loss: 0.7488 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2125 - accuracy: 0.9127 - val_loss: 0.7356 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1969 - accuracy: 0.9249 - val_loss: 0.8071 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1773 - accuracy: 0.9318 - val_loss: 0.7857 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1614 - accuracy: 0.9409 - val_loss: 0.8006 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1797 - accuracy: 0.9340 - val_loss: 0.8269 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1582 - accuracy: 0.9384 - val_loss: 0.8583 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1675 - accuracy: 0.9377 - val_loss: 0.8279 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1597 - accuracy: 0.9412 - val_loss: 0.7967 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1480 - accuracy: 0.9493 - val_loss: 0.8693 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.1424 - accuracy: 0.9437 - val_loss: 0.8505 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1204 - accuracy: 0.9593 - val_loss: 0.9409 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1805 - accuracy: 0.9293 - val_loss: 0.7915 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1193 - accuracy: 0.9590 - val_loss: 0.8444 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1150 - accuracy: 0.9621 - val_loss: 0.8160 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1142 - accuracy: 0.9609 - val_loss: 0.8663 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1118 - accuracy: 0.9612 - val_loss: 0.9005 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0939 - accuracy: 0.9687 - val_loss: 0.9857 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0988 - accuracy: 0.9696 - val_loss: 1.0898 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1544 - accuracy: 0.9474 - val_loss: 0.8475 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0909 - accuracy: 0.9712 - val_loss: 0.9097 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0929 - accuracy: 0.9700 - val_loss: 0.8933 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0912 - accuracy: 0.9743 - val_loss: 1.0352 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1071 - accuracy: 0.9668 - val_loss: 0.9303 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0885 - accuracy: 0.9768 - val_loss: 0.9999 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0817 - accuracy: 0.9753 - val_loss: 0.9407 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1077 - accuracy: 0.9696 - val_loss: 0.9629 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0845 - accuracy: 0.9740 - val_loss: 0.9904 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0867 - accuracy: 0.9731 - val_loss: 0.9525 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0902 - accuracy: 0.9750 - val_loss: 0.8954 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0966 - accuracy: 0.9737 - val_loss: 0.9466 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0982 - accuracy: 0.9715 - val_loss: 0.9223 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0869 - accuracy: 0.9747 - val_loss: 0.8897 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0613 - accuracy: 0.9856 - val_loss: 0.9175 - val_accuracy: 0.7825 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0572 - accuracy: 0.9853 - val_loss: 1.0062 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1022 - accuracy: 0.9709 - val_loss: 0.9343 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0930 - accuracy: 0.9734 - val_loss: 0.8984 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0741 - accuracy: 0.9819 - val_loss: 0.9376 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0637 - accuracy: 0.9837 - val_loss: 0.9312 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0822 - accuracy: 0.9753 - val_loss: 0.9660 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0809 - accuracy: 0.9753 - val_loss: 1.0034 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0725 - accuracy: 0.9819 - val_loss: 1.0107 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0675 - accuracy: 0.9825 - val_loss: 0.9802 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0832 - accuracy: 0.9772 - val_loss: 0.9263 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0647 - accuracy: 0.9853 - val_loss: 0.9283 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0755 - accuracy: 0.9828 - val_loss: 1.0121 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0755 - accuracy: 0.9772 - val_loss: 0.9192 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0644 - accuracy: 0.9812 - val_loss: 0.9804 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0825 - accuracy: 0.9768 - val_loss: 0.9695 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0667 - accuracy: 0.9837 - val_loss: 0.9456 - val_accuracy: 0.7763 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0703 - accuracy: 0.9812 - val_loss: 0.9503 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.0778 - accuracy: 0.9778 - val_loss: 0.9345 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0757 - accuracy: 0.9803 - val_loss: 0.9581 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0569 - accuracy: 0.9853 - val_loss: 0.9816 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0500 - accuracy: 0.9881 - val_loss: 1.0094 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0591 - accuracy: 0.9837 - val_loss: 1.0650 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0866 - accuracy: 0.9778 - val_loss: 0.9998 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0538 - accuracy: 0.9869 - val_loss: 0.9216 - val_accuracy: 0.7912 - lr: 0.0010\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1087 - accuracy: 0.9687 - val_loss: 0.8740 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0699 - accuracy: 0.9828 - val_loss: 0.9298 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0483 - accuracy: 0.9890 - val_loss: 1.0411 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0511 - accuracy: 0.9890 - val_loss: 0.9556 - val_accuracy: 0.7800 - lr: 0.0010\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0517 - accuracy: 0.9900 - val_loss: 1.0198 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0540 - accuracy: 0.9865 - val_loss: 0.9514 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0538 - accuracy: 0.9869 - val_loss: 0.9512 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0710 - accuracy: 0.9819 - val_loss: 0.9367 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0616 - accuracy: 0.9850 - val_loss: 0.9944 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0593 - accuracy: 0.9850 - val_loss: 0.9497 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0485 - accuracy: 0.9887 - val_loss: 0.9616 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0480 - accuracy: 0.9881 - val_loss: 1.0823 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0449 - accuracy: 0.9881 - val_loss: 1.1000 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0588 - accuracy: 0.9850 - val_loss: 1.0009 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0674 - accuracy: 0.9809 - val_loss: 1.0404 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0695 - accuracy: 0.9803 - val_loss: 1.0169 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0558 - accuracy: 0.9869 - val_loss: 0.9784 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0393 - accuracy: 0.9903 - val_loss: 1.0508 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0574 - accuracy: 0.9853 - val_loss: 1.1595 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1188 - accuracy: 0.9653 - val_loss: 0.8805 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0544 - accuracy: 0.9856 - val_loss: 1.0101 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0532 - accuracy: 0.9862 - val_loss: 1.0252 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0386 - accuracy: 0.9912 - val_loss: 1.0196 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0405 - accuracy: 0.9916 - val_loss: 1.1059 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0577 - accuracy: 0.9875 - val_loss: 1.0845 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0989 - accuracy: 0.9725 - val_loss: 1.0244 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0553 - accuracy: 0.9881 - val_loss: 0.9780 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0489 - accuracy: 0.9875 - val_loss: 0.9562 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0483 - accuracy: 0.9878 - val_loss: 0.9229 - val_accuracy: 0.7800 - lr: 0.0010\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0574 - accuracy: 0.9853 - val_loss: 1.0203 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0502 - accuracy: 0.9878 - val_loss: 1.0179 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0393 - accuracy: 0.9925 - val_loss: 1.0640 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0514 - accuracy: 0.9872 - val_loss: 0.9503 - val_accuracy: 0.7875 - lr: 0.0010\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0495 - accuracy: 0.9881 - val_loss: 1.0301 - val_accuracy: 0.7800 - lr: 0.0010\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9919\n",
            "Epoch 153: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0396 - accuracy: 0.9919 - val_loss: 0.9693 - val_accuracy: 0.7912 - lr: 0.0010\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 0.9942 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0334 - accuracy: 0.9937 - val_loss: 0.9983 - val_accuracy: 0.7825 - lr: 1.0000e-04\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0285 - accuracy: 0.9947 - val_loss: 1.0181 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0289 - accuracy: 0.9947 - val_loss: 1.0361 - val_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0280 - accuracy: 0.9944 - val_loss: 1.0336 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0287 - accuracy: 0.9953 - val_loss: 1.0315 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0297 - accuracy: 0.9950 - val_loss: 1.0373 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0294 - accuracy: 0.9950 - val_loss: 1.0421 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0270 - accuracy: 0.9959 - val_loss: 1.0629 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0279 - accuracy: 0.9956 - val_loss: 1.0620 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0276 - accuracy: 0.9950 - val_loss: 1.0760 - val_accuracy: 0.7738 - lr: 1.0000e-04\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0278 - accuracy: 0.9956 - val_loss: 1.0772 - val_accuracy: 0.7738 - lr: 1.0000e-04\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0285 - accuracy: 0.9953 - val_loss: 1.0628 - val_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0267 - accuracy: 0.9959 - val_loss: 1.0672 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0271 - accuracy: 0.9959 - val_loss: 1.0653 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0268 - accuracy: 0.9956 - val_loss: 1.0715 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0294 - accuracy: 0.9956 - val_loss: 1.0733 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0302 - accuracy: 0.9950 - val_loss: 1.0738 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0260 - accuracy: 0.9959 - val_loss: 1.0803 - val_accuracy: 0.7738 - lr: 1.0000e-04\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0286 - accuracy: 0.9953 - val_loss: 1.0772 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0281 - accuracy: 0.9950 - val_loss: 1.0975 - val_accuracy: 0.7725 - lr: 1.0000e-04\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0274 - accuracy: 0.9953 - val_loss: 1.0909 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0269 - accuracy: 0.9950 - val_loss: 1.0763 - val_accuracy: 0.7750 - lr: 1.0000e-04\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0278 - accuracy: 0.9947 - val_loss: 1.0912 - val_accuracy: 0.7713 - lr: 1.0000e-04\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0266 - accuracy: 0.9959 - val_loss: 1.0863 - val_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0280 - accuracy: 0.9953 - val_loss: 1.0924 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 0.0276 - accuracy: 0.9953 - val_loss: 1.0881 - val_accuracy: 0.7775 - lr: 1.0000e-04\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0271 - accuracy: 0.9953 - val_loss: 1.0770 - val_accuracy: 0.7837 - lr: 1.0000e-04\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0282 - accuracy: 0.9953 - val_loss: 1.0773 - val_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0272 - accuracy: 0.9953 - val_loss: 1.0802 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0262 - accuracy: 0.9956 - val_loss: 1.0741 - val_accuracy: 0.7887 - lr: 1.0000e-04\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0257 - accuracy: 0.9959 - val_loss: 1.0783 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 3s 30ms/step - loss: 0.0270 - accuracy: 0.9950 - val_loss: 1.0645 - val_accuracy: 0.7912 - lr: 1.0000e-04\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.0283 - accuracy: 0.9950 - val_loss: 1.0652 - val_accuracy: 0.7900 - lr: 1.0000e-04\n",
            "Epoch 188/500\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9952\n",
            "Epoch 188: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0268 - accuracy: 0.9953 - val_loss: 1.0986 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.0275 - accuracy: 0.9953 - val_loss: 1.0993 - val_accuracy: 0.7875 - lr: 1.0000e-05\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.0282 - accuracy: 0.9947 - val_loss: 1.0993 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0278 - accuracy: 0.9947 - val_loss: 1.0990 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0257 - accuracy: 0.9956 - val_loss: 1.0985 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0263 - accuracy: 0.9953 - val_loss: 1.1002 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0264 - accuracy: 0.9956 - val_loss: 1.1015 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0294 - accuracy: 0.9937 - val_loss: 1.0990 - val_accuracy: 0.7875 - lr: 1.0000e-05\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0263 - accuracy: 0.9950 - val_loss: 1.0997 - val_accuracy: 0.7875 - lr: 1.0000e-05\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0270 - accuracy: 0.9953 - val_loss: 1.1021 - val_accuracy: 0.7875 - lr: 1.0000e-05\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0305 - accuracy: 0.9947 - val_loss: 1.1030 - val_accuracy: 0.7875 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff925fccfa0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_19.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiagSuTuTrCS",
        "outputId": "4ad179e5-cce5-4adc-9862-7e3b35621302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 6ms/step - loss: 0.9216 - accuracy: 0.7912\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9215546250343323, 0.7912499904632568]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(model_19,\"model_19\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQvMey3RT3V4",
        "outputId": "65b2cf6a-a132-44a2-edc7-9a629edfc364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_28_layer_call_fn, lstm_cell_28_layer_call_and_return_conditional_losses while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Best Performing Model"
      ],
      "metadata": {
        "id": "LM640mM4Jnyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model_20=Sequential([\n",
        "\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=3,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(64,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.LSTM(8),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_20.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "model_20.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=80,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOYVaf_XUA49",
        "outputId": "a4d95da1-2d54-4714-84a1-45c1713c3efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 13s 34ms/step - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6931 - accuracy: 0.5019 - val_loss: 0.6921 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6914 - accuracy: 0.5059 - val_loss: 0.6918 - val_accuracy: 0.5387 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6909 - accuracy: 0.5310 - val_loss: 0.6876 - val_accuracy: 0.5562 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6841 - accuracy: 0.5476 - val_loss: 0.6833 - val_accuracy: 0.5537 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6846 - accuracy: 0.5557 - val_loss: 0.6851 - val_accuracy: 0.5638 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6827 - accuracy: 0.5472 - val_loss: 0.6800 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6793 - accuracy: 0.5576 - val_loss: 0.6790 - val_accuracy: 0.5813 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6761 - accuracy: 0.5701 - val_loss: 0.6764 - val_accuracy: 0.5863 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6740 - accuracy: 0.5585 - val_loss: 0.6812 - val_accuracy: 0.5663 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6734 - accuracy: 0.5535 - val_loss: 0.6743 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6752 - accuracy: 0.5588 - val_loss: 0.6804 - val_accuracy: 0.5725 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6699 - accuracy: 0.5776 - val_loss: 0.6790 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6670 - accuracy: 0.5851 - val_loss: 0.6802 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6660 - accuracy: 0.5860 - val_loss: 0.6783 - val_accuracy: 0.6012 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6640 - accuracy: 0.5732 - val_loss: 0.6711 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6636 - accuracy: 0.5707 - val_loss: 0.6743 - val_accuracy: 0.6037 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6605 - accuracy: 0.5898 - val_loss: 0.6648 - val_accuracy: 0.5875 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6583 - accuracy: 0.5895 - val_loss: 0.6660 - val_accuracy: 0.5925 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6513 - accuracy: 0.6058 - val_loss: 0.6642 - val_accuracy: 0.5725 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 0.6548 - accuracy: 0.6033 - val_loss: 0.6642 - val_accuracy: 0.5600 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.6495 - accuracy: 0.5892 - val_loss: 0.6602 - val_accuracy: 0.6212 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6478 - accuracy: 0.6039 - val_loss: 0.6582 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6434 - accuracy: 0.6245 - val_loss: 0.6519 - val_accuracy: 0.6087 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6349 - accuracy: 0.6233 - val_loss: 0.6545 - val_accuracy: 0.5950 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6319 - accuracy: 0.6277 - val_loss: 0.6554 - val_accuracy: 0.6288 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6243 - accuracy: 0.6370 - val_loss: 0.6411 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6275 - accuracy: 0.6458 - val_loss: 0.6536 - val_accuracy: 0.6137 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6154 - accuracy: 0.6496 - val_loss: 0.6488 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6126 - accuracy: 0.6633 - val_loss: 0.6448 - val_accuracy: 0.6225 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6090 - accuracy: 0.6558 - val_loss: 0.6322 - val_accuracy: 0.6525 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.6021 - accuracy: 0.6668 - val_loss: 0.6333 - val_accuracy: 0.6237 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5923 - accuracy: 0.6737 - val_loss: 0.6203 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5940 - accuracy: 0.6705 - val_loss: 0.6425 - val_accuracy: 0.6350 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5812 - accuracy: 0.6740 - val_loss: 0.6106 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5741 - accuracy: 0.6918 - val_loss: 0.6165 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5694 - accuracy: 0.6855 - val_loss: 0.6096 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5627 - accuracy: 0.6987 - val_loss: 0.6189 - val_accuracy: 0.6438 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5528 - accuracy: 0.7062 - val_loss: 0.6094 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5389 - accuracy: 0.7212 - val_loss: 0.6666 - val_accuracy: 0.6363 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5518 - accuracy: 0.7084 - val_loss: 0.6072 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5398 - accuracy: 0.7103 - val_loss: 0.6197 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5339 - accuracy: 0.7225 - val_loss: 0.6504 - val_accuracy: 0.6200 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5082 - accuracy: 0.7397 - val_loss: 0.6147 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5011 - accuracy: 0.7531 - val_loss: 0.6114 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5027 - accuracy: 0.7516 - val_loss: 0.5771 - val_accuracy: 0.7038 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4890 - accuracy: 0.7566 - val_loss: 0.6173 - val_accuracy: 0.6675 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4879 - accuracy: 0.7584 - val_loss: 0.6379 - val_accuracy: 0.6513 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4721 - accuracy: 0.7660 - val_loss: 0.6175 - val_accuracy: 0.6787 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4662 - accuracy: 0.7703 - val_loss: 0.5949 - val_accuracy: 0.6825 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4620 - accuracy: 0.7825 - val_loss: 0.6132 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.6338 - val_accuracy: 0.6787 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4350 - accuracy: 0.7919 - val_loss: 0.6335 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4165 - accuracy: 0.8041 - val_loss: 0.6346 - val_accuracy: 0.6913 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4193 - accuracy: 0.8013 - val_loss: 0.6265 - val_accuracy: 0.6875 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3857 - accuracy: 0.8260 - val_loss: 0.6723 - val_accuracy: 0.6850 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3866 - accuracy: 0.8276 - val_loss: 0.6555 - val_accuracy: 0.7025 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4124 - accuracy: 0.8126 - val_loss: 0.6062 - val_accuracy: 0.6963 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3778 - accuracy: 0.8285 - val_loss: 0.6217 - val_accuracy: 0.7050 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3673 - accuracy: 0.8335 - val_loss: 0.6278 - val_accuracy: 0.7125 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3541 - accuracy: 0.8389 - val_loss: 0.6397 - val_accuracy: 0.7063 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3529 - accuracy: 0.8439 - val_loss: 0.6197 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3281 - accuracy: 0.8529 - val_loss: 0.7161 - val_accuracy: 0.6975 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3362 - accuracy: 0.8517 - val_loss: 0.6657 - val_accuracy: 0.7100 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3079 - accuracy: 0.8670 - val_loss: 0.6605 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3137 - accuracy: 0.8620 - val_loss: 0.6959 - val_accuracy: 0.7138 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3067 - accuracy: 0.8642 - val_loss: 0.6572 - val_accuracy: 0.7212 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2992 - accuracy: 0.8698 - val_loss: 0.6886 - val_accuracy: 0.7138 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2823 - accuracy: 0.8786 - val_loss: 0.6914 - val_accuracy: 0.7150 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2772 - accuracy: 0.8877 - val_loss: 0.6799 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2807 - accuracy: 0.8817 - val_loss: 0.6626 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2444 - accuracy: 0.9002 - val_loss: 0.7234 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2568 - accuracy: 0.8908 - val_loss: 0.7087 - val_accuracy: 0.7163 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2510 - accuracy: 0.8986 - val_loss: 0.6684 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2414 - accuracy: 0.9030 - val_loss: 0.8340 - val_accuracy: 0.7013 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2383 - accuracy: 0.9008 - val_loss: 0.7266 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2371 - accuracy: 0.9093 - val_loss: 0.7492 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2201 - accuracy: 0.9105 - val_loss: 0.7457 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2069 - accuracy: 0.9221 - val_loss: 0.7257 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2015 - accuracy: 0.9224 - val_loss: 0.7161 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2252 - accuracy: 0.9118 - val_loss: 0.7320 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1918 - accuracy: 0.9243 - val_loss: 0.7650 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1848 - accuracy: 0.9315 - val_loss: 0.7072 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1763 - accuracy: 0.9321 - val_loss: 0.8730 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1783 - accuracy: 0.9302 - val_loss: 0.7393 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1755 - accuracy: 0.9337 - val_loss: 0.7149 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1629 - accuracy: 0.9374 - val_loss: 0.8058 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1693 - accuracy: 0.9355 - val_loss: 0.8054 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1498 - accuracy: 0.9418 - val_loss: 0.7780 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1698 - accuracy: 0.9374 - val_loss: 0.7866 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1577 - accuracy: 0.9374 - val_loss: 0.7882 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1440 - accuracy: 0.9490 - val_loss: 0.8277 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1329 - accuracy: 0.9487 - val_loss: 0.9547 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1480 - accuracy: 0.9477 - val_loss: 0.8446 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1432 - accuracy: 0.9465 - val_loss: 0.8903 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1389 - accuracy: 0.9471 - val_loss: 0.8552 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1358 - accuracy: 0.9509 - val_loss: 0.8199 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1308 - accuracy: 0.9528 - val_loss: 0.8424 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1210 - accuracy: 0.9578 - val_loss: 0.8622 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1228 - accuracy: 0.9562 - val_loss: 0.8167 - val_accuracy: 0.7763 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1192 - accuracy: 0.9603 - val_loss: 0.7793 - val_accuracy: 0.7825 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1291 - accuracy: 0.9556 - val_loss: 0.8009 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1238 - accuracy: 0.9549 - val_loss: 0.7683 - val_accuracy: 0.7837 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1155 - accuracy: 0.9568 - val_loss: 0.8841 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0940 - accuracy: 0.9678 - val_loss: 0.8930 - val_accuracy: 0.7763 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1244 - accuracy: 0.9499 - val_loss: 0.8237 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0975 - accuracy: 0.9693 - val_loss: 0.8267 - val_accuracy: 0.7975 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0998 - accuracy: 0.9662 - val_loss: 0.9078 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1009 - accuracy: 0.9653 - val_loss: 0.8798 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0973 - accuracy: 0.9659 - val_loss: 0.9095 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1066 - accuracy: 0.9675 - val_loss: 0.8289 - val_accuracy: 0.7887 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0891 - accuracy: 0.9712 - val_loss: 0.8900 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0917 - accuracy: 0.9687 - val_loss: 0.9017 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0859 - accuracy: 0.9715 - val_loss: 0.8933 - val_accuracy: 0.7825 - lr: 0.0010\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0908 - accuracy: 0.9700 - val_loss: 0.8632 - val_accuracy: 0.7862 - lr: 0.0010\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0839 - accuracy: 0.9728 - val_loss: 0.8932 - val_accuracy: 0.7875 - lr: 0.0010\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0855 - accuracy: 0.9731 - val_loss: 0.9279 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0849 - accuracy: 0.9703 - val_loss: 0.8691 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0780 - accuracy: 0.9734 - val_loss: 0.8580 - val_accuracy: 0.7862 - lr: 0.0010\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0950 - accuracy: 0.9675 - val_loss: 0.8627 - val_accuracy: 0.7825 - lr: 0.0010\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0808 - accuracy: 0.9700 - val_loss: 0.8000 - val_accuracy: 0.8075 - lr: 0.0010\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0820 - accuracy: 0.9737 - val_loss: 0.8571 - val_accuracy: 0.7975 - lr: 0.0010\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0701 - accuracy: 0.9787 - val_loss: 1.0171 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0877 - accuracy: 0.9718 - val_loss: 1.0081 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0723 - accuracy: 0.9756 - val_loss: 0.9229 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0760 - accuracy: 0.9759 - val_loss: 0.9837 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0771 - accuracy: 0.9768 - val_loss: 0.9135 - val_accuracy: 0.7800 - lr: 0.0010\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0655 - accuracy: 0.9803 - val_loss: 0.8898 - val_accuracy: 0.7962 - lr: 0.0010\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0769 - accuracy: 0.9756 - val_loss: 1.0125 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0730 - accuracy: 0.9793 - val_loss: 1.0410 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0898 - accuracy: 0.9731 - val_loss: 0.9834 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0650 - accuracy: 0.9781 - val_loss: 0.8282 - val_accuracy: 0.8037 - lr: 0.0010\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0711 - accuracy: 0.9775 - val_loss: 0.9708 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0654 - accuracy: 0.9781 - val_loss: 0.9771 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0615 - accuracy: 0.9828 - val_loss: 0.9794 - val_accuracy: 0.7800 - lr: 0.0010\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0686 - accuracy: 0.9775 - val_loss: 1.0574 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0791 - accuracy: 0.9725 - val_loss: 0.8734 - val_accuracy: 0.7950 - lr: 0.0010\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0532 - accuracy: 0.9847 - val_loss: 0.9919 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0550 - accuracy: 0.9837 - val_loss: 0.9680 - val_accuracy: 0.7862 - lr: 0.0010\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0659 - accuracy: 0.9784 - val_loss: 0.9166 - val_accuracy: 0.7987 - lr: 0.0010\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0856 - accuracy: 0.9731 - val_loss: 0.9285 - val_accuracy: 0.7763 - lr: 0.0010\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0645 - accuracy: 0.9781 - val_loss: 0.8809 - val_accuracy: 0.8087 - lr: 0.0010\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0647 - accuracy: 0.9790 - val_loss: 0.8801 - val_accuracy: 0.7887 - lr: 0.0010\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0687 - accuracy: 0.9765 - val_loss: 0.9651 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0672 - accuracy: 0.9778 - val_loss: 0.9935 - val_accuracy: 0.7825 - lr: 0.0010\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0660 - accuracy: 0.9778 - val_loss: 1.0408 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0656 - accuracy: 0.9778 - val_loss: 1.0926 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0631 - accuracy: 0.9803 - val_loss: 0.8815 - val_accuracy: 0.8012 - lr: 0.0010\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.0873 - accuracy: 0.9722 - val_loss: 0.9233 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.0594 - accuracy: 0.9819 - val_loss: 0.9808 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.0467 - accuracy: 0.9847 - val_loss: 1.0236 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.0534 - accuracy: 0.9862 - val_loss: 1.0968 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.0609 - accuracy: 0.9806 - val_loss: 1.0895 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 0.0766 - accuracy: 0.9762 - val_loss: 0.9892 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0565 - accuracy: 0.9819 - val_loss: 0.9996 - val_accuracy: 0.7887 - lr: 0.0010\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0541 - accuracy: 0.9850 - val_loss: 0.9752 - val_accuracy: 0.7825 - lr: 0.0010\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0637 - accuracy: 0.9806 - val_loss: 0.9737 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0491 - accuracy: 0.9853 - val_loss: 1.0701 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0585 - accuracy: 0.9831 - val_loss: 1.0186 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0556 - accuracy: 0.9850 - val_loss: 1.0113 - val_accuracy: 0.7850 - lr: 0.0010\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0499 - accuracy: 0.9869 - val_loss: 0.9042 - val_accuracy: 0.7875 - lr: 0.0010\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0394 - accuracy: 0.9887 - val_loss: 1.1091 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0497 - accuracy: 0.9840 - val_loss: 1.0956 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0688 - accuracy: 0.9784 - val_loss: 0.9567 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0540 - accuracy: 0.9819 - val_loss: 1.0936 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0563 - accuracy: 0.9847 - val_loss: 1.0118 - val_accuracy: 0.7763 - lr: 0.0010\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0459 - accuracy: 0.9847 - val_loss: 1.0429 - val_accuracy: 0.7837 - lr: 0.0010\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0592 - accuracy: 0.9819 - val_loss: 1.0339 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0630 - accuracy: 0.9800 - val_loss: 1.0084 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0522 - accuracy: 0.9850 - val_loss: 0.9427 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0577 - accuracy: 0.9787 - val_loss: 0.9107 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0441 - accuracy: 0.9865 - val_loss: 0.9643 - val_accuracy: 0.7937 - lr: 0.0010\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0473 - accuracy: 0.9865 - val_loss: 0.9992 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0693 - accuracy: 0.9784 - val_loss: 1.0073 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0384 - accuracy: 0.9881 - val_loss: 0.9362 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0467 - accuracy: 0.9865 - val_loss: 0.9994 - val_accuracy: 0.7962 - lr: 0.0010\n",
            "Epoch 181/500\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 0.9703\n",
            "Epoch 181: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0837 - accuracy: 0.9709 - val_loss: 0.8100 - val_accuracy: 0.7925 - lr: 0.0010\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0581 - accuracy: 0.9822 - val_loss: 0.8699 - val_accuracy: 0.7937 - lr: 1.0000e-04\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0408 - accuracy: 0.9912 - val_loss: 0.9129 - val_accuracy: 0.7837 - lr: 1.0000e-04\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0331 - accuracy: 0.9912 - val_loss: 0.9171 - val_accuracy: 0.7900 - lr: 1.0000e-04\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 0.9298 - val_accuracy: 0.7900 - lr: 1.0000e-04\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0273 - accuracy: 0.9925 - val_loss: 0.9475 - val_accuracy: 0.7925 - lr: 1.0000e-04\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0278 - accuracy: 0.9919 - val_loss: 0.9431 - val_accuracy: 0.7975 - lr: 1.0000e-04\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.9675 - val_accuracy: 0.7925 - lr: 1.0000e-04\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0254 - accuracy: 0.9950 - val_loss: 0.9701 - val_accuracy: 0.7937 - lr: 1.0000e-04\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.9955 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0273 - accuracy: 0.9922 - val_loss: 1.0036 - val_accuracy: 0.7900 - lr: 1.0000e-04\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0242 - accuracy: 0.9934 - val_loss: 1.0119 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0261 - accuracy: 0.9934 - val_loss: 0.9900 - val_accuracy: 0.7925 - lr: 1.0000e-04\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0216 - accuracy: 0.9950 - val_loss: 1.0164 - val_accuracy: 0.7900 - lr: 1.0000e-04\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0204 - accuracy: 0.9956 - val_loss: 1.0147 - val_accuracy: 0.7925 - lr: 1.0000e-04\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0184 - accuracy: 0.9959 - val_loss: 1.0168 - val_accuracy: 0.7937 - lr: 1.0000e-04\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 1.0860 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0223 - accuracy: 0.9947 - val_loss: 1.0581 - val_accuracy: 0.7875 - lr: 1.0000e-04\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0223 - accuracy: 0.9950 - val_loss: 1.0536 - val_accuracy: 0.7875 - lr: 1.0000e-04\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0225 - accuracy: 0.9956 - val_loss: 1.0402 - val_accuracy: 0.7937 - lr: 1.0000e-04\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0217 - accuracy: 0.9953 - val_loss: 1.0672 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0193 - accuracy: 0.9959 - val_loss: 1.0814 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 1.0648 - val_accuracy: 0.7950 - lr: 1.0000e-04\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 1.0830 - val_accuracy: 0.7912 - lr: 1.0000e-04\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 1.0802 - val_accuracy: 0.7875 - lr: 1.0000e-04\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 1.0761 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 1.0772 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 1.0706 - val_accuracy: 0.7887 - lr: 1.0000e-04\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 1.1202 - val_accuracy: 0.7837 - lr: 1.0000e-04\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 1.0957 - val_accuracy: 0.7837 - lr: 1.0000e-04\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 1.0847 - val_accuracy: 0.7887 - lr: 1.0000e-04\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0171 - accuracy: 0.9962 - val_loss: 1.1038 - val_accuracy: 0.7875 - lr: 1.0000e-04\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 1.0578 - val_accuracy: 0.7937 - lr: 1.0000e-04\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 1.0911 - val_accuracy: 0.7875 - lr: 1.0000e-04\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 1.0891 - val_accuracy: 0.7925 - lr: 1.0000e-04\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9959\n",
            "Epoch 216: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 1.1196 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 1.1240 - val_accuracy: 0.7812 - lr: 1.0000e-05\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 1.1274 - val_accuracy: 0.7800 - lr: 1.0000e-05\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 1.1277 - val_accuracy: 0.7800 - lr: 1.0000e-05\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 1.1299 - val_accuracy: 0.7788 - lr: 1.0000e-05\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0203 - accuracy: 0.9953 - val_loss: 1.1267 - val_accuracy: 0.7788 - lr: 1.0000e-05\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 1.1281 - val_accuracy: 0.7788 - lr: 1.0000e-05\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 1.1312 - val_accuracy: 0.7812 - lr: 1.0000e-05\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0187 - accuracy: 0.9956 - val_loss: 1.1365 - val_accuracy: 0.7825 - lr: 1.0000e-05\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 1.1358 - val_accuracy: 0.7800 - lr: 1.0000e-05\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0186 - accuracy: 0.9950 - val_loss: 1.1329 - val_accuracy: 0.7812 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff892e983d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_20.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzZT9wEPVHg5",
        "outputId": "ac0b148f-5d31-4b3c-f7f8-149d29878aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 6ms/step - loss: 0.8809 - accuracy: 0.8087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.880947470664978, 0.8087499737739563]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model_21=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=3,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(64,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.LSTM(8),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_21.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.8,beta_2=0.8),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "model_21.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=80,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw9gG-ipVwIx",
        "outputId": "d867faa8-9432-4699-e473-b10fdc943a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 14s 33ms/step - loss: 0.6933 - accuracy: 0.4900 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5050 - val_loss: 0.6933 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6933 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6930 - accuracy: 0.5063 - val_loss: 0.6926 - val_accuracy: 0.5250 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6919 - accuracy: 0.5272 - val_loss: 0.6879 - val_accuracy: 0.5487 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6858 - accuracy: 0.5457 - val_loss: 0.6925 - val_accuracy: 0.5387 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6843 - accuracy: 0.5538 - val_loss: 0.6857 - val_accuracy: 0.5612 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6822 - accuracy: 0.5516 - val_loss: 0.6804 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6806 - accuracy: 0.5660 - val_loss: 0.6775 - val_accuracy: 0.5663 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6793 - accuracy: 0.5594 - val_loss: 0.6789 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6783 - accuracy: 0.5582 - val_loss: 0.6816 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6750 - accuracy: 0.5679 - val_loss: 0.6803 - val_accuracy: 0.5725 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6765 - accuracy: 0.5629 - val_loss: 0.6761 - val_accuracy: 0.5688 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6701 - accuracy: 0.5648 - val_loss: 0.6713 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6720 - accuracy: 0.5757 - val_loss: 0.6835 - val_accuracy: 0.5600 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6681 - accuracy: 0.5751 - val_loss: 0.6792 - val_accuracy: 0.5375 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6704 - accuracy: 0.5723 - val_loss: 0.6790 - val_accuracy: 0.5775 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6679 - accuracy: 0.5713 - val_loss: 0.6745 - val_accuracy: 0.5675 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6647 - accuracy: 0.5757 - val_loss: 0.6698 - val_accuracy: 0.5775 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6655 - accuracy: 0.5723 - val_loss: 0.6662 - val_accuracy: 0.5612 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6603 - accuracy: 0.5767 - val_loss: 0.6694 - val_accuracy: 0.5362 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6617 - accuracy: 0.5860 - val_loss: 0.6710 - val_accuracy: 0.5575 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6584 - accuracy: 0.5857 - val_loss: 0.6795 - val_accuracy: 0.5475 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6577 - accuracy: 0.5851 - val_loss: 0.6680 - val_accuracy: 0.5663 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6564 - accuracy: 0.5942 - val_loss: 0.6648 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6548 - accuracy: 0.5942 - val_loss: 0.6750 - val_accuracy: 0.5600 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6540 - accuracy: 0.5979 - val_loss: 0.6591 - val_accuracy: 0.5650 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6481 - accuracy: 0.5945 - val_loss: 0.6582 - val_accuracy: 0.5462 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6485 - accuracy: 0.6029 - val_loss: 0.6538 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6461 - accuracy: 0.5979 - val_loss: 0.6505 - val_accuracy: 0.5537 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6435 - accuracy: 0.5982 - val_loss: 0.6566 - val_accuracy: 0.5688 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6410 - accuracy: 0.6195 - val_loss: 0.6573 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6432 - accuracy: 0.6045 - val_loss: 0.6575 - val_accuracy: 0.5487 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6390 - accuracy: 0.6064 - val_loss: 0.6511 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6377 - accuracy: 0.6083 - val_loss: 0.6425 - val_accuracy: 0.5575 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6325 - accuracy: 0.6145 - val_loss: 0.6543 - val_accuracy: 0.5675 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6351 - accuracy: 0.6083 - val_loss: 0.6379 - val_accuracy: 0.5725 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6335 - accuracy: 0.6067 - val_loss: 0.6382 - val_accuracy: 0.5888 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6306 - accuracy: 0.6227 - val_loss: 0.6412 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6250 - accuracy: 0.6161 - val_loss: 0.6321 - val_accuracy: 0.5888 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6232 - accuracy: 0.6292 - val_loss: 0.6382 - val_accuracy: 0.5725 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6177 - accuracy: 0.6386 - val_loss: 0.6323 - val_accuracy: 0.5713 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6192 - accuracy: 0.6273 - val_loss: 0.6423 - val_accuracy: 0.5888 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6187 - accuracy: 0.6330 - val_loss: 0.6372 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6216 - accuracy: 0.6330 - val_loss: 0.6380 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6132 - accuracy: 0.6336 - val_loss: 0.6335 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6121 - accuracy: 0.6330 - val_loss: 0.6282 - val_accuracy: 0.6100 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6062 - accuracy: 0.6442 - val_loss: 0.6359 - val_accuracy: 0.6037 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6035 - accuracy: 0.6386 - val_loss: 0.6394 - val_accuracy: 0.6050 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6096 - accuracy: 0.6380 - val_loss: 0.6338 - val_accuracy: 0.6087 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6023 - accuracy: 0.6392 - val_loss: 0.6293 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5994 - accuracy: 0.6521 - val_loss: 0.6334 - val_accuracy: 0.6012 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5974 - accuracy: 0.6533 - val_loss: 0.6317 - val_accuracy: 0.6087 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5883 - accuracy: 0.6633 - val_loss: 0.6192 - val_accuracy: 0.6175 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5976 - accuracy: 0.6536 - val_loss: 0.6252 - val_accuracy: 0.6050 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5965 - accuracy: 0.6433 - val_loss: 0.6214 - val_accuracy: 0.5863 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.5905 - accuracy: 0.6571 - val_loss: 0.6155 - val_accuracy: 0.6225 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.5870 - accuracy: 0.6630 - val_loss: 0.6419 - val_accuracy: 0.6187 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5879 - accuracy: 0.6627 - val_loss: 0.6282 - val_accuracy: 0.6087 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5791 - accuracy: 0.6596 - val_loss: 0.6631 - val_accuracy: 0.6112 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5835 - accuracy: 0.6674 - val_loss: 0.6357 - val_accuracy: 0.6162 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5791 - accuracy: 0.6661 - val_loss: 0.6337 - val_accuracy: 0.5975 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5744 - accuracy: 0.6758 - val_loss: 0.6230 - val_accuracy: 0.6237 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5754 - accuracy: 0.6758 - val_loss: 0.6213 - val_accuracy: 0.6237 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5705 - accuracy: 0.6705 - val_loss: 0.6355 - val_accuracy: 0.6288 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5673 - accuracy: 0.6818 - val_loss: 0.6174 - val_accuracy: 0.6375 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5567 - accuracy: 0.6912 - val_loss: 0.6407 - val_accuracy: 0.6425 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5572 - accuracy: 0.6893 - val_loss: 0.6270 - val_accuracy: 0.6263 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5529 - accuracy: 0.6971 - val_loss: 0.6161 - val_accuracy: 0.6288 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5564 - accuracy: 0.6852 - val_loss: 0.6236 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5518 - accuracy: 0.6880 - val_loss: 0.6168 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5443 - accuracy: 0.6974 - val_loss: 0.6324 - val_accuracy: 0.6438 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5378 - accuracy: 0.7068 - val_loss: 0.6188 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5431 - accuracy: 0.7049 - val_loss: 0.6524 - val_accuracy: 0.6150 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5307 - accuracy: 0.7084 - val_loss: 0.6320 - val_accuracy: 0.6375 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5397 - accuracy: 0.7034 - val_loss: 0.6225 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5312 - accuracy: 0.7068 - val_loss: 0.6333 - val_accuracy: 0.6413 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5182 - accuracy: 0.7131 - val_loss: 0.6255 - val_accuracy: 0.6338 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5280 - accuracy: 0.7118 - val_loss: 0.6333 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5129 - accuracy: 0.7074 - val_loss: 0.6169 - val_accuracy: 0.6388 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5179 - accuracy: 0.7175 - val_loss: 0.6315 - val_accuracy: 0.6300 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5033 - accuracy: 0.7243 - val_loss: 0.6377 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5109 - accuracy: 0.7175 - val_loss: 0.6382 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5142 - accuracy: 0.7146 - val_loss: 0.6251 - val_accuracy: 0.6375 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5025 - accuracy: 0.7237 - val_loss: 0.6266 - val_accuracy: 0.6475 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4971 - accuracy: 0.7262 - val_loss: 0.6353 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4996 - accuracy: 0.7256 - val_loss: 0.6475 - val_accuracy: 0.6475 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4925 - accuracy: 0.7290 - val_loss: 0.6348 - val_accuracy: 0.6463 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4939 - accuracy: 0.7265 - val_loss: 0.6134 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4823 - accuracy: 0.7375 - val_loss: 0.6634 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4827 - accuracy: 0.7387 - val_loss: 0.6577 - val_accuracy: 0.6388 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4790 - accuracy: 0.7369 - val_loss: 0.6730 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4724 - accuracy: 0.7509 - val_loss: 0.6404 - val_accuracy: 0.6513 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4691 - accuracy: 0.7456 - val_loss: 0.6577 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4720 - accuracy: 0.7397 - val_loss: 0.6149 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4694 - accuracy: 0.7497 - val_loss: 0.6435 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4638 - accuracy: 0.7566 - val_loss: 0.6515 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4604 - accuracy: 0.7591 - val_loss: 0.6591 - val_accuracy: 0.6612 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4553 - accuracy: 0.7572 - val_loss: 0.6538 - val_accuracy: 0.6712 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4591 - accuracy: 0.7541 - val_loss: 0.6658 - val_accuracy: 0.6463 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4542 - accuracy: 0.7572 - val_loss: 0.6703 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4508 - accuracy: 0.7578 - val_loss: 0.6843 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4532 - accuracy: 0.7610 - val_loss: 0.6604 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4450 - accuracy: 0.7625 - val_loss: 0.6367 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4370 - accuracy: 0.7631 - val_loss: 0.6608 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4368 - accuracy: 0.7691 - val_loss: 0.6363 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4254 - accuracy: 0.7769 - val_loss: 0.6731 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4297 - accuracy: 0.7775 - val_loss: 0.7068 - val_accuracy: 0.6475 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4274 - accuracy: 0.7719 - val_loss: 0.6615 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4233 - accuracy: 0.7760 - val_loss: 0.6786 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4216 - accuracy: 0.7807 - val_loss: 0.6811 - val_accuracy: 0.6800 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4063 - accuracy: 0.7844 - val_loss: 0.7029 - val_accuracy: 0.6762 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4172 - accuracy: 0.7910 - val_loss: 0.7104 - val_accuracy: 0.6488 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4101 - accuracy: 0.7879 - val_loss: 0.6768 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4082 - accuracy: 0.7904 - val_loss: 0.6924 - val_accuracy: 0.6425 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4060 - accuracy: 0.7888 - val_loss: 0.6864 - val_accuracy: 0.6725 - lr: 0.0010\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3988 - accuracy: 0.7926 - val_loss: 0.6709 - val_accuracy: 0.6737 - lr: 0.0010\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3987 - accuracy: 0.8010 - val_loss: 0.6779 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3815 - accuracy: 0.8126 - val_loss: 0.7300 - val_accuracy: 0.6812 - lr: 0.0010\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3972 - accuracy: 0.7951 - val_loss: 0.6874 - val_accuracy: 0.6513 - lr: 0.0010\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3784 - accuracy: 0.8066 - val_loss: 0.6873 - val_accuracy: 0.6612 - lr: 0.0010\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3789 - accuracy: 0.8110 - val_loss: 0.7004 - val_accuracy: 0.6837 - lr: 0.0010\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3802 - accuracy: 0.8088 - val_loss: 0.7088 - val_accuracy: 0.6862 - lr: 0.0010\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3554 - accuracy: 0.8226 - val_loss: 0.7001 - val_accuracy: 0.6888 - lr: 0.0010\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3711 - accuracy: 0.8182 - val_loss: 0.7224 - val_accuracy: 0.6913 - lr: 0.0010\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3676 - accuracy: 0.8145 - val_loss: 0.6664 - val_accuracy: 0.6875 - lr: 0.0010\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3558 - accuracy: 0.8285 - val_loss: 0.7207 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3563 - accuracy: 0.8210 - val_loss: 0.7161 - val_accuracy: 0.6900 - lr: 0.0010\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3417 - accuracy: 0.8263 - val_loss: 0.7187 - val_accuracy: 0.6938 - lr: 0.0010\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3487 - accuracy: 0.8389 - val_loss: 0.7017 - val_accuracy: 0.6938 - lr: 0.0010\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3591 - accuracy: 0.8317 - val_loss: 0.7320 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3522 - accuracy: 0.8329 - val_loss: 0.7624 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3488 - accuracy: 0.8317 - val_loss: 0.7398 - val_accuracy: 0.6925 - lr: 0.0010\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3375 - accuracy: 0.8451 - val_loss: 0.7869 - val_accuracy: 0.6737 - lr: 0.0010\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3278 - accuracy: 0.8442 - val_loss: 0.7781 - val_accuracy: 0.6737 - lr: 0.0010\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3149 - accuracy: 0.8498 - val_loss: 0.7252 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3208 - accuracy: 0.8476 - val_loss: 0.7353 - val_accuracy: 0.7125 - lr: 0.0010\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3060 - accuracy: 0.8570 - val_loss: 0.7592 - val_accuracy: 0.6938 - lr: 0.0010\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3205 - accuracy: 0.8517 - val_loss: 0.7296 - val_accuracy: 0.6963 - lr: 0.0010\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2909 - accuracy: 0.8658 - val_loss: 0.7679 - val_accuracy: 0.7200 - lr: 0.0010\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3030 - accuracy: 0.8655 - val_loss: 0.7844 - val_accuracy: 0.6963 - lr: 0.0010\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3126 - accuracy: 0.8539 - val_loss: 0.6856 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3029 - accuracy: 0.8651 - val_loss: 0.7366 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2926 - accuracy: 0.8717 - val_loss: 0.7577 - val_accuracy: 0.7013 - lr: 0.0010\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2975 - accuracy: 0.8692 - val_loss: 0.7676 - val_accuracy: 0.7200 - lr: 0.0010\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2834 - accuracy: 0.8655 - val_loss: 0.7836 - val_accuracy: 0.7175 - lr: 0.0010\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2745 - accuracy: 0.8836 - val_loss: 0.7848 - val_accuracy: 0.7150 - lr: 0.0010\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2722 - accuracy: 0.8780 - val_loss: 0.8107 - val_accuracy: 0.7063 - lr: 0.0010\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2749 - accuracy: 0.8758 - val_loss: 0.7503 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2668 - accuracy: 0.8817 - val_loss: 0.7462 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2622 - accuracy: 0.8786 - val_loss: 0.7846 - val_accuracy: 0.7050 - lr: 0.0010\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2530 - accuracy: 0.8921 - val_loss: 0.7529 - val_accuracy: 0.7212 - lr: 0.0010\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2590 - accuracy: 0.8867 - val_loss: 0.8230 - val_accuracy: 0.6988 - lr: 0.0010\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2520 - accuracy: 0.8952 - val_loss: 0.7842 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2477 - accuracy: 0.8952 - val_loss: 0.7811 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2483 - accuracy: 0.8977 - val_loss: 0.8040 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2502 - accuracy: 0.8924 - val_loss: 0.7905 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2428 - accuracy: 0.8974 - val_loss: 0.7582 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2408 - accuracy: 0.8999 - val_loss: 0.7731 - val_accuracy: 0.7262 - lr: 0.0010\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2485 - accuracy: 0.8971 - val_loss: 0.7742 - val_accuracy: 0.7362 - lr: 0.0010\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2348 - accuracy: 0.9014 - val_loss: 0.7718 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2187 - accuracy: 0.9061 - val_loss: 0.8080 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2382 - accuracy: 0.9018 - val_loss: 0.8002 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2121 - accuracy: 0.9161 - val_loss: 0.8454 - val_accuracy: 0.7150 - lr: 0.0010\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2262 - accuracy: 0.9080 - val_loss: 0.8410 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2237 - accuracy: 0.9011 - val_loss: 0.7889 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2173 - accuracy: 0.9133 - val_loss: 0.7794 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2074 - accuracy: 0.9165 - val_loss: 0.7584 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2117 - accuracy: 0.9161 - val_loss: 0.8127 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2113 - accuracy: 0.9190 - val_loss: 0.7701 - val_accuracy: 0.7362 - lr: 0.0010\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2080 - accuracy: 0.9190 - val_loss: 0.7612 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2013 - accuracy: 0.9158 - val_loss: 0.8661 - val_accuracy: 0.7125 - lr: 0.0010\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2091 - accuracy: 0.9127 - val_loss: 0.7893 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1927 - accuracy: 0.9205 - val_loss: 0.7822 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1777 - accuracy: 0.9293 - val_loss: 0.7798 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1903 - accuracy: 0.9280 - val_loss: 0.8329 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1788 - accuracy: 0.9299 - val_loss: 0.7818 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1860 - accuracy: 0.9274 - val_loss: 0.8463 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1984 - accuracy: 0.9218 - val_loss: 0.7665 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1786 - accuracy: 0.9296 - val_loss: 0.8074 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1911 - accuracy: 0.9227 - val_loss: 0.7890 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1743 - accuracy: 0.9346 - val_loss: 0.7830 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1570 - accuracy: 0.9377 - val_loss: 0.8770 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1789 - accuracy: 0.9305 - val_loss: 0.8362 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1631 - accuracy: 0.9368 - val_loss: 0.8415 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1776 - accuracy: 0.9330 - val_loss: 0.7925 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1771 - accuracy: 0.9374 - val_loss: 0.8256 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1676 - accuracy: 0.9330 - val_loss: 0.8507 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1716 - accuracy: 0.9368 - val_loss: 0.8314 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1589 - accuracy: 0.9390 - val_loss: 0.8276 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1610 - accuracy: 0.9368 - val_loss: 0.8747 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1648 - accuracy: 0.9390 - val_loss: 0.8751 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1538 - accuracy: 0.9396 - val_loss: 0.8845 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1472 - accuracy: 0.9431 - val_loss: 0.8646 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1476 - accuracy: 0.9452 - val_loss: 0.8349 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1512 - accuracy: 0.9443 - val_loss: 0.8799 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1394 - accuracy: 0.9462 - val_loss: 0.9048 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1425 - accuracy: 0.9459 - val_loss: 0.8732 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1364 - accuracy: 0.9509 - val_loss: 0.8797 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1352 - accuracy: 0.9503 - val_loss: 0.9656 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1373 - accuracy: 0.9496 - val_loss: 0.9090 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1442 - accuracy: 0.9465 - val_loss: 0.9495 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1398 - accuracy: 0.9484 - val_loss: 0.8913 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1336 - accuracy: 0.9556 - val_loss: 0.8871 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1376 - accuracy: 0.9556 - val_loss: 0.8819 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1379 - accuracy: 0.9487 - val_loss: 0.8696 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1345 - accuracy: 0.9490 - val_loss: 0.9160 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1310 - accuracy: 0.9543 - val_loss: 0.8981 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1245 - accuracy: 0.9565 - val_loss: 0.9135 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1209 - accuracy: 0.9571 - val_loss: 0.9879 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1274 - accuracy: 0.9571 - val_loss: 0.9571 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1229 - accuracy: 0.9556 - val_loss: 0.9967 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1408 - accuracy: 0.9521 - val_loss: 0.8892 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1229 - accuracy: 0.9578 - val_loss: 0.9331 - val_accuracy: 0.7312 - lr: 0.0010\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1076 - accuracy: 0.9643 - val_loss: 0.9016 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1179 - accuracy: 0.9584 - val_loss: 0.9371 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1225 - accuracy: 0.9568 - val_loss: 0.9759 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1120 - accuracy: 0.9640 - val_loss: 0.9734 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1204 - accuracy: 0.9618 - val_loss: 0.9031 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1275 - accuracy: 0.9574 - val_loss: 0.9593 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1010 - accuracy: 0.9643 - val_loss: 1.0766 - val_accuracy: 0.7262 - lr: 0.0010\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1160 - accuracy: 0.9646 - val_loss: 0.9799 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1107 - accuracy: 0.9631 - val_loss: 0.9573 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1159 - accuracy: 0.9615 - val_loss: 0.8583 - val_accuracy: 0.7763 - lr: 0.0010\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1137 - accuracy: 0.9628 - val_loss: 0.9557 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0987 - accuracy: 0.9656 - val_loss: 0.9476 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1145 - accuracy: 0.9637 - val_loss: 0.9098 - val_accuracy: 0.7763 - lr: 0.0010\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1024 - accuracy: 0.9681 - val_loss: 0.9426 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1077 - accuracy: 0.9643 - val_loss: 0.9627 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1196 - accuracy: 0.9628 - val_loss: 0.9079 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0943 - accuracy: 0.9675 - val_loss: 0.9423 - val_accuracy: 0.7625 - lr: 0.0010\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0954 - accuracy: 0.9718 - val_loss: 0.9905 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0973 - accuracy: 0.9678 - val_loss: 1.1374 - val_accuracy: 0.7150 - lr: 0.0010\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1060 - accuracy: 0.9693 - val_loss: 1.0090 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.1081 - accuracy: 0.9659 - val_loss: 0.8931 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 0.1053 - accuracy: 0.9653 - val_loss: 1.0056 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 0.0991 - accuracy: 0.9671 - val_loss: 0.9247 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.0939 - accuracy: 0.9693 - val_loss: 0.8673 - val_accuracy: 0.7900 - lr: 0.0010\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1027 - accuracy: 0.9693 - val_loss: 0.9720 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0974 - accuracy: 0.9687 - val_loss: 0.8938 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0929 - accuracy: 0.9731 - val_loss: 0.9964 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1059 - accuracy: 0.9684 - val_loss: 0.9626 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0913 - accuracy: 0.9734 - val_loss: 0.9291 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0964 - accuracy: 0.9709 - val_loss: 0.9144 - val_accuracy: 0.7837 - lr: 0.0010\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1050 - accuracy: 0.9693 - val_loss: 0.9272 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.0841 - accuracy: 0.9762 - val_loss: 0.9788 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.1059 - accuracy: 0.9687 - val_loss: 0.9148 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.0898 - accuracy: 0.9728 - val_loss: 0.9826 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1014 - accuracy: 0.9662 - val_loss: 0.9240 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0838 - accuracy: 0.9747 - val_loss: 1.0386 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0943 - accuracy: 0.9722 - val_loss: 0.9572 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0865 - accuracy: 0.9750 - val_loss: 0.9189 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.9701 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0967 - accuracy: 0.9706 - val_loss: 1.0252 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1046 - accuracy: 0.9665 - val_loss: 0.9991 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0929 - accuracy: 0.9703 - val_loss: 0.9768 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0784 - accuracy: 0.9747 - val_loss: 1.0312 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0978 - accuracy: 0.9725 - val_loss: 1.0102 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0868 - accuracy: 0.9740 - val_loss: 0.9856 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0732 - accuracy: 0.9809 - val_loss: 1.0556 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0905 - accuracy: 0.9765 - val_loss: 0.9496 - val_accuracy: 0.7862 - lr: 0.0010\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0936 - accuracy: 0.9734 - val_loss: 1.0502 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0990 - accuracy: 0.9696 - val_loss: 0.9170 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0899 - accuracy: 0.9734 - val_loss: 0.9187 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0752 - accuracy: 0.9806 - val_loss: 1.0279 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1037 - accuracy: 0.9715 - val_loss: 0.9568 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0799 - accuracy: 0.9747 - val_loss: 0.9321 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0850 - accuracy: 0.9772 - val_loss: 1.0005 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0973 - accuracy: 0.9728 - val_loss: 0.9560 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0676 - accuracy: 0.9803 - val_loss: 1.0676 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0973 - accuracy: 0.9740 - val_loss: 0.9113 - val_accuracy: 0.7800 - lr: 0.0010\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0824 - accuracy: 0.9753 - val_loss: 0.9914 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 274/500\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0722 - accuracy: 0.9805\n",
            "Epoch 274: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0712 - accuracy: 0.9809 - val_loss: 1.0389 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0609 - accuracy: 0.9834 - val_loss: 1.0276 - val_accuracy: 0.7563 - lr: 1.0000e-04\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0513 - accuracy: 0.9869 - val_loss: 1.0183 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0474 - accuracy: 0.9878 - val_loss: 1.0295 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0491 - accuracy: 0.9884 - val_loss: 1.0462 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0376 - accuracy: 0.9919 - val_loss: 1.0623 - val_accuracy: 0.7550 - lr: 1.0000e-04\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0417 - accuracy: 0.9887 - val_loss: 1.0427 - val_accuracy: 0.7638 - lr: 1.0000e-04\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0522 - accuracy: 0.9865 - val_loss: 1.0280 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0470 - accuracy: 0.9887 - val_loss: 1.0553 - val_accuracy: 0.7563 - lr: 1.0000e-04\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0457 - accuracy: 0.9900 - val_loss: 1.0640 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0426 - accuracy: 0.9875 - val_loss: 1.1021 - val_accuracy: 0.7525 - lr: 1.0000e-04\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0421 - accuracy: 0.9890 - val_loss: 1.0813 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0374 - accuracy: 0.9916 - val_loss: 1.0489 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0370 - accuracy: 0.9903 - val_loss: 1.0738 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0346 - accuracy: 0.9919 - val_loss: 1.1178 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0330 - accuracy: 0.9934 - val_loss: 1.0866 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0416 - accuracy: 0.9894 - val_loss: 1.1153 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0270 - accuracy: 0.9941 - val_loss: 1.0975 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0304 - accuracy: 0.9941 - val_loss: 1.1203 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0337 - accuracy: 0.9925 - val_loss: 1.1431 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0365 - accuracy: 0.9922 - val_loss: 1.1102 - val_accuracy: 0.7700 - lr: 1.0000e-04\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0304 - accuracy: 0.9937 - val_loss: 1.1069 - val_accuracy: 0.7725 - lr: 1.0000e-04\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0311 - accuracy: 0.9937 - val_loss: 1.1243 - val_accuracy: 0.7700 - lr: 1.0000e-04\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0409 - accuracy: 0.9909 - val_loss: 1.1441 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0388 - accuracy: 0.9916 - val_loss: 1.1202 - val_accuracy: 0.7725 - lr: 1.0000e-04\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0367 - accuracy: 0.9925 - val_loss: 1.1618 - val_accuracy: 0.7638 - lr: 1.0000e-04\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0362 - accuracy: 0.9925 - val_loss: 1.1988 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0448 - accuracy: 0.9906 - val_loss: 1.1395 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0310 - accuracy: 0.9928 - val_loss: 1.1518 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0316 - accuracy: 0.9941 - val_loss: 1.2203 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0434 - accuracy: 0.9900 - val_loss: 1.1883 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0377 - accuracy: 0.9909 - val_loss: 1.2156 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0343 - accuracy: 0.9934 - val_loss: 1.2348 - val_accuracy: 0.7550 - lr: 1.0000e-04\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0308 - accuracy: 0.9941 - val_loss: 1.1736 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0346 - accuracy: 0.9916 - val_loss: 1.1798 - val_accuracy: 0.7675 - lr: 1.0000e-04\n",
            "Epoch 309/500\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9953\n",
            "Epoch 309: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0274 - accuracy: 0.9953 - val_loss: 1.2005 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0321 - accuracy: 0.9931 - val_loss: 1.2117 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0357 - accuracy: 0.9928 - val_loss: 1.2101 - val_accuracy: 0.7600 - lr: 1.0000e-05\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0403 - accuracy: 0.9922 - val_loss: 1.2110 - val_accuracy: 0.7575 - lr: 1.0000e-05\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0298 - accuracy: 0.9947 - val_loss: 1.2116 - val_accuracy: 0.7600 - lr: 1.0000e-05\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0371 - accuracy: 0.9925 - val_loss: 1.2136 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0277 - accuracy: 0.9947 - val_loss: 1.2135 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0227 - accuracy: 0.9953 - val_loss: 1.2138 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.0388 - accuracy: 0.9912 - val_loss: 1.2173 - val_accuracy: 0.7588 - lr: 1.0000e-05\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0396 - accuracy: 0.9922 - val_loss: 1.2153 - val_accuracy: 0.7613 - lr: 1.0000e-05\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0262 - accuracy: 0.9947 - val_loss: 1.2151 - val_accuracy: 0.7588 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff893249610>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_21.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6Hk8LwZY6iQ",
        "outputId": "935abd1f-ff3b-48c5-d151-baf6b72df70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 6ms/step - loss: 0.7610 - accuracy: 0.7850\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7609546184539795, 0.7850000262260437]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model_21=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=3,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(64,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.LSTM(8),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_21.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.1,beta_2=0.11),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "model_21.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=80,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ftdFns3agt2",
        "outputId": "ad642ad9-718b-47c7-e0ee-7b32f3e782ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 14s 34ms/step - loss: 0.6933 - accuracy: 0.4916 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6933 - accuracy: 0.5047 - val_loss: 0.6933 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5044 - val_loss: 0.6931 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6926 - accuracy: 0.5100 - val_loss: 0.6914 - val_accuracy: 0.5412 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6903 - accuracy: 0.5338 - val_loss: 0.6914 - val_accuracy: 0.5150 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6890 - accuracy: 0.5341 - val_loss: 0.6973 - val_accuracy: 0.4963 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6871 - accuracy: 0.5457 - val_loss: 0.6842 - val_accuracy: 0.5387 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6805 - accuracy: 0.5529 - val_loss: 0.6873 - val_accuracy: 0.5325 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6817 - accuracy: 0.5557 - val_loss: 0.6822 - val_accuracy: 0.5400 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6797 - accuracy: 0.5713 - val_loss: 0.6880 - val_accuracy: 0.5300 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6776 - accuracy: 0.5826 - val_loss: 0.6885 - val_accuracy: 0.5337 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6754 - accuracy: 0.5648 - val_loss: 0.6891 - val_accuracy: 0.5325 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6780 - accuracy: 0.5660 - val_loss: 0.6824 - val_accuracy: 0.5325 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6711 - accuracy: 0.5839 - val_loss: 0.6830 - val_accuracy: 0.5450 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6714 - accuracy: 0.5892 - val_loss: 0.6822 - val_accuracy: 0.5437 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6680 - accuracy: 0.5820 - val_loss: 0.6908 - val_accuracy: 0.5275 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6697 - accuracy: 0.5792 - val_loss: 0.6864 - val_accuracy: 0.5238 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6692 - accuracy: 0.5817 - val_loss: 0.6866 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6682 - accuracy: 0.5823 - val_loss: 0.6849 - val_accuracy: 0.5425 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6647 - accuracy: 0.5807 - val_loss: 0.6854 - val_accuracy: 0.5088 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6639 - accuracy: 0.5857 - val_loss: 0.6826 - val_accuracy: 0.5250 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6674 - accuracy: 0.5751 - val_loss: 0.6867 - val_accuracy: 0.5612 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6635 - accuracy: 0.5823 - val_loss: 0.7193 - val_accuracy: 0.5200 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6640 - accuracy: 0.5842 - val_loss: 0.6741 - val_accuracy: 0.5562 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6604 - accuracy: 0.5917 - val_loss: 0.6842 - val_accuracy: 0.5587 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6596 - accuracy: 0.5851 - val_loss: 0.6789 - val_accuracy: 0.5587 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6583 - accuracy: 0.5895 - val_loss: 0.6803 - val_accuracy: 0.5462 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6565 - accuracy: 0.5882 - val_loss: 0.6610 - val_accuracy: 0.5575 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6603 - accuracy: 0.6026 - val_loss: 0.6719 - val_accuracy: 0.5325 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6514 - accuracy: 0.5964 - val_loss: 0.6917 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6505 - accuracy: 0.5926 - val_loss: 0.6645 - val_accuracy: 0.5813 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6551 - accuracy: 0.5976 - val_loss: 0.6799 - val_accuracy: 0.5675 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6565 - accuracy: 0.5945 - val_loss: 0.6649 - val_accuracy: 0.5575 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6504 - accuracy: 0.5942 - val_loss: 0.6627 - val_accuracy: 0.5587 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6487 - accuracy: 0.5976 - val_loss: 0.6573 - val_accuracy: 0.5638 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6497 - accuracy: 0.6020 - val_loss: 0.6607 - val_accuracy: 0.5537 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6492 - accuracy: 0.6029 - val_loss: 0.6758 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6502 - accuracy: 0.6086 - val_loss: 0.6846 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6474 - accuracy: 0.6014 - val_loss: 0.6548 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6456 - accuracy: 0.6051 - val_loss: 0.6500 - val_accuracy: 0.5813 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6411 - accuracy: 0.6101 - val_loss: 0.6636 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6432 - accuracy: 0.6061 - val_loss: 0.6712 - val_accuracy: 0.5675 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6395 - accuracy: 0.6108 - val_loss: 0.6474 - val_accuracy: 0.6062 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6368 - accuracy: 0.6230 - val_loss: 0.6448 - val_accuracy: 0.5950 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6270 - accuracy: 0.6317 - val_loss: 0.6523 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6289 - accuracy: 0.6170 - val_loss: 0.6471 - val_accuracy: 0.5850 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6275 - accuracy: 0.6280 - val_loss: 0.6776 - val_accuracy: 0.5788 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6228 - accuracy: 0.6292 - val_loss: 0.6592 - val_accuracy: 0.6200 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6235 - accuracy: 0.6342 - val_loss: 0.6690 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6293 - accuracy: 0.6333 - val_loss: 0.6434 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6243 - accuracy: 0.6283 - val_loss: 0.7008 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6261 - accuracy: 0.6367 - val_loss: 0.6595 - val_accuracy: 0.5863 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6221 - accuracy: 0.6317 - val_loss: 0.6318 - val_accuracy: 0.6075 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6187 - accuracy: 0.6427 - val_loss: 0.6533 - val_accuracy: 0.5962 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6183 - accuracy: 0.6433 - val_loss: 0.6509 - val_accuracy: 0.5900 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6129 - accuracy: 0.6430 - val_loss: 0.6457 - val_accuracy: 0.6162 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6181 - accuracy: 0.6527 - val_loss: 0.6448 - val_accuracy: 0.6162 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6105 - accuracy: 0.6574 - val_loss: 0.6280 - val_accuracy: 0.6338 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6066 - accuracy: 0.6624 - val_loss: 0.6438 - val_accuracy: 0.6237 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6036 - accuracy: 0.6580 - val_loss: 0.6907 - val_accuracy: 0.5900 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6051 - accuracy: 0.6580 - val_loss: 0.6646 - val_accuracy: 0.6087 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.6071 - accuracy: 0.6658 - val_loss: 0.6383 - val_accuracy: 0.6237 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6002 - accuracy: 0.6702 - val_loss: 0.6243 - val_accuracy: 0.6388 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5964 - accuracy: 0.6571 - val_loss: 0.6454 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5934 - accuracy: 0.6730 - val_loss: 0.6492 - val_accuracy: 0.5987 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5923 - accuracy: 0.6690 - val_loss: 0.6952 - val_accuracy: 0.6050 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5956 - accuracy: 0.6809 - val_loss: 0.6527 - val_accuracy: 0.6100 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.5868 - accuracy: 0.6815 - val_loss: 0.6528 - val_accuracy: 0.6075 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.5782 - accuracy: 0.6880 - val_loss: 0.6361 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5826 - accuracy: 0.6699 - val_loss: 0.6381 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5833 - accuracy: 0.6868 - val_loss: 0.6546 - val_accuracy: 0.6100 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.5704 - accuracy: 0.6949 - val_loss: 0.6455 - val_accuracy: 0.6125 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5840 - accuracy: 0.6830 - val_loss: 0.6383 - val_accuracy: 0.6300 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5683 - accuracy: 0.6921 - val_loss: 0.6469 - val_accuracy: 0.6400 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5697 - accuracy: 0.6912 - val_loss: 0.6486 - val_accuracy: 0.6150 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5671 - accuracy: 0.6968 - val_loss: 0.6475 - val_accuracy: 0.6263 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5735 - accuracy: 0.6927 - val_loss: 0.6286 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5719 - accuracy: 0.6977 - val_loss: 0.6588 - val_accuracy: 0.6313 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5567 - accuracy: 0.6965 - val_loss: 0.6447 - val_accuracy: 0.6400 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5563 - accuracy: 0.7093 - val_loss: 0.6963 - val_accuracy: 0.6187 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.6533 - val_accuracy: 0.6375 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5544 - accuracy: 0.7162 - val_loss: 0.6353 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5537 - accuracy: 0.7099 - val_loss: 0.6446 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5421 - accuracy: 0.7281 - val_loss: 0.6543 - val_accuracy: 0.6263 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5472 - accuracy: 0.7153 - val_loss: 0.6696 - val_accuracy: 0.6350 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5416 - accuracy: 0.7168 - val_loss: 0.6292 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5349 - accuracy: 0.7331 - val_loss: 0.6551 - val_accuracy: 0.6400 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5373 - accuracy: 0.7312 - val_loss: 0.6571 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5357 - accuracy: 0.7162 - val_loss: 0.6584 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5208 - accuracy: 0.7422 - val_loss: 0.6891 - val_accuracy: 0.6525 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5316 - accuracy: 0.7431 - val_loss: 0.6853 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5261 - accuracy: 0.7487 - val_loss: 0.6779 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5180 - accuracy: 0.7484 - val_loss: 0.6595 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5035 - accuracy: 0.7547 - val_loss: 0.6793 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5033 - accuracy: 0.7569 - val_loss: 0.6861 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5052 - accuracy: 0.7660 - val_loss: 0.6639 - val_accuracy: 0.6463 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5019 - accuracy: 0.7484 - val_loss: 0.6602 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4965 - accuracy: 0.7610 - val_loss: 0.7033 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5021 - accuracy: 0.7672 - val_loss: 0.6472 - val_accuracy: 0.6825 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4923 - accuracy: 0.7656 - val_loss: 0.6656 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4847 - accuracy: 0.7757 - val_loss: 0.6997 - val_accuracy: 0.6538 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4797 - accuracy: 0.7769 - val_loss: 0.6588 - val_accuracy: 0.6837 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4767 - accuracy: 0.7807 - val_loss: 0.6819 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4610 - accuracy: 0.7891 - val_loss: 0.7056 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4632 - accuracy: 0.7844 - val_loss: 0.6909 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4584 - accuracy: 0.7941 - val_loss: 0.6887 - val_accuracy: 0.6762 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4617 - accuracy: 0.7988 - val_loss: 0.6852 - val_accuracy: 0.6825 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4624 - accuracy: 0.7907 - val_loss: 0.6607 - val_accuracy: 0.6963 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4455 - accuracy: 0.8019 - val_loss: 0.6636 - val_accuracy: 0.6963 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4443 - accuracy: 0.8082 - val_loss: 0.6648 - val_accuracy: 0.6850 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4328 - accuracy: 0.8154 - val_loss: 0.6700 - val_accuracy: 0.6925 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4442 - accuracy: 0.8123 - val_loss: 0.6459 - val_accuracy: 0.6900 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4295 - accuracy: 0.8173 - val_loss: 0.6787 - val_accuracy: 0.6938 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4325 - accuracy: 0.8141 - val_loss: 0.6603 - val_accuracy: 0.6913 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4244 - accuracy: 0.8141 - val_loss: 0.6492 - val_accuracy: 0.6925 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4165 - accuracy: 0.8217 - val_loss: 0.6767 - val_accuracy: 0.6938 - lr: 0.0010\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4112 - accuracy: 0.8276 - val_loss: 0.6723 - val_accuracy: 0.7075 - lr: 0.0010\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4057 - accuracy: 0.8279 - val_loss: 0.6980 - val_accuracy: 0.6862 - lr: 0.0010\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.4023 - accuracy: 0.8342 - val_loss: 0.6260 - val_accuracy: 0.7212 - lr: 0.0010\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3973 - accuracy: 0.8304 - val_loss: 0.6666 - val_accuracy: 0.7100 - lr: 0.0010\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3992 - accuracy: 0.8310 - val_loss: 0.6767 - val_accuracy: 0.7050 - lr: 0.0010\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3961 - accuracy: 0.8345 - val_loss: 0.7064 - val_accuracy: 0.6913 - lr: 0.0010\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3878 - accuracy: 0.8420 - val_loss: 0.7221 - val_accuracy: 0.6875 - lr: 0.0010\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3834 - accuracy: 0.8445 - val_loss: 0.7039 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3823 - accuracy: 0.8482 - val_loss: 0.6987 - val_accuracy: 0.7050 - lr: 0.0010\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3881 - accuracy: 0.8489 - val_loss: 0.6493 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3771 - accuracy: 0.8517 - val_loss: 0.6734 - val_accuracy: 0.7088 - lr: 0.0010\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3671 - accuracy: 0.8608 - val_loss: 0.6395 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3766 - accuracy: 0.8498 - val_loss: 0.6871 - val_accuracy: 0.7088 - lr: 0.0010\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3804 - accuracy: 0.8504 - val_loss: 0.6689 - val_accuracy: 0.7163 - lr: 0.0010\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3623 - accuracy: 0.8589 - val_loss: 0.6541 - val_accuracy: 0.7113 - lr: 0.0010\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3526 - accuracy: 0.8648 - val_loss: 0.6613 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3516 - accuracy: 0.8683 - val_loss: 0.6617 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3523 - accuracy: 0.8633 - val_loss: 0.7507 - val_accuracy: 0.6988 - lr: 0.0010\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3581 - accuracy: 0.8645 - val_loss: 0.6847 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3375 - accuracy: 0.8730 - val_loss: 0.6864 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3355 - accuracy: 0.8752 - val_loss: 0.6770 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3277 - accuracy: 0.8817 - val_loss: 0.6845 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3458 - accuracy: 0.8755 - val_loss: 0.6859 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3400 - accuracy: 0.8717 - val_loss: 0.6435 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3244 - accuracy: 0.8845 - val_loss: 0.6751 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3293 - accuracy: 0.8805 - val_loss: 0.7034 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3460 - accuracy: 0.8748 - val_loss: 0.6553 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3234 - accuracy: 0.8830 - val_loss: 0.7400 - val_accuracy: 0.7125 - lr: 0.0010\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3156 - accuracy: 0.8889 - val_loss: 0.6621 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3290 - accuracy: 0.8883 - val_loss: 0.6989 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3368 - accuracy: 0.8792 - val_loss: 0.6616 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3126 - accuracy: 0.8877 - val_loss: 0.7015 - val_accuracy: 0.7212 - lr: 0.0010\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3173 - accuracy: 0.8902 - val_loss: 0.6700 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3295 - accuracy: 0.8789 - val_loss: 0.7026 - val_accuracy: 0.7262 - lr: 0.0010\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3115 - accuracy: 0.8895 - val_loss: 0.6938 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3243 - accuracy: 0.8830 - val_loss: 0.6403 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2949 - accuracy: 0.8964 - val_loss: 0.7008 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3019 - accuracy: 0.8955 - val_loss: 0.6652 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3106 - accuracy: 0.8927 - val_loss: 0.6518 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2968 - accuracy: 0.8989 - val_loss: 0.7133 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2922 - accuracy: 0.9024 - val_loss: 0.7249 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3019 - accuracy: 0.9005 - val_loss: 0.7372 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2977 - accuracy: 0.8999 - val_loss: 0.7456 - val_accuracy: 0.7113 - lr: 0.0010\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3005 - accuracy: 0.9008 - val_loss: 0.7351 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3000 - accuracy: 0.8986 - val_loss: 0.7259 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3090 - accuracy: 0.8946 - val_loss: 0.7061 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3090 - accuracy: 0.8980 - val_loss: 0.7032 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2958 - accuracy: 0.9049 - val_loss: 0.7096 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3015 - accuracy: 0.8977 - val_loss: 0.7088 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2855 - accuracy: 0.9068 - val_loss: 0.7706 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3155 - accuracy: 0.8914 - val_loss: 0.6663 - val_accuracy: 0.7362 - lr: 0.0010\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2955 - accuracy: 0.9061 - val_loss: 0.7081 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2892 - accuracy: 0.9052 - val_loss: 0.7204 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2943 - accuracy: 0.9033 - val_loss: 0.7215 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2918 - accuracy: 0.9055 - val_loss: 0.7610 - val_accuracy: 0.7262 - lr: 0.0010\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2666 - accuracy: 0.9133 - val_loss: 0.6975 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2943 - accuracy: 0.9077 - val_loss: 0.7298 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2839 - accuracy: 0.9108 - val_loss: 0.7514 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2850 - accuracy: 0.9130 - val_loss: 0.6559 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2748 - accuracy: 0.9158 - val_loss: 0.8186 - val_accuracy: 0.7063 - lr: 0.0010\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2804 - accuracy: 0.9105 - val_loss: 0.7778 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2712 - accuracy: 0.9186 - val_loss: 0.7043 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2961 - accuracy: 0.9071 - val_loss: 0.7262 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2793 - accuracy: 0.9124 - val_loss: 0.6814 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2757 - accuracy: 0.9136 - val_loss: 0.6980 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2575 - accuracy: 0.9224 - val_loss: 0.7157 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.3075 - accuracy: 0.9011 - val_loss: 0.7337 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2734 - accuracy: 0.9168 - val_loss: 0.6658 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2727 - accuracy: 0.9152 - val_loss: 0.7364 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2719 - accuracy: 0.9133 - val_loss: 0.7187 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2623 - accuracy: 0.9168 - val_loss: 0.7560 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2673 - accuracy: 0.9174 - val_loss: 0.7374 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2696 - accuracy: 0.9140 - val_loss: 0.6901 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2628 - accuracy: 0.9174 - val_loss: 0.7450 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2601 - accuracy: 0.9215 - val_loss: 0.7405 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2664 - accuracy: 0.9196 - val_loss: 0.7691 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2424 - accuracy: 0.9287 - val_loss: 0.7324 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2425 - accuracy: 0.9293 - val_loss: 0.8104 - val_accuracy: 0.7262 - lr: 0.0010\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2626 - accuracy: 0.9215 - val_loss: 0.7742 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2682 - accuracy: 0.9190 - val_loss: 0.8014 - val_accuracy: 0.7138 - lr: 0.0010\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2545 - accuracy: 0.9255 - val_loss: 0.8062 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2775 - accuracy: 0.9158 - val_loss: 0.7216 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2696 - accuracy: 0.9177 - val_loss: 0.7415 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2713 - accuracy: 0.9155 - val_loss: 0.7117 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2653 - accuracy: 0.9186 - val_loss: 0.7913 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2450 - accuracy: 0.9258 - val_loss: 0.7754 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2812 - accuracy: 0.9146 - val_loss: 0.7483 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2624 - accuracy: 0.9212 - val_loss: 0.7474 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2561 - accuracy: 0.9237 - val_loss: 0.7702 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2535 - accuracy: 0.9246 - val_loss: 0.7580 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2680 - accuracy: 0.9180 - val_loss: 0.7607 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2366 - accuracy: 0.9290 - val_loss: 0.7342 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2593 - accuracy: 0.9227 - val_loss: 0.7046 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2667 - accuracy: 0.9196\n",
            "Epoch 211: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2667 - accuracy: 0.9196 - val_loss: 0.7577 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2404 - accuracy: 0.9315 - val_loss: 0.7321 - val_accuracy: 0.7475 - lr: 1.0000e-04\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2285 - accuracy: 0.9346 - val_loss: 0.7400 - val_accuracy: 0.7450 - lr: 1.0000e-04\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2118 - accuracy: 0.9427 - val_loss: 0.7244 - val_accuracy: 0.7525 - lr: 1.0000e-04\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2000 - accuracy: 0.9474 - val_loss: 0.7349 - val_accuracy: 0.7475 - lr: 1.0000e-04\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1852 - accuracy: 0.9515 - val_loss: 0.7191 - val_accuracy: 0.7538 - lr: 1.0000e-04\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2050 - accuracy: 0.9449 - val_loss: 0.7277 - val_accuracy: 0.7525 - lr: 1.0000e-04\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1993 - accuracy: 0.9468 - val_loss: 0.7476 - val_accuracy: 0.7487 - lr: 1.0000e-04\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1828 - accuracy: 0.9543 - val_loss: 0.7525 - val_accuracy: 0.7437 - lr: 1.0000e-04\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1936 - accuracy: 0.9496 - val_loss: 0.7492 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1899 - accuracy: 0.9503 - val_loss: 0.7604 - val_accuracy: 0.7462 - lr: 1.0000e-04\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1761 - accuracy: 0.9556 - val_loss: 0.7640 - val_accuracy: 0.7450 - lr: 1.0000e-04\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1910 - accuracy: 0.9509 - val_loss: 0.7687 - val_accuracy: 0.7450 - lr: 1.0000e-04\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1988 - accuracy: 0.9477 - val_loss: 0.7732 - val_accuracy: 0.7450 - lr: 1.0000e-04\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1640 - accuracy: 0.9603 - val_loss: 0.7623 - val_accuracy: 0.7513 - lr: 1.0000e-04\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1811 - accuracy: 0.9540 - val_loss: 0.7757 - val_accuracy: 0.7462 - lr: 1.0000e-04\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.1848 - accuracy: 0.9521 - val_loss: 0.7546 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1952 - accuracy: 0.9496 - val_loss: 0.7501 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1780 - accuracy: 0.9553 - val_loss: 0.7658 - val_accuracy: 0.7538 - lr: 1.0000e-04\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1761 - accuracy: 0.9562 - val_loss: 0.7602 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1796 - accuracy: 0.9543 - val_loss: 0.7675 - val_accuracy: 0.7550 - lr: 1.0000e-04\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1893 - accuracy: 0.9509 - val_loss: 0.7820 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1851 - accuracy: 0.9531 - val_loss: 0.7690 - val_accuracy: 0.7563 - lr: 1.0000e-04\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1864 - accuracy: 0.9515 - val_loss: 0.7794 - val_accuracy: 0.7513 - lr: 1.0000e-04\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1797 - accuracy: 0.9546 - val_loss: 0.7791 - val_accuracy: 0.7538 - lr: 1.0000e-04\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1832 - accuracy: 0.9521 - val_loss: 0.7734 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1796 - accuracy: 0.9540 - val_loss: 0.7718 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1657 - accuracy: 0.9593 - val_loss: 0.7897 - val_accuracy: 0.7538 - lr: 1.0000e-04\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1780 - accuracy: 0.9546 - val_loss: 0.7918 - val_accuracy: 0.7538 - lr: 1.0000e-04\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1723 - accuracy: 0.9565 - val_loss: 0.7808 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1800 - accuracy: 0.9540 - val_loss: 0.8138 - val_accuracy: 0.7462 - lr: 1.0000e-04\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1884 - accuracy: 0.9518 - val_loss: 0.8065 - val_accuracy: 0.7475 - lr: 1.0000e-04\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1609 - accuracy: 0.9603 - val_loss: 0.7862 - val_accuracy: 0.7538 - lr: 1.0000e-04\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1694 - accuracy: 0.9587 - val_loss: 0.8129 - val_accuracy: 0.7487 - lr: 1.0000e-04\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.1756 - accuracy: 0.9556 - val_loss: 0.8147 - val_accuracy: 0.7513 - lr: 1.0000e-04\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1673 - accuracy: 0.9587\n",
            "Epoch 246: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 0.1673 - accuracy: 0.9587 - val_loss: 0.7738 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.1744 - accuracy: 0.9562 - val_loss: 0.7727 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.1800 - accuracy: 0.9543 - val_loss: 0.7786 - val_accuracy: 0.7600 - lr: 1.0000e-05\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.1739 - accuracy: 0.9553 - val_loss: 0.7794 - val_accuracy: 0.7613 - lr: 1.0000e-05\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.1631 - accuracy: 0.9596 - val_loss: 0.7797 - val_accuracy: 0.7625 - lr: 1.0000e-05\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1655 - accuracy: 0.9587 - val_loss: 0.7824 - val_accuracy: 0.7613 - lr: 1.0000e-05\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.1727 - accuracy: 0.9565 - val_loss: 0.7781 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.1716 - accuracy: 0.9587 - val_loss: 0.7755 - val_accuracy: 0.7650 - lr: 1.0000e-05\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.1702 - accuracy: 0.9581 - val_loss: 0.7777 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1742 - accuracy: 0.9556 - val_loss: 0.7771 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.1795 - accuracy: 0.9546 - val_loss: 0.7769 - val_accuracy: 0.7638 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff88f3ea040>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model_23=Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x,axis=-1)),\n",
        "    layers.LSTM(32,return_sequences=True),\n",
        "    layers.LSTM(16,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.LSTM(128,return_sequences=True),\n",
        "    layers.GRU(8,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=3,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.LSTM(64,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv1D(filters=32,\n",
        "                  kernel_size=4,\n",
        "                  padding=\"valid\",\n",
        "                  activation=\"relu\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.GRU(16,return_sequences=True),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.LSTM(8),\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_23.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "model_23.fit(x_train,y_train,\n",
        "            epochs=500,\n",
        "            validation_data=(x_test,y_test),\n",
        "            batch_size=32,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                        patience=80,\n",
        "                                                        restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                            patience=35,\n",
        "                                                            verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6rzYcrodt4E",
        "outputId": "27728173-d45a-46bb-b755-da66dfcf9d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 14s 36ms/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6933 - accuracy: 0.5022 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5059 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6931 - accuracy: 0.5050 - val_loss: 0.6929 - val_accuracy: 0.5188 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.6934 - accuracy: 0.5056 - val_loss: 0.6937 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6934 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6932 - accuracy: 0.5050 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.6933 - accuracy: 0.5034 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.6932 - accuracy: 0.4962 - val_loss: 0.6935 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6936 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6952 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6924 - accuracy: 0.5059 - val_loss: 0.6907 - val_accuracy: 0.5188 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6903 - accuracy: 0.4981 - val_loss: 0.6926 - val_accuracy: 0.5288 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6884 - accuracy: 0.5294 - val_loss: 0.6888 - val_accuracy: 0.5663 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6840 - accuracy: 0.5535 - val_loss: 0.6794 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6799 - accuracy: 0.5673 - val_loss: 0.6767 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6785 - accuracy: 0.5569 - val_loss: 0.6780 - val_accuracy: 0.5713 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6711 - accuracy: 0.5773 - val_loss: 0.6723 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6718 - accuracy: 0.5857 - val_loss: 0.6754 - val_accuracy: 0.5638 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6664 - accuracy: 0.5879 - val_loss: 0.6738 - val_accuracy: 0.5775 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6677 - accuracy: 0.5948 - val_loss: 0.6788 - val_accuracy: 0.5263 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6612 - accuracy: 0.5873 - val_loss: 0.6715 - val_accuracy: 0.5775 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6604 - accuracy: 0.5845 - val_loss: 0.6648 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6561 - accuracy: 0.6061 - val_loss: 0.6650 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6531 - accuracy: 0.5986 - val_loss: 0.6594 - val_accuracy: 0.5900 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6482 - accuracy: 0.6076 - val_loss: 0.6642 - val_accuracy: 0.5775 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6467 - accuracy: 0.6123 - val_loss: 0.6608 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6442 - accuracy: 0.6195 - val_loss: 0.6552 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6392 - accuracy: 0.6114 - val_loss: 0.6662 - val_accuracy: 0.5900 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6378 - accuracy: 0.6170 - val_loss: 0.6482 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6370 - accuracy: 0.6048 - val_loss: 0.6567 - val_accuracy: 0.5825 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6353 - accuracy: 0.6211 - val_loss: 0.6510 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6303 - accuracy: 0.6258 - val_loss: 0.6471 - val_accuracy: 0.5725 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6277 - accuracy: 0.6289 - val_loss: 0.6433 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6255 - accuracy: 0.6264 - val_loss: 0.6571 - val_accuracy: 0.5850 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6229 - accuracy: 0.6339 - val_loss: 0.6457 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6191 - accuracy: 0.6314 - val_loss: 0.6422 - val_accuracy: 0.6075 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6184 - accuracy: 0.6364 - val_loss: 0.6519 - val_accuracy: 0.5612 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6122 - accuracy: 0.6477 - val_loss: 0.6438 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6173 - accuracy: 0.6324 - val_loss: 0.6426 - val_accuracy: 0.5900 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6153 - accuracy: 0.6355 - val_loss: 0.6436 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6111 - accuracy: 0.6546 - val_loss: 0.6431 - val_accuracy: 0.5850 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.6016 - accuracy: 0.6474 - val_loss: 0.6550 - val_accuracy: 0.6112 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.6020 - accuracy: 0.6464 - val_loss: 0.6364 - val_accuracy: 0.5925 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6004 - accuracy: 0.6568 - val_loss: 0.6359 - val_accuracy: 0.6012 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5986 - accuracy: 0.6546 - val_loss: 0.6400 - val_accuracy: 0.6037 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5907 - accuracy: 0.6558 - val_loss: 0.6497 - val_accuracy: 0.6112 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5952 - accuracy: 0.6589 - val_loss: 0.6427 - val_accuracy: 0.6212 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5900 - accuracy: 0.6668 - val_loss: 0.6662 - val_accuracy: 0.5850 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5847 - accuracy: 0.6577 - val_loss: 0.6458 - val_accuracy: 0.6112 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5796 - accuracy: 0.6646 - val_loss: 0.6358 - val_accuracy: 0.6175 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5826 - accuracy: 0.6737 - val_loss: 0.6579 - val_accuracy: 0.6050 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5815 - accuracy: 0.6690 - val_loss: 0.6393 - val_accuracy: 0.6075 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5744 - accuracy: 0.6705 - val_loss: 0.6588 - val_accuracy: 0.6100 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5707 - accuracy: 0.6652 - val_loss: 0.6514 - val_accuracy: 0.6025 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.5690 - accuracy: 0.6771 - val_loss: 0.6491 - val_accuracy: 0.6062 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.5637 - accuracy: 0.6780 - val_loss: 0.6525 - val_accuracy: 0.5950 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5653 - accuracy: 0.6737 - val_loss: 0.6553 - val_accuracy: 0.6012 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5640 - accuracy: 0.6827 - val_loss: 0.6574 - val_accuracy: 0.6075 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5613 - accuracy: 0.6840 - val_loss: 0.6519 - val_accuracy: 0.6162 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5613 - accuracy: 0.6859 - val_loss: 0.6488 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5532 - accuracy: 0.6893 - val_loss: 0.6527 - val_accuracy: 0.6125 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5582 - accuracy: 0.6855 - val_loss: 0.6425 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5549 - accuracy: 0.6855 - val_loss: 0.6497 - val_accuracy: 0.6075 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5496 - accuracy: 0.6834 - val_loss: 0.6479 - val_accuracy: 0.6200 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5461 - accuracy: 0.6915 - val_loss: 0.6367 - val_accuracy: 0.6338 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5376 - accuracy: 0.7024 - val_loss: 0.6449 - val_accuracy: 0.6150 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5436 - accuracy: 0.6884 - val_loss: 0.6388 - val_accuracy: 0.6225 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.5327 - accuracy: 0.7049 - val_loss: 0.6399 - val_accuracy: 0.6263 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.5308 - accuracy: 0.7040 - val_loss: 0.6339 - val_accuracy: 0.6350 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5323 - accuracy: 0.7018 - val_loss: 0.6385 - val_accuracy: 0.6475 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5225 - accuracy: 0.7059 - val_loss: 0.6421 - val_accuracy: 0.6300 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5286 - accuracy: 0.7053 - val_loss: 0.6516 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5247 - accuracy: 0.6946 - val_loss: 0.6636 - val_accuracy: 0.6200 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5215 - accuracy: 0.7165 - val_loss: 0.6396 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5171 - accuracy: 0.7099 - val_loss: 0.6386 - val_accuracy: 0.6363 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5088 - accuracy: 0.7159 - val_loss: 0.6358 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5068 - accuracy: 0.7165 - val_loss: 0.6795 - val_accuracy: 0.6225 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5179 - accuracy: 0.7131 - val_loss: 0.6488 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5095 - accuracy: 0.7178 - val_loss: 0.6403 - val_accuracy: 0.6513 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5111 - accuracy: 0.7159 - val_loss: 0.6792 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4887 - accuracy: 0.7390 - val_loss: 0.6531 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4911 - accuracy: 0.7337 - val_loss: 0.6317 - val_accuracy: 0.6438 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4916 - accuracy: 0.7403 - val_loss: 0.6726 - val_accuracy: 0.6413 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5133 - accuracy: 0.7250 - val_loss: 0.6311 - val_accuracy: 0.6587 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4858 - accuracy: 0.7344 - val_loss: 0.6277 - val_accuracy: 0.6737 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4847 - accuracy: 0.7409 - val_loss: 0.6418 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4744 - accuracy: 0.7450 - val_loss: 0.6465 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4752 - accuracy: 0.7456 - val_loss: 0.6654 - val_accuracy: 0.6225 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4822 - accuracy: 0.7394 - val_loss: 0.6547 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4810 - accuracy: 0.7384 - val_loss: 0.6752 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4617 - accuracy: 0.7531 - val_loss: 0.6727 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4775 - accuracy: 0.7472 - val_loss: 0.6396 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4656 - accuracy: 0.7531 - val_loss: 0.6626 - val_accuracy: 0.6450 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4718 - accuracy: 0.7397 - val_loss: 0.6409 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4556 - accuracy: 0.7513 - val_loss: 0.6742 - val_accuracy: 0.6525 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4575 - accuracy: 0.7603 - val_loss: 0.6831 - val_accuracy: 0.6575 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4513 - accuracy: 0.7610 - val_loss: 0.7081 - val_accuracy: 0.6463 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4448 - accuracy: 0.7669 - val_loss: 0.6765 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4472 - accuracy: 0.7700 - val_loss: 0.6604 - val_accuracy: 0.6662 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4367 - accuracy: 0.7716 - val_loss: 0.6798 - val_accuracy: 0.6637 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4478 - accuracy: 0.7591 - val_loss: 0.6617 - val_accuracy: 0.6488 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4450 - accuracy: 0.7691 - val_loss: 0.6480 - val_accuracy: 0.6800 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.4302 - accuracy: 0.7753 - val_loss: 0.6730 - val_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4277 - accuracy: 0.7869 - val_loss: 0.6781 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4492 - accuracy: 0.7710 - val_loss: 0.6602 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4205 - accuracy: 0.7807 - val_loss: 0.7022 - val_accuracy: 0.6687 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4134 - accuracy: 0.7857 - val_loss: 0.6653 - val_accuracy: 0.6825 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4175 - accuracy: 0.7854 - val_loss: 0.6838 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.4101 - accuracy: 0.7850 - val_loss: 0.6753 - val_accuracy: 0.6775 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3973 - accuracy: 0.7988 - val_loss: 0.7042 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4120 - accuracy: 0.7844 - val_loss: 0.6795 - val_accuracy: 0.6825 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4049 - accuracy: 0.7929 - val_loss: 0.6942 - val_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4111 - accuracy: 0.7969 - val_loss: 0.6808 - val_accuracy: 0.6837 - lr: 0.0010\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4047 - accuracy: 0.7941 - val_loss: 0.6775 - val_accuracy: 0.6913 - lr: 0.0010\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3998 - accuracy: 0.7982 - val_loss: 0.6589 - val_accuracy: 0.6938 - lr: 0.0010\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3865 - accuracy: 0.8066 - val_loss: 0.7373 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4024 - accuracy: 0.7976 - val_loss: 0.6855 - val_accuracy: 0.6862 - lr: 0.0010\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3834 - accuracy: 0.8116 - val_loss: 0.6672 - val_accuracy: 0.6988 - lr: 0.0010\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3829 - accuracy: 0.8079 - val_loss: 0.7098 - val_accuracy: 0.6925 - lr: 0.0010\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3751 - accuracy: 0.8107 - val_loss: 0.6655 - val_accuracy: 0.7075 - lr: 0.0010\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3876 - accuracy: 0.8126 - val_loss: 0.6760 - val_accuracy: 0.6963 - lr: 0.0010\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3989 - accuracy: 0.8044 - val_loss: 0.6889 - val_accuracy: 0.6925 - lr: 0.0010\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3848 - accuracy: 0.8085 - val_loss: 0.6655 - val_accuracy: 0.6850 - lr: 0.0010\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3666 - accuracy: 0.8223 - val_loss: 0.6635 - val_accuracy: 0.7063 - lr: 0.0010\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3582 - accuracy: 0.8151 - val_loss: 0.7009 - val_accuracy: 0.6888 - lr: 0.0010\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3589 - accuracy: 0.8210 - val_loss: 0.7542 - val_accuracy: 0.6837 - lr: 0.0010\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3606 - accuracy: 0.8210 - val_loss: 0.7095 - val_accuracy: 0.6975 - lr: 0.0010\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3647 - accuracy: 0.8173 - val_loss: 0.7144 - val_accuracy: 0.6938 - lr: 0.0010\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3524 - accuracy: 0.8292 - val_loss: 0.7232 - val_accuracy: 0.6913 - lr: 0.0010\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3520 - accuracy: 0.8307 - val_loss: 0.7249 - val_accuracy: 0.6862 - lr: 0.0010\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3541 - accuracy: 0.8335 - val_loss: 0.7708 - val_accuracy: 0.6787 - lr: 0.0010\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3658 - accuracy: 0.8210 - val_loss: 0.6872 - val_accuracy: 0.7125 - lr: 0.0010\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3235 - accuracy: 0.8504 - val_loss: 0.7561 - val_accuracy: 0.7063 - lr: 0.0010\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3489 - accuracy: 0.8307 - val_loss: 0.6920 - val_accuracy: 0.7038 - lr: 0.0010\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3370 - accuracy: 0.8426 - val_loss: 0.7893 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3349 - accuracy: 0.8429 - val_loss: 0.6912 - val_accuracy: 0.7125 - lr: 0.0010\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3264 - accuracy: 0.8426 - val_loss: 0.7025 - val_accuracy: 0.7063 - lr: 0.0010\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3451 - accuracy: 0.8389 - val_loss: 0.7769 - val_accuracy: 0.6888 - lr: 0.0010\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3438 - accuracy: 0.8370 - val_loss: 0.7135 - val_accuracy: 0.6950 - lr: 0.0010\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3176 - accuracy: 0.8548 - val_loss: 0.7642 - val_accuracy: 0.6875 - lr: 0.0010\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3105 - accuracy: 0.8495 - val_loss: 0.7444 - val_accuracy: 0.7025 - lr: 0.0010\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3301 - accuracy: 0.8442 - val_loss: 0.7297 - val_accuracy: 0.7100 - lr: 0.0010\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3249 - accuracy: 0.8536 - val_loss: 0.7368 - val_accuracy: 0.6888 - lr: 0.0010\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3130 - accuracy: 0.8526 - val_loss: 0.7662 - val_accuracy: 0.7150 - lr: 0.0010\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3042 - accuracy: 0.8605 - val_loss: 0.7265 - val_accuracy: 0.7100 - lr: 0.0010\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.3148 - accuracy: 0.8526 - val_loss: 0.6849 - val_accuracy: 0.7262 - lr: 0.0010\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2899 - accuracy: 0.8651 - val_loss: 0.7682 - val_accuracy: 0.7050 - lr: 0.0010\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3072 - accuracy: 0.8617 - val_loss: 0.7385 - val_accuracy: 0.7050 - lr: 0.0010\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2999 - accuracy: 0.8598 - val_loss: 0.7092 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.3113 - accuracy: 0.8576 - val_loss: 0.7127 - val_accuracy: 0.7138 - lr: 0.0010\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2961 - accuracy: 0.8617 - val_loss: 0.7456 - val_accuracy: 0.7163 - lr: 0.0010\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2959 - accuracy: 0.8673 - val_loss: 0.7012 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3078 - accuracy: 0.8529 - val_loss: 0.7196 - val_accuracy: 0.7088 - lr: 0.0010\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2850 - accuracy: 0.8614 - val_loss: 0.7711 - val_accuracy: 0.7088 - lr: 0.0010\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2920 - accuracy: 0.8626 - val_loss: 0.7620 - val_accuracy: 0.7113 - lr: 0.0010\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2831 - accuracy: 0.8736 - val_loss: 0.7981 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2724 - accuracy: 0.8814 - val_loss: 0.7971 - val_accuracy: 0.7212 - lr: 0.0010\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.2811 - accuracy: 0.8789 - val_loss: 0.7415 - val_accuracy: 0.7075 - lr: 0.0010\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2747 - accuracy: 0.8742 - val_loss: 0.7474 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2778 - accuracy: 0.8748 - val_loss: 0.7724 - val_accuracy: 0.7200 - lr: 0.0010\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2647 - accuracy: 0.8849 - val_loss: 0.7623 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2719 - accuracy: 0.8786 - val_loss: 0.7389 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2672 - accuracy: 0.8820 - val_loss: 0.7340 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.2715 - accuracy: 0.8739 - val_loss: 0.7619 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2558 - accuracy: 0.8858 - val_loss: 0.7695 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2551 - accuracy: 0.8845 - val_loss: 0.8220 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2609 - accuracy: 0.8917 - val_loss: 0.7571 - val_accuracy: 0.7312 - lr: 0.0010\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2347 - accuracy: 0.9014 - val_loss: 0.7828 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2571 - accuracy: 0.8895 - val_loss: 0.7493 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2634 - accuracy: 0.8820 - val_loss: 0.7879 - val_accuracy: 0.7362 - lr: 0.0010\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2393 - accuracy: 0.8930 - val_loss: 0.7693 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2648 - accuracy: 0.8880 - val_loss: 0.7129 - val_accuracy: 0.7362 - lr: 0.0010\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2422 - accuracy: 0.8961 - val_loss: 0.7559 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2352 - accuracy: 0.8999 - val_loss: 0.7829 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2472 - accuracy: 0.9014 - val_loss: 0.7372 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2393 - accuracy: 0.8961 - val_loss: 0.7526 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2407 - accuracy: 0.8936 - val_loss: 0.7635 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2181 - accuracy: 0.9086 - val_loss: 0.7620 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2017 - accuracy: 0.9143 - val_loss: 0.8650 - val_accuracy: 0.7287 - lr: 0.0010\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2215 - accuracy: 0.9089 - val_loss: 0.8901 - val_accuracy: 0.7125 - lr: 0.0010\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2348 - accuracy: 0.9046 - val_loss: 0.7906 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2270 - accuracy: 0.9046 - val_loss: 0.7787 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2207 - accuracy: 0.9080 - val_loss: 0.7554 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2016 - accuracy: 0.9186 - val_loss: 0.8651 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.2162 - accuracy: 0.9161 - val_loss: 0.7796 - val_accuracy: 0.7462 - lr: 0.0010\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2151 - accuracy: 0.9168 - val_loss: 0.8297 - val_accuracy: 0.7212 - lr: 0.0010\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2105 - accuracy: 0.9165 - val_loss: 0.7673 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1983 - accuracy: 0.9196 - val_loss: 0.7589 - val_accuracy: 0.7575 - lr: 0.0010\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.2179 - accuracy: 0.9115 - val_loss: 0.7491 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.2094 - accuracy: 0.9168 - val_loss: 0.7622 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2055 - accuracy: 0.9190 - val_loss: 0.7829 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1986 - accuracy: 0.9212 - val_loss: 0.8129 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2000 - accuracy: 0.9177 - val_loss: 0.7868 - val_accuracy: 0.7425 - lr: 0.0010\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1849 - accuracy: 0.9302 - val_loss: 0.7893 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.2087 - accuracy: 0.9136 - val_loss: 0.7272 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1900 - accuracy: 0.9296 - val_loss: 0.7869 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1895 - accuracy: 0.9221 - val_loss: 0.7962 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1869 - accuracy: 0.9302 - val_loss: 0.8602 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1805 - accuracy: 0.9277 - val_loss: 0.8344 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1660 - accuracy: 0.9343 - val_loss: 0.8474 - val_accuracy: 0.7375 - lr: 0.0010\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1792 - accuracy: 0.9321 - val_loss: 0.7787 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1789 - accuracy: 0.9268 - val_loss: 0.7525 - val_accuracy: 0.7825 - lr: 0.0010\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1609 - accuracy: 0.9352 - val_loss: 0.8673 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1714 - accuracy: 0.9302 - val_loss: 0.8639 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1657 - accuracy: 0.9334 - val_loss: 0.8290 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1656 - accuracy: 0.9343 - val_loss: 0.7872 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1775 - accuracy: 0.9318 - val_loss: 0.8324 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1602 - accuracy: 0.9393 - val_loss: 0.7970 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1657 - accuracy: 0.9387 - val_loss: 0.8001 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1611 - accuracy: 0.9346 - val_loss: 0.8484 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1615 - accuracy: 0.9424 - val_loss: 0.8784 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1610 - accuracy: 0.9374 - val_loss: 0.7919 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1640 - accuracy: 0.9359 - val_loss: 0.7957 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1719 - accuracy: 0.9327 - val_loss: 0.7852 - val_accuracy: 0.7850 - lr: 0.0010\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1593 - accuracy: 0.9437 - val_loss: 0.8310 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1464 - accuracy: 0.9427 - val_loss: 0.7583 - val_accuracy: 0.7850 - lr: 0.0010\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1559 - accuracy: 0.9384 - val_loss: 0.8132 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1590 - accuracy: 0.9374 - val_loss: 0.7626 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1509 - accuracy: 0.9387 - val_loss: 0.8030 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1578 - accuracy: 0.9412 - val_loss: 0.8714 - val_accuracy: 0.7275 - lr: 0.0010\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1605 - accuracy: 0.9377 - val_loss: 0.7842 - val_accuracy: 0.7738 - lr: 0.0010\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1500 - accuracy: 0.9406 - val_loss: 0.8422 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1331 - accuracy: 0.9512 - val_loss: 0.9072 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1331 - accuracy: 0.9503 - val_loss: 0.8088 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1601 - accuracy: 0.9377 - val_loss: 0.8897 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1440 - accuracy: 0.9471 - val_loss: 0.8618 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1443 - accuracy: 0.9459 - val_loss: 0.8555 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1539 - accuracy: 0.9424 - val_loss: 0.8665 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1556 - accuracy: 0.9365 - val_loss: 0.8196 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1412 - accuracy: 0.9474 - val_loss: 0.8965 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1192 - accuracy: 0.9565 - val_loss: 0.9134 - val_accuracy: 0.7563 - lr: 0.0010\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1481 - accuracy: 0.9449 - val_loss: 0.8327 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1408 - accuracy: 0.9487 - val_loss: 0.8543 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1513 - accuracy: 0.9465 - val_loss: 0.8503 - val_accuracy: 0.7475 - lr: 0.0010\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1343 - accuracy: 0.9537 - val_loss: 0.8293 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1312 - accuracy: 0.9506 - val_loss: 0.9323 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1344 - accuracy: 0.9521 - val_loss: 0.9118 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1497 - accuracy: 0.9421 - val_loss: 0.8851 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1262 - accuracy: 0.9518 - val_loss: 0.9865 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1325 - accuracy: 0.9471 - val_loss: 0.9671 - val_accuracy: 0.7387 - lr: 0.0010\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1340 - accuracy: 0.9490 - val_loss: 0.8932 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1299 - accuracy: 0.9537 - val_loss: 0.8954 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1224 - accuracy: 0.9549 - val_loss: 0.9082 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1208 - accuracy: 0.9574 - val_loss: 0.8646 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1276 - accuracy: 0.9549 - val_loss: 0.9159 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1242 - accuracy: 0.9496 - val_loss: 0.9072 - val_accuracy: 0.7613 - lr: 0.0010\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1318 - accuracy: 0.9496 - val_loss: 0.8983 - val_accuracy: 0.7538 - lr: 0.0010\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1259 - accuracy: 0.9509 - val_loss: 0.9454 - val_accuracy: 0.7588 - lr: 0.0010\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9606\n",
            "Epoch 253: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.1071 - accuracy: 0.9606 - val_loss: 0.9251 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.1113 - accuracy: 0.9615 - val_loss: 0.9280 - val_accuracy: 0.7638 - lr: 1.0000e-04\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0893 - accuracy: 0.9681 - val_loss: 0.9385 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0802 - accuracy: 0.9725 - val_loss: 0.9618 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0848 - accuracy: 0.9678 - val_loss: 0.9691 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0850 - accuracy: 0.9718 - val_loss: 0.9571 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0749 - accuracy: 0.9725 - val_loss: 0.9697 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0826 - accuracy: 0.9718 - val_loss: 0.9703 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0772 - accuracy: 0.9728 - val_loss: 0.9692 - val_accuracy: 0.7638 - lr: 1.0000e-04\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0783 - accuracy: 0.9709 - val_loss: 0.9888 - val_accuracy: 0.7588 - lr: 1.0000e-04\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0807 - accuracy: 0.9737 - val_loss: 1.0043 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0672 - accuracy: 0.9784 - val_loss: 0.9965 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0616 - accuracy: 0.9772 - val_loss: 1.0186 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0680 - accuracy: 0.9759 - val_loss: 1.0115 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0569 - accuracy: 0.9768 - val_loss: 1.0157 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0679 - accuracy: 0.9762 - val_loss: 0.9990 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0658 - accuracy: 0.9753 - val_loss: 1.0211 - val_accuracy: 0.7638 - lr: 1.0000e-04\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0604 - accuracy: 0.9781 - val_loss: 1.0204 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0613 - accuracy: 0.9815 - val_loss: 1.0319 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0563 - accuracy: 0.9800 - val_loss: 1.0421 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.0634 - accuracy: 0.9790 - val_loss: 1.0519 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0758 - accuracy: 0.9743 - val_loss: 1.0252 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0513 - accuracy: 0.9812 - val_loss: 1.0525 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0687 - accuracy: 0.9734 - val_loss: 1.0496 - val_accuracy: 0.7600 - lr: 1.0000e-04\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0567 - accuracy: 0.9803 - val_loss: 1.0321 - val_accuracy: 0.7713 - lr: 1.0000e-04\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0652 - accuracy: 0.9750 - val_loss: 1.0500 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0601 - accuracy: 0.9784 - val_loss: 1.0690 - val_accuracy: 0.7638 - lr: 1.0000e-04\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0696 - accuracy: 0.9737 - val_loss: 1.0459 - val_accuracy: 0.7738 - lr: 1.0000e-04\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0567 - accuracy: 0.9800 - val_loss: 1.0593 - val_accuracy: 0.7650 - lr: 1.0000e-04\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0595 - accuracy: 0.9790 - val_loss: 1.0592 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0637 - accuracy: 0.9790 - val_loss: 1.0909 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0551 - accuracy: 0.9806 - val_loss: 1.0770 - val_accuracy: 0.7700 - lr: 1.0000e-04\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0589 - accuracy: 0.9784 - val_loss: 1.0897 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0542 - accuracy: 0.9828 - val_loss: 1.0902 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0645 - accuracy: 0.9775 - val_loss: 1.0713 - val_accuracy: 0.7625 - lr: 1.0000e-04\n",
            "Epoch 288/500\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9793\n",
            "Epoch 288: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0583 - accuracy: 0.9790 - val_loss: 1.0860 - val_accuracy: 0.7638 - lr: 1.0000e-04\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0593 - accuracy: 0.9812 - val_loss: 1.0872 - val_accuracy: 0.7613 - lr: 1.0000e-05\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0566 - accuracy: 0.9781 - val_loss: 1.0868 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0664 - accuracy: 0.9781 - val_loss: 1.0837 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0609 - accuracy: 0.9778 - val_loss: 1.0843 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0541 - accuracy: 0.9803 - val_loss: 1.0826 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0505 - accuracy: 0.9819 - val_loss: 1.0844 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0558 - accuracy: 0.9806 - val_loss: 1.0842 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0656 - accuracy: 0.9784 - val_loss: 1.0825 - val_accuracy: 0.7625 - lr: 1.0000e-05\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.0595 - accuracy: 0.9784 - val_loss: 1.0837 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.0722 - accuracy: 0.9753 - val_loss: 1.0816 - val_accuracy: 0.7625 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff88e8a8910>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_23.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eaTkZbcj3XL",
        "outputId": "54af22d4-e191-431f-9b29-9619fea1299a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 6ms/step - loss: 0.7852 - accuracy: 0.7850\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7852028012275696, 0.7850000262260437]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ensembling"
      ],
      "metadata": {
        "id": "gSOGruHN2yGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_models=[model_10,model_9]\n",
        "ensemble_preds=[]"
      ],
      "metadata": {
        "id": "H-VnM6yd20k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in ensemble_models:\n",
        "  pred=tf.round(model.predict(x_test))\n",
        "  ensemble_preds.append(pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyEha6FGFZhz",
        "outputId": "a0c0b612-cb1e-4afb-d86f-cc633d14768e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 1s 4ms/step\n",
            "25/25 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_mean=tf.reduce_mean(ensemble_preds)"
      ],
      "metadata": {
        "id": "85KlD-uJF3_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Achu\n"
      ],
      "metadata": {
        "id": "WfTZVk8jmWkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10 # subroutines for fetching the CIFAR-10 dataset\n",
        "from keras.models import Model # basic class for specifying and training a neural network\n",
        "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
        "import numpy as np\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "import pandas\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "8CEPepPImYnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
        "num_epochs = 20 # we iterate 20 times over the entire training set\n",
        "kernel_size = 2 # we will use 3x3 kernels throughout\n",
        "pool_size = 2 # we will use 2x2 pooling throughout\n",
        "conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
        "conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
        "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
        "drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
        "hidden_size = 512 # the FC layer will have 512 neurons\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data() # fetch CIFAR-10 data\n",
        "\n",
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXX2DlsVsEzb",
        "outputId": "45f1a045-a4f1-47f6-8857-c32d555fa21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n",
            "[[[[ 59  62  63]\n",
            "   [ 43  46  45]\n",
            "   [ 50  48  43]\n",
            "   ...\n",
            "   [158 132 108]\n",
            "   [152 125 102]\n",
            "   [148 124 103]]\n",
            "\n",
            "  [[ 16  20  20]\n",
            "   [  0   0   0]\n",
            "   [ 18   8   0]\n",
            "   ...\n",
            "   [123  88  55]\n",
            "   [119  83  50]\n",
            "   [122  87  57]]\n",
            "\n",
            "  [[ 25  24  21]\n",
            "   [ 16   7   0]\n",
            "   [ 49  27   8]\n",
            "   ...\n",
            "   [118  84  50]\n",
            "   [120  84  50]\n",
            "   [109  73  42]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[208 170  96]\n",
            "   [201 153  34]\n",
            "   [198 161  26]\n",
            "   ...\n",
            "   [160 133  70]\n",
            "   [ 56  31   7]\n",
            "   [ 53  34  20]]\n",
            "\n",
            "  [[180 139  96]\n",
            "   [173 123  42]\n",
            "   [186 144  30]\n",
            "   ...\n",
            "   [184 148  94]\n",
            "   [ 97  62  34]\n",
            "   [ 83  53  34]]\n",
            "\n",
            "  [[177 144 116]\n",
            "   [168 129  94]\n",
            "   [179 142  87]\n",
            "   ...\n",
            "   [216 184 140]\n",
            "   [151 118  84]\n",
            "   [123  92  72]]]\n",
            "\n",
            "\n",
            " [[[154 177 187]\n",
            "   [126 137 136]\n",
            "   [105 104  95]\n",
            "   ...\n",
            "   [ 91  95  71]\n",
            "   [ 87  90  71]\n",
            "   [ 79  81  70]]\n",
            "\n",
            "  [[140 160 169]\n",
            "   [145 153 154]\n",
            "   [125 125 118]\n",
            "   ...\n",
            "   [ 96  99  78]\n",
            "   [ 77  80  62]\n",
            "   [ 71  73  61]]\n",
            "\n",
            "  [[140 155 164]\n",
            "   [139 146 149]\n",
            "   [115 115 112]\n",
            "   ...\n",
            "   [ 79  82  64]\n",
            "   [ 68  70  55]\n",
            "   [ 67  69  55]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[175 167 166]\n",
            "   [156 154 160]\n",
            "   [154 160 170]\n",
            "   ...\n",
            "   [ 42  34  36]\n",
            "   [ 61  53  57]\n",
            "   [ 93  83  91]]\n",
            "\n",
            "  [[165 154 128]\n",
            "   [156 152 130]\n",
            "   [159 161 142]\n",
            "   ...\n",
            "   [103  93  96]\n",
            "   [123 114 120]\n",
            "   [131 121 131]]\n",
            "\n",
            "  [[163 148 120]\n",
            "   [158 148 122]\n",
            "   [163 156 133]\n",
            "   ...\n",
            "   [143 133 139]\n",
            "   [143 134 142]\n",
            "   [143 133 144]]]\n",
            "\n",
            "\n",
            " [[[255 255 255]\n",
            "   [253 253 253]\n",
            "   [253 253 253]\n",
            "   ...\n",
            "   [253 253 253]\n",
            "   [253 253 253]\n",
            "   [253 253 253]]\n",
            "\n",
            "  [[255 255 255]\n",
            "   [255 255 255]\n",
            "   [255 255 255]\n",
            "   ...\n",
            "   [255 255 255]\n",
            "   [255 255 255]\n",
            "   [255 255 255]]\n",
            "\n",
            "  [[255 255 255]\n",
            "   [254 254 254]\n",
            "   [254 254 254]\n",
            "   ...\n",
            "   [254 254 254]\n",
            "   [254 254 254]\n",
            "   [254 254 254]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[113 120 112]\n",
            "   [111 118 111]\n",
            "   [105 112 106]\n",
            "   ...\n",
            "   [ 72  81  80]\n",
            "   [ 72  80  79]\n",
            "   [ 72  80  79]]\n",
            "\n",
            "  [[111 118 110]\n",
            "   [104 111 104]\n",
            "   [ 99 106  98]\n",
            "   ...\n",
            "   [ 68  75  73]\n",
            "   [ 70  76  75]\n",
            "   [ 78  84  82]]\n",
            "\n",
            "  [[106 113 105]\n",
            "   [ 99 106  98]\n",
            "   [ 95 102  94]\n",
            "   ...\n",
            "   [ 78  85  83]\n",
            "   [ 79  85  83]\n",
            "   [ 80  86  84]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 35 178 235]\n",
            "   [ 40 176 239]\n",
            "   [ 42 176 241]\n",
            "   ...\n",
            "   [ 99 177 219]\n",
            "   [ 79 147 197]\n",
            "   [ 89 148 189]]\n",
            "\n",
            "  [[ 57 182 234]\n",
            "   [ 44 184 250]\n",
            "   [ 50 183 240]\n",
            "   ...\n",
            "   [156 182 200]\n",
            "   [141 177 206]\n",
            "   [116 149 175]]\n",
            "\n",
            "  [[ 98 197 237]\n",
            "   [ 64 189 252]\n",
            "   [ 69 192 245]\n",
            "   ...\n",
            "   [188 195 206]\n",
            "   [119 135 147]\n",
            "   [ 61  79  90]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 73  79  77]\n",
            "   [ 53  63  68]\n",
            "   [ 54  68  80]\n",
            "   ...\n",
            "   [ 17  40  64]\n",
            "   [ 21  36  51]\n",
            "   [ 33  48  49]]\n",
            "\n",
            "  [[ 61  68  75]\n",
            "   [ 55  70  86]\n",
            "   [ 57  79 103]\n",
            "   ...\n",
            "   [ 24  48  72]\n",
            "   [ 17  35  53]\n",
            "   [  7  23  32]]\n",
            "\n",
            "  [[ 44  56  73]\n",
            "   [ 46  66  88]\n",
            "   [ 49  77 105]\n",
            "   ...\n",
            "   [ 27  52  77]\n",
            "   [ 21  43  66]\n",
            "   [ 12  31  50]]]\n",
            "\n",
            "\n",
            " [[[189 211 240]\n",
            "   [186 208 236]\n",
            "   [185 207 235]\n",
            "   ...\n",
            "   [175 195 224]\n",
            "   [172 194 222]\n",
            "   [169 194 220]]\n",
            "\n",
            "  [[194 210 239]\n",
            "   [191 207 236]\n",
            "   [190 206 235]\n",
            "   ...\n",
            "   [173 192 220]\n",
            "   [171 191 218]\n",
            "   [167 190 216]]\n",
            "\n",
            "  [[208 219 244]\n",
            "   [205 216 240]\n",
            "   [204 215 239]\n",
            "   ...\n",
            "   [175 191 217]\n",
            "   [172 190 216]\n",
            "   [169 191 215]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[207 199 181]\n",
            "   [203 195 175]\n",
            "   [203 196 173]\n",
            "   ...\n",
            "   [135 132 127]\n",
            "   [162 158 150]\n",
            "   [168 163 151]]\n",
            "\n",
            "  [[198 190 170]\n",
            "   [189 181 159]\n",
            "   [180 172 147]\n",
            "   ...\n",
            "   [178 171 160]\n",
            "   [175 169 156]\n",
            "   [175 169 154]]\n",
            "\n",
            "  [[198 189 173]\n",
            "   [189 181 162]\n",
            "   [178 170 149]\n",
            "   ...\n",
            "   [195 184 169]\n",
            "   [196 189 171]\n",
            "   [195 190 171]]]\n",
            "\n",
            "\n",
            " [[[229 229 239]\n",
            "   [236 237 247]\n",
            "   [234 236 247]\n",
            "   ...\n",
            "   [217 219 233]\n",
            "   [221 223 234]\n",
            "   [222 223 233]]\n",
            "\n",
            "  [[222 221 229]\n",
            "   [239 239 249]\n",
            "   [233 234 246]\n",
            "   ...\n",
            "   [223 223 236]\n",
            "   [227 228 238]\n",
            "   [210 211 220]]\n",
            "\n",
            "  [[213 206 211]\n",
            "   [234 232 239]\n",
            "   [231 233 244]\n",
            "   ...\n",
            "   [220 220 232]\n",
            "   [220 219 232]\n",
            "   [202 203 215]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[150 143 135]\n",
            "   [140 135 127]\n",
            "   [132 127 120]\n",
            "   ...\n",
            "   [224 222 218]\n",
            "   [230 228 225]\n",
            "   [241 241 238]]\n",
            "\n",
            "  [[137 132 126]\n",
            "   [130 127 120]\n",
            "   [125 121 115]\n",
            "   ...\n",
            "   [181 180 178]\n",
            "   [202 201 198]\n",
            "   [212 211 207]]\n",
            "\n",
            "  [[122 119 114]\n",
            "   [118 116 110]\n",
            "   [120 116 111]\n",
            "   ...\n",
            "   [179 177 173]\n",
            "   [164 164 162]\n",
            "   [163 163 161]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train),len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y27U7bTgVbN",
        "outputId": "6570ded7-a67e-4ef9-dc11-972ddb62d495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 50000)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RolTLq0tKH7",
        "outputId": "fddbb4c2-25dc-47de-ad1b-10330a30c38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 12)                108       \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcg6vHpmw4ek",
        "outputId": "f4959ce0-7ef7-4794-86e5-599c6c28c68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"Baseline: %.2f%%\" % (results.histo\n",
        "\n",
        "# Predict\n",
        "y_pred = Model.predict_classes(X_test, batch_size=batch_size, verbose=verbose)\n",
        "\n",
        "test_acc = round(accuracy_score(y_test_cat, y_pred)*100)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "\n",
        "print(y_pred)\n",
        "for i in range(len(X_test)):\n",
        "    preds = y_pred[i]\n",
        "    print(i, preds, y_test_cat[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "WiCUptxXUF9L",
        "outputId": "9f34ad48-7e43-4912-d76c-49b656387218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8489a12929c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'Model' has no attribute 'predict_classes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSgk-UdfxI4s",
        "outputId": "befc3190-9840-4859-db21-c3c303a6b88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train, depth, height, width = x_train.shape # there are 50000 training examples in CIFAR-10\n",
        "num_test = x_test.shape[0] # there are 10000 test examples in CIFAR-10\n",
        "num_classes = np.unique(y_train).shape[0] # there are 10 image classes\n",
        "\n",
        "X_train = x_train.astype('float32')\n",
        "X_test = x_test.astype('float32')\n",
        "X_train /= np.max(X_train) # Normalise data to [0, 1] range\n",
        "X_test /= np.max(X_train) # Normalise data to [0, 1] range\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
        "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
        "\n",
        "inp = Input(shape=(depth, height, width)) # N.B. depth goes first in Keras!\n",
        "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
        "conv_1 = Convolution2D(conv_depth_1, kernel_size=(2,2), activation='relu')(inp)\n",
        "conv_2 = Convolution2D(conv_depth_1, kernel_size=(2,2), activation='relu')(conv_1)\n",
        "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
        "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
        "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
        "conv_3 = Convolution2D(conv_depth_2, kernel_size=(2,2), activation='relu')(drop_1)\n",
        "conv_4 = Convolution2D(conv_depth_2, kernel_size=(2,2), activation='relu')(conv_3)\n",
        "pool_2 = MaxPooling2D()(conv_4)\n",
        "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
        "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
        "flat = Flatten()(drop_2)\n",
        "hidden = Dense(hidden_size, activation='relu')(flat)\n",
        "drop_3 = Dropout(drop_prob_2)(hidden)\n",
        "out = Dense(num_classes, activation='softmax')(drop_3)\n",
        "\n",
        "model11 = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers\n",
        "\n",
        "model11.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
        "              optimizer='adam', # using the Adam optimiser\n",
        "              metrics=['accuracy']) # reporting the accuracy\n",
        "\n",
        "model11.fit(X_train, Y_train, # Train the model using the training set...\n",
        "          batch_size=batch_size,epochs=100,\n",
        "          verbose=1, validation_data=(X_test,Y_test),\n",
        "          callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                                                          patience=10,\n",
        "                                                          verbose=1),\n",
        "                     tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                      patience=20,\n",
        "                                                      verbose=1)]) # ...holding out 10% of"
      ],
      "metadata": {
        "id": "XTzB0TL9Vaw9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "87e23743-3ac8-43d6-cda4-b0cd84513f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7db2172c626b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m           callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n\u001b[0m\u001b[1;32m     40\u001b[0m                                                           \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                                           verbose=1),\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eQvo0zDxjYF",
        "outputId": "49ac017f-b3cd-4041-f0dc-85e45dc3d358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 12)                108       \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "ekYt_lw6wbWX",
        "outputId": "472f58fe-eebc-4cca-c57d-6a5c9ffefd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-18e53af38380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "model = Sequential()\n",
        "#Adding 3 dense layers\n",
        "model.add(Dense(12, input_dim=8))\n",
        "model.add(Dense(8))\n",
        "model.add(Dense(1))\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(x, y_test, nb_epoch=20, batch_size=10,  verbose=2)\n",
        "# evaluate the model\n",
        "\n",
        "scores = model.evaluate(x, y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "RXWCguIQYL2f",
        "outputId": "f0100194-ceae-4cfa-ad08-38b58e1f0d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-8060c8f174ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'nb_epoch'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}